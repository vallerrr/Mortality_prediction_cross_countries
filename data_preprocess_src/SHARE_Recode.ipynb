{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and initial specification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have imported the data and it has 6385 rows and 139620 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "share_path= Path('/Users/valler/Python/OX_Thesis/OX_thesis/Data/SHARE')\n",
    "\n",
    "# import data\n",
    "data=pd.read_pickle(share_path/'harmonised/H_SHARE_f.pkl')\n",
    "print('we have imported the data and it has {} rows and {} columns'.format(data.shape[1],data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_wave = '8'\n",
    "drink_wave=[2,4,5]\n",
    "financial_difficulties_wave=[3,7]\n",
    "today = datetime.now().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data recode record initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have recoded 33 vars so far, keep going on\n",
      "and the last variable is Zperceivedconstraints\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "\n",
    "if os.path.exists(share_path/'recoded_data.pkl'):\n",
    "    df_recode_record=pd.read_csv(share_path/'recode_record.csv')\n",
    "    df = pd.read_pickle(share_path/'recoded_data.pkl')\n",
    "    print(f'we have recoded {len(df_recode_record)} vars so far, keep going on')\n",
    "    print(f\"and the last variable is {df_recode_record.loc[len(df_recode_record)-1,'varname']}\")\n",
    "    \n",
    "else:\n",
    "    columns = ['varname',\n",
    "               'conventional_name',\n",
    "               'varname_in_raw',\n",
    "               'domain',\n",
    "\n",
    "               'available_waves',  # 0:time invariant\n",
    "               'recode_type', # [historical, multi-response, direct]\n",
    "               'reverse_code', # Boolean\n",
    "               'maximum_missing_response', # If the variable \n",
    "               'replace_dict',\n",
    "               'standardise',\n",
    "\n",
    "               'notes',\n",
    "               'in_HRS',\n",
    "               'in_ELSA',\n",
    "               'recode_date']\n",
    "    \n",
    "    df_recode_record=pd.DataFrame(columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row_to_df_record(new_row,df_recode_record):\n",
    "    \"\"\"\n",
    "    add row to df_recode_record\n",
    "    if the row exists, rewrite it\n",
    "    \"\"\"\n",
    "    varname= new_row['varname']\n",
    "    replace_control = 1 # by deafualt, we update the dict\n",
    "    \n",
    "    if varname in list(df_recode_record['varname']):\n",
    "        exist_row=df_recode_record.loc[df_recode_record['varname']==varname,:]\n",
    "        \n",
    "        # for vars with replace_dict, ask whether to clean it \n",
    "        replace_dict=exist_row['replace_dict'].values[0]\n",
    "        if not pd.isnull(replace_dict) and isinstance(replace_dict,dict):\n",
    "            \n",
    "            \n",
    "            stay_control=True\n",
    "            while stay_control:\n",
    "                print('we have found the dict as follows')\n",
    "                for key in replace_dict.keys():\n",
    "                    print('{}->{}'.format(key,replace_dict[key]))\n",
    "                    \n",
    "                replace_control=input(\"do you want to update it? 1->yes 0->no\")\n",
    "                try:\n",
    "                    replace_control=int(replace_control)\n",
    "                    if replace_control in [1,0]:\n",
    "                        stay_control=False\n",
    "                    else:   \n",
    "                        print('please check your response and try again')\n",
    "                except:\n",
    "                    print('please check your response and try again')\n",
    "            \n",
    "            \n",
    "        \n",
    "        # only keep those rows that doesn't match the new varname\n",
    "        df_recode_record=df_recode_record.where(df_recode_record['varname']!=varname)\n",
    "        df_recode_record.dropna(how='all',inplace=True)\n",
    "    \n",
    "    if  replace_control==0:  # not update, keep the original one\n",
    "        print('we will keep the original replace_dict')\n",
    "        new_row['replace_dict']=replace_dict\n",
    "        \n",
    "    df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n",
    "    \n",
    "         \n",
    "    return df_recode_record\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data_across_waves(varname_w1,total_waves,data):\n",
    "    \"\"\"\n",
    "    generate the column names with the first column name\n",
    "    when we need to draw information from multiple waves\n",
    "    \"\"\"\n",
    "    var_names=[]\n",
    "    for i in range(1,total_waves+1):\n",
    "        var_names.append(varname_w1.replace('1',str(i)))\n",
    "    temp = data[var_names]\n",
    "    return temp\n",
    "\n",
    "def count_times(df_row,response_to_count):\n",
    "    \"\"\"\n",
    "    send the row and response to count, to count the times that the \n",
    "    response has appeared in ech row/ppl\n",
    "    e.g. df['rentperiod'] = temp.apply(count_times,axis=1,response_to_count='1.own home')\n",
    "    \"\"\"\n",
    "    count=0\n",
    "    for item in df_row:\n",
    "        if item==response_to_count:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "\n",
    "def average_response_by_row(df_row,maximum_missing_response):\n",
    "    \"\"\"\n",
    "    for vars that draw info from multiple variables, this\n",
    "    function help to average them with maximum_missing_response\n",
    "    # df_row should be sliced data\n",
    "    \"\"\"\n",
    "    \n",
    "    missing_count=sum(pd.isnull(df_row))\n",
    "    if missing_count>=maximum_missing_response:\n",
    "        return None\n",
    "    else:\n",
    "        df_row=[x for x in df_row if not pd.isnull(x)]\n",
    "        # average among avaliable responses\n",
    "        return sum(df_row)/len(df_row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple response functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def multiresponse_average(varname,df_recode_record,data,df,print_missing_count_control):\n",
    "    \"\"\"\n",
    "    automation of average to multiple response\n",
    "    \"\"\"\n",
    "    \n",
    "    sliced_row = df_recode_record.loc[df_recode_record['varname']==varname,]\n",
    "    varset=sliced_row['var_set'].values[0]\n",
    "    maximum_missing_response=sliced_row['maximum_missing_response'].values[0]\n",
    "    reverse_control=sliced_row['reverse_code'].values[0]\n",
    "    \n",
    "    sliced_data = data[varset].copy()\n",
    "    \n",
    "    # print_missing counts info\n",
    "    if print_missing_count_control:\n",
    "        missing_count(sliced_data)\n",
    "    \n",
    "    print(f'1. maximum_missing_response {maximum_missing_response}\\n2. reverse_control {reverse_control}')\n",
    "    \n",
    "    # replace string to number \n",
    "    replace_dict=replace_response_with_value(sliced_data)\n",
    "    print(\"3. the replace dict is {}\".format(replace_dict))\n",
    "    sliced_data.replace(replace_dict,inplace=True)\n",
    "    \n",
    "    # reverse control\n",
    "    if reverse_control:\n",
    "        \n",
    "        unique_vals = get_unique_valaues(sliced_data)\n",
    "        print(\"4. unique_vals are {}\".format(unique_vals))\n",
    "        replace_dict = generate_value_replace_dict(unique_vals)\n",
    "        print(\"5. dict is {}\".format(replace_dict))\n",
    "        sliced_data.replace(replace_dict,inplace=True)\n",
    "    \n",
    "    # if there is only one variable, set it to the df directly rather than averaging them \n",
    "    if len(varset)==1:\n",
    "        df[varname]=sliced_data[varset[0]]\n",
    "    else:    \n",
    "        df[varname]=sliced_data.apply(average_response_by_row,axis=1,maximum_missing_response=maximum_missing_response)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_value_replace_dict(res_lst):\n",
    "    \"\"\"\n",
    "    return the replace dict for reverse coding \n",
    "    \"\"\"\n",
    "    replace_dict={}\n",
    "    max_val=max(res_lst)\n",
    "    res_lst.sort()\n",
    "    res_len=len(res_lst)\n",
    "    \n",
    "    for index in range(res_len):\n",
    "        reverse_ind = res_len-index-1\n",
    "        replace_dict[res_lst[index]]=res_lst[reverse_ind]\n",
    "    return replace_dict  \n",
    "\n",
    "def get_unique_valaues(sliced_data):\n",
    "    \"\"\"\n",
    "    if we need to treat values from all columns as a whole,\n",
    "    this function help to get the unique value list\n",
    "    \"\"\"\n",
    "    unique_list=[]\n",
    "    for column in sliced_data.columns:\n",
    "        unique_list+=list(sliced_data[column].unique())\n",
    "    \n",
    "    # delete repeat value\n",
    "    unique_list=list(set(unique_list))\n",
    "    \n",
    "    # get rid of nans\n",
    "    unique_list= [x for x in unique_list if not pd.isnull(x)]\n",
    "    return unique_list\n",
    "\n",
    "\n",
    "def replace_response_with_value(sliced_data):\n",
    "    \"\"\"\n",
    "    replace the string response with numbers \n",
    "    # here by default we assume all the values are format of '#. explain'\n",
    "    # e.g. '1.hardly ever or never'\n",
    "    \"\"\"\n",
    "    replace_dict={}\n",
    "    response_list = get_unique_valaues(sliced_data)\n",
    "    \n",
    "    # generate the dict\n",
    "    for res in response_list:\n",
    "        if isinstance(res,str):\n",
    "            number=res.split('.')[0]\n",
    "            replace_dict[res]=int(number)\n",
    "        elif isinstance(res,float) or isinstance(res,int):\n",
    "            number=res\n",
    "            replace_dict[res]=int(number)\n",
    "        else:\n",
    "            print('the response is incorrect, {}, type{}'.format(res,type(res)))\n",
    "        \n",
    "        \n",
    "    return replace_dict\n",
    "\n",
    "def missing_count(sliced_data):\n",
    "    \"\"\"\n",
    "    print the missing counts in each row, account for all columns in var_set\n",
    "    \"\"\"\n",
    "    \n",
    "    def return_sum_of_null(row):\n",
    "        missing_count=sum(pd.isnull(row))\n",
    "        return missing_count\n",
    "    sliced_data['missing_count']=sliced_data.apply(return_sum_of_null,axis=1)\n",
    "    print(\"0. missing information -------- start\")\n",
    "    print(sliced_data['missing_count'].value_counts())\n",
    "    sliced_data.drop(columns=['missing_count'],inplace=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### historical response functions \n",
    "\n",
    "- historical response : mainly for yes or no type variable\n",
    "- once `yes` lable appears, it will be counted as `yes`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def historical_response_recorder(varname,df_recode_record,data,df):\n",
    "    \"\"\"\n",
    "    check whether there is any affimative response to the question, if exists (doesn't matter how many times) ->1\n",
    "    \"\"\"\n",
    "    \n",
    "    sliced_row = df_recode_record.loc[df_recode_record['varname']==varname,]\n",
    "    varset = sliced_row['var_set'].values[0]\n",
    "    sliced_data = data[varset].copy()\n",
    "\n",
    "    # get the replace_dict by inputting or from df_recode_record\n",
    "        \n",
    "    replace_dict=generate_replace_dict_for_historical_response(sliced_row,sliced_data)\n",
    "    replace_dict['nan']=None\n",
    "    # record the replace_dict\n",
    "    \n",
    "    df_recode_record.loc[df_recode_record['varname']==varname,'replace_dict']=[replace_dict]\n",
    "    \n",
    "    # here all the values will be changed to 1/-1 value\n",
    "    # first convert all columns to str (could be categorical)\n",
    "    # for col in sliced_data.columns:\n",
    "        # sliced_data[col].replace(replace_dict,inplace=True)\n",
    "        # sliced_data[col]=sliced_data[col].astype('str')\n",
    "        \n",
    "    # print(f'unique values are {get_unique_valaues(sliced_data)}')\n",
    "    # print(sliced_data.value_counts())\n",
    "    print(f'\\n1.the replace dict is \\n{replace_dict}')\n",
    "    \n",
    "    sliced_data.replace(replace_dict,inplace=True)\n",
    "    \n",
    "    \n",
    "    # if there is only one variable being sent -> set the sliced_data to df directly\n",
    "    if len(varset)==1:\n",
    "        \n",
    "        df[varname]=sliced_data[varset[0]]\n",
    "    else:\n",
    "        # mark response \n",
    "        df[varname]=sliced_data.apply(mark_positive_response,axis=1)\n",
    "        \n",
    "    return df,df_recode_record\n",
    "\n",
    "\n",
    "def generate_replace_dict_for_historical_response(sliced_row,sliced_data):\n",
    "    \"\"\"\n",
    "    generate the replace_dict if there is nothing in sliced_row['replace_dict']/returned object is not dict\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        replace_dict=sliced_row['replace_dict'].values[0]\n",
    "    except:\n",
    "        replace_dict=None\n",
    "    # if we had done it, we shouldn't do it again..\n",
    "    if pd.isnull(replace_dict) or not isinstance(replace_dict,dict):\n",
    "        replace_dict={}\n",
    "        response_list = get_unique_valaues(sliced_data)\n",
    "        print(f'all responses are: {response_list}')\n",
    "        for response in response_list:\n",
    "            Pass_control=True\n",
    "            while Pass_control:\n",
    "                replace_val=input(f'replace response [{response}] with int .. (999 -> none)')\n",
    "                try:\n",
    "                    replace_val=int(replace_val)\n",
    "                    Pass_control=False\n",
    "                except:\n",
    "                    print('error in the response, please try again')\n",
    "                    \n",
    "            replace_dict[response]= None if replace_val==999 else replace_val \n",
    "            \n",
    "    return replace_dict\n",
    "    \n",
    "def mark_positive_response(df_row):\n",
    "    \"\"\"\n",
    "    if 1 exists in df_row, mark it as 1 else -1\n",
    "    \"\"\"\n",
    "    if 1 in list(df_row):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace only function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_only_recorder(varname,df_recode_record,data,df):\n",
    "    \n",
    "    # get the records \n",
    "    sliced_row = df_recode_record.loc[df_recode_record['varname']==varname,]\n",
    "    varset=sliced_row['var_set'].values[0]\n",
    "    reverse_control = sliced_row['reverse_code'].values[0]\n",
    "    sliced_data = data[varset].copy()\n",
    "    \n",
    "\n",
    "    # get the replace_dict by inputting or from df_recode_record\n",
    "    replace_dict=generate_replace_dict_for_historical_response(sliced_row,sliced_data)\n",
    "    replace_dict['nan']=None\n",
    "    # record the replace_dict\n",
    "    \n",
    "    \n",
    "    df_recode_record.loc[df_recode_record['varname']==varname,'replace_dict'] = [replace_dict]\n",
    "    print(f'\\n1.the replace dict is \\n{replace_dict}')\n",
    "    \n",
    "    df[varname] = sliced_data.replace(replace_dict)\n",
    "    \n",
    "    # we reverse code lastly to avoid crashing the previous replacing action\n",
    "    if reverse_control:\n",
    "        response_list = list(replace_dict.values())\n",
    "        while None in response_list: response_list.remove(None)\n",
    "        reverse_replace_dict = generate_value_replace_dict(response_list)\n",
    "        df[varname].replace(reverse_replace_dict, inplace=True)\n",
    "    \n",
    "    return df,df_recode_record\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recode Processor \n",
    "\n",
    "after reading the new_row dict, decide which function we should use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_processor(varname,df_recode_record,df):\n",
    "    var_dict=df_recode_record.loc[df_recode_record['varname']==varname,:].to_dict('records')[0]\n",
    "\n",
    "    if var_dict['recode_type']=='direct_use':\n",
    "        df[varname]=data[var_dict['var_set']]\n",
    "        print(df[varname].describe())\n",
    "    elif var_dict['recode_type']=='replace_only':\n",
    "        df,df_recode_record = replace_only_recorder(varname,df_recode_record,data,df)\n",
    "        print(f'\\n2. the updated var_dict is\\n{var_dict}')\n",
    "        print(f'\\n3. statistics\\n{df[varname].value_counts()}')\n",
    "    elif var_dict['recode_type']=='historical':\n",
    "        df,df_recode_record=historical_response_recorder(varname,df_recode_record,data,df)\n",
    "        print(df[varname].value_counts())\n",
    "    elif var_dict['recode_type'] == 'multi_response':\n",
    "        print_missing_count_control=True if input('want to check the missings ? 1/0 ')=='1' else False\n",
    "        df=multiresponse_average(varname,df_recode_record,data,df,print_missing_count_control)\n",
    "    return df,df_recode_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Var Recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_dict={\"1\":\"Demographic\", \"2\": \"Childhood Adversity\",\n",
    "             \"3\": \"Adulthood Socioeconomic\",\"4\":\"Adulthood Health Behaviors\",\n",
    "             \"5\":\"Adulthood Social Connections\",\"6\":\"Adulthood Psychological\",\n",
    "             \"7\":\"Adulthood Adverse Experiences\",\"8\":'Others'}\n",
    "\n",
    "recode_type_dict={\"1\":'historical',\"2\":'multi_response',\"3\":'replace_only',\"4\":'direct_use',\"5\":'row_manual'}\n",
    "\n",
    "wave_controller_dict={\"1\":'latest_wave',\"2\":\"single_wave\",'3':\"drink_wave\",'4':'financial_difficulties_wave',\"5\":\"manual\"}\n",
    "\n",
    "def new_var_record_input(varname,var_set,available_waves,replace_dict,notes):\n",
    "    new_row={}\n",
    "    \n",
    "    new_row['varname']=varname\n",
    "    new_row['var_set']=var_set\n",
    "    new_row['available_waves'] = available_waves\n",
    "    new_row['replace_dict'] =replace_dict\n",
    "    new_row['notes'] = notes\n",
    "\n",
    "    new_row['conventional_name']=input(\"what's the conventional name? \")\n",
    "    \n",
    "    for key,value in domain_dict.items():\n",
    "        print(f'\\n{key}:{value}')\n",
    "    domain_key=input(\"what's the domain? (select the number) \")\n",
    "    new_row['domain']=domain_dict[domain_key]\n",
    "        \n",
    "    for key,value in recode_type_dict.items():\n",
    "        print(f'\\n{key}:{value}')\n",
    "    recode_type_key=input(\"what's the recode_type? \")\n",
    "    new_row['recode_type']=recode_type_dict[recode_type_key]\n",
    "    \n",
    "    for key,value in wave_controller_dict.items():\n",
    "        print(f'\\n{key}:{value}')\n",
    "    wave_controller_key=input(\"what's the recode_type? \")\n",
    "    new_row['wave_controller']=wave_controller_dict[wave_controller_key]\n",
    "    \n",
    "    reverse_code_control = input('do this var need to be reverse_coded? 1/0 ')\n",
    "    new_row['reverse_code']=True if reverse_code_control=='1' else False\n",
    "\n",
    "    \n",
    "    new_row['maximum_missing_response']=int(input(\"what's the maximum_missing_response? \")) if recode_type_key=='2' else None\n",
    "    \n",
    "    standardise_control = input('do this var need to be standardised? 1/0 ')\n",
    "    new_row['standardise']=True if standardise_control=='1' else False\n",
    "    \n",
    "    HRS_control= input('Is this var in HRS? 1/0 ')\n",
    "    new_row['in_HRS']=True if HRS_control=='1' else False\n",
    "    \n",
    "    ELSA_control= input('Is this var in ELSA? 1/0 ')\n",
    "    new_row['in_ELSA']=True if ELSA_control=='1' else False\n",
    "    \n",
    "    new_row['recode_date']=today\n",
    "    \n",
    "    return new_row\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDs and Death Info "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df[['hhid','pn','mergeid','isocountry']]=data[['hhid','pn','mergeid','isocountry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Death Year `deathY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='deathY'\n",
    "var_set=['radyear']\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Death Year',\n",
    " 'domain': 'Others',\n",
    " 'recode_type': 'direct_use',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': False,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='deathY'\n",
    "var_set=['radyear']\n",
    "available_waves= [0]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='deathY'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['deathY'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016.0    1910\n",
       "2018.0    1718\n",
       "2019.0    1668\n",
       "2017.0    1597\n",
       "2014.0    1586\n",
       "2015.0    1538\n",
       "2013.0    1391\n",
       "2012.0    1357\n",
       "2020.0     922\n",
       "2011.0     901\n",
       "2008.0     723\n",
       "2010.0     644\n",
       "2009.0     571\n",
       "2007.0     527\n",
       "2021.0     512\n",
       "2006.0     446\n",
       "2005.0     290\n",
       "2004.0      48\n",
       "Name: deathY, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['deathY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139620"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18349"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['deathY'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age at Interview `age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='age'\n",
    "var_set=['r8agey'.replace('8',latest_wave)]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Age at Interview',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'domain': 'Demographic',\n",
    " 'recode_type': 'direct_use',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='age'\n",
    "var_set=['r8agey'.replace('8',latest_wave)]\n",
    "available_waves= list(range(1,9))\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    46733.000000\n",
       "mean        70.270815\n",
       "std          9.472927\n",
       "min         31.000000\n",
       "25%         63.000000\n",
       "50%         70.000000\n",
       "75%         77.000000\n",
       "max        103.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname='age'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)\n",
    "df[varname].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Male `maleYN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "1.man->1\n",
      "2.woman->-1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>conventional_name</th>\n",
       "      <th>varname_in_raw</th>\n",
       "      <th>domain</th>\n",
       "      <th>available_waves</th>\n",
       "      <th>recode_type</th>\n",
       "      <th>reverse_code</th>\n",
       "      <th>maximum_missing_response</th>\n",
       "      <th>replace_dict</th>\n",
       "      <th>standardise</th>\n",
       "      <th>notes</th>\n",
       "      <th>recode_date</th>\n",
       "      <th>var_set</th>\n",
       "      <th>in_ELSA</th>\n",
       "      <th>in_HRS</th>\n",
       "      <th>wave_controller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deathY</td>\n",
       "      <td>Death Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Others</td>\n",
       "      <td>[0]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[radyear]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>Age at Interview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8agey]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>everunemployed</td>\n",
       "      <td>History of Unemployment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lencurmarridge</td>\n",
       "      <td>length of current marriage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1mcurln]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>currentpaternered</td>\n",
       "      <td>Current Marital Status: With Partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8mstat]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zeduccat</td>\n",
       "      <td>Lower Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.Primary education': 1, '3.Upper secondary ...</td>\n",
       "      <td>True</td>\n",
       "      <td>not same as HRS, we use the ISCED 2 code for e...</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[raedisced]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rural</td>\n",
       "      <td>Residence in Rurual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.rural': 1, '0.urban': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>1:rural;-1:urban</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[h8rural]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>citizenship</td>\n",
       "      <td>Citizenship Status</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>whether citizen at baseline interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[racitizen]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>migrantYN</td>\n",
       "      <td>Foreign Born</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.in country': -1, '0.out of country': 1, 'n...</td>\n",
       "      <td>True</td>\n",
       "      <td>Born in Country of Interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[rabcountry]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>maleYN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.man': 1, '2.woman': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[ragender]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             varname                         conventional_name  \\\n",
       "0             deathY                                Death Year   \n",
       "1                age                          Age at Interview   \n",
       "2     everunemployed                   History of Unemployment   \n",
       "3     lencurmarridge                length of current marriage   \n",
       "4  currentpaternered  Current Marital Status: With Partnership   \n",
       "5           Zeduccat                           Lower Education   \n",
       "6              rural                       Residence in Rurual   \n",
       "7        citizenship                        Citizenship Status   \n",
       "8          migrantYN                              Foreign Born   \n",
       "9             maleYN                                      Male   \n",
       "\n",
       "   varname_in_raw                   domain           available_waves  \\\n",
       "0             NaN                   Others                       [0]   \n",
       "1             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "2             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "3             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "4             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "5             NaN  Adulthood Socioeconomic                       [0]   \n",
       "6             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "7             NaN              Demographic                       [0]   \n",
       "8             NaN              Demographic                       [0]   \n",
       "9             NaN              Demographic                       [0]   \n",
       "\n",
       "    recode_type reverse_code maximum_missing_response  \\\n",
       "0    direct_use        False                     None   \n",
       "1    direct_use        False                     None   \n",
       "2    historical        False                     None   \n",
       "3    direct_use        False                     None   \n",
       "4  replace_only        False                     None   \n",
       "5  replace_only         True                     None   \n",
       "6  replace_only        False                     None   \n",
       "7  replace_only        False                     None   \n",
       "8  replace_only        False                     None   \n",
       "9  replace_only        False                     None   \n",
       "\n",
       "                                        replace_dict standardise  \\\n",
       "0                                               None       False   \n",
       "1                                               None        True   \n",
       "2                                               None        True   \n",
       "3                                               None        True   \n",
       "4                                               None        True   \n",
       "5  {'1.Primary education': 1, '3.Upper secondary ...        True   \n",
       "6         {'1.rural': 1, '0.urban': -1, 'nan': None}        True   \n",
       "7              {'0.No': -1, '1.Yes': 1, 'nan': None}        True   \n",
       "8  {'1.in country': -1, '0.out of country': 1, 'n...        True   \n",
       "9           {'1.man': 1, '2.woman': -1, 'nan': None}        True   \n",
       "\n",
       "                                               notes recode_date  \\\n",
       "0                                               None  2023-01-10   \n",
       "1                                               None  2023-01-10   \n",
       "2                                               None  2023-01-10   \n",
       "3                                               None  2023-01-10   \n",
       "4                                               None  2023-01-10   \n",
       "5  not same as HRS, we use the ISCED 2 code for e...  2023-01-10   \n",
       "6                                   1:rural;-1:urban  2023-01-10   \n",
       "7              whether citizen at baseline interview  2023-01-10   \n",
       "8                       Born in Country of Interview  2023-01-10   \n",
       "9                                               None  2023-01-10   \n",
       "\n",
       "                                             var_set in_ELSA in_HRS  \\\n",
       "0                                          [radyear]    True   True   \n",
       "1                                           [r8agey]    True   True   \n",
       "2  [r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...    True   True   \n",
       "3                                         [r1mcurln]   False  False   \n",
       "4                                          [r8mstat]    True  False   \n",
       "5                                        [raedisced]    True   True   \n",
       "6                                          [h8rural]   False  False   \n",
       "7                                        [racitizen]   False  False   \n",
       "8                                       [rabcountry]    True   True   \n",
       "9                                         [ragender]    True   True   \n",
       "\n",
       "  wave_controller  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2     latest_wave  \n",
       "3     latest_wave  \n",
       "4     latest_wave  \n",
       "5     latest_wave  \n",
       "6     latest_wave  \n",
       "7     single_wave  \n",
       "8     single_wave  \n",
       "9     single_wave  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname='maleYN'\n",
    "var_set=['ragender']\n",
    "\n",
    "new_row={'varname':varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': {'1.man': 1, '2.woman': -1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Male',\n",
    " 'domain': 'Demographic',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'in_HRS':True,\n",
    " 'in_ELSA': True,\n",
    " 'standardise': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='maleYN'\n",
    "var_set=['ragender']\n",
    "available_waves= [0]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.the replace dict is \n",
      "{'1.man': 1, '2.woman': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      " {'varname': 'maleYN', 'conventional_name': 'Male', 'varname_in_raw': nan, 'domain': 'Demographic', 'available_waves': [0], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': {'1.man': 1, '2.woman': -1, 'nan': None}, 'standardise': True, 'notes': None, 'recode_date': '2023-01-10', 'var_set': ['ragender']}\n",
      "\n",
      "3. statistics\n",
      " -1    77707\n",
      " 1    61913\n",
      "Name: maleYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='maleYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foreign Born `migrantYN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "1.in country->-1\n",
      "0.out of country->1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>conventional_name</th>\n",
       "      <th>varname_in_raw</th>\n",
       "      <th>domain</th>\n",
       "      <th>available_waves</th>\n",
       "      <th>recode_type</th>\n",
       "      <th>reverse_code</th>\n",
       "      <th>maximum_missing_response</th>\n",
       "      <th>replace_dict</th>\n",
       "      <th>standardise</th>\n",
       "      <th>notes</th>\n",
       "      <th>recode_date</th>\n",
       "      <th>var_set</th>\n",
       "      <th>in_ELSA</th>\n",
       "      <th>in_HRS</th>\n",
       "      <th>wave_controller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deathY</td>\n",
       "      <td>Death Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Others</td>\n",
       "      <td>[0]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[radyear]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>Age at Interview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8agey]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maleYN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.man': 1, '2.woman': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[ragender]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>everunemployed</td>\n",
       "      <td>History of Unemployment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lencurmarridge</td>\n",
       "      <td>length of current marriage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1mcurln]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>currentpaternered</td>\n",
       "      <td>Current Marital Status: With Partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8mstat]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zeduccat</td>\n",
       "      <td>Lower Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.Primary education': 1, '3.Upper secondary ...</td>\n",
       "      <td>True</td>\n",
       "      <td>not same as HRS, we use the ISCED 2 code for e...</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[raedisced]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rural</td>\n",
       "      <td>Residence in Rurual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.rural': 1, '0.urban': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>1:rural;-1:urban</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[h8rural]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>citizenship</td>\n",
       "      <td>Citizenship Status</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>whether citizen at baseline interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[racitizen]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>migrantYN</td>\n",
       "      <td>Foreign Born</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.in country': -1, '0.out of country': 1, 'n...</td>\n",
       "      <td>True</td>\n",
       "      <td>Born in Country of Interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[rabcountry]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             varname                         conventional_name  \\\n",
       "0             deathY                                Death Year   \n",
       "1                age                          Age at Interview   \n",
       "2             maleYN                                      Male   \n",
       "3     everunemployed                   History of Unemployment   \n",
       "4     lencurmarridge                length of current marriage   \n",
       "5  currentpaternered  Current Marital Status: With Partnership   \n",
       "6           Zeduccat                           Lower Education   \n",
       "7              rural                       Residence in Rurual   \n",
       "8        citizenship                        Citizenship Status   \n",
       "9          migrantYN                              Foreign Born   \n",
       "\n",
       "   varname_in_raw                   domain           available_waves  \\\n",
       "0             NaN                   Others                       [0]   \n",
       "1             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "2             NaN              Demographic                       [0]   \n",
       "3             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "4             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "5             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "6             NaN  Adulthood Socioeconomic                       [0]   \n",
       "7             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "8             NaN              Demographic                       [0]   \n",
       "9             NaN              Demographic                       [0]   \n",
       "\n",
       "    recode_type reverse_code maximum_missing_response  \\\n",
       "0    direct_use        False                     None   \n",
       "1    direct_use        False                     None   \n",
       "2  replace_only        False                     None   \n",
       "3    historical        False                     None   \n",
       "4    direct_use        False                     None   \n",
       "5  replace_only        False                     None   \n",
       "6  replace_only         True                     None   \n",
       "7  replace_only        False                     None   \n",
       "8  replace_only        False                     None   \n",
       "9  replace_only        False                     None   \n",
       "\n",
       "                                        replace_dict standardise  \\\n",
       "0                                               None       False   \n",
       "1                                               None        True   \n",
       "2           {'1.man': 1, '2.woman': -1, 'nan': None}        True   \n",
       "3                                               None        True   \n",
       "4                                               None        True   \n",
       "5                                               None        True   \n",
       "6  {'1.Primary education': 1, '3.Upper secondary ...        True   \n",
       "7         {'1.rural': 1, '0.urban': -1, 'nan': None}        True   \n",
       "8              {'0.No': -1, '1.Yes': 1, 'nan': None}        True   \n",
       "9  {'1.in country': -1, '0.out of country': 1, 'n...        True   \n",
       "\n",
       "                                               notes recode_date  \\\n",
       "0                                               None  2023-01-10   \n",
       "1                                               None  2023-01-10   \n",
       "2                                               None  2023-01-10   \n",
       "3                                               None  2023-01-10   \n",
       "4                                               None  2023-01-10   \n",
       "5                                               None  2023-01-10   \n",
       "6  not same as HRS, we use the ISCED 2 code for e...  2023-01-10   \n",
       "7                                   1:rural;-1:urban  2023-01-10   \n",
       "8              whether citizen at baseline interview  2023-01-10   \n",
       "9                       Born in Country of Interview  2023-01-10   \n",
       "\n",
       "                                             var_set in_ELSA in_HRS  \\\n",
       "0                                          [radyear]    True   True   \n",
       "1                                           [r8agey]    True   True   \n",
       "2                                         [ragender]    True   True   \n",
       "3  [r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...    True   True   \n",
       "4                                         [r1mcurln]   False  False   \n",
       "5                                          [r8mstat]    True  False   \n",
       "6                                        [raedisced]    True   True   \n",
       "7                                          [h8rural]   False  False   \n",
       "8                                        [racitizen]   False  False   \n",
       "9                                       [rabcountry]    True   True   \n",
       "\n",
       "  wave_controller  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3     latest_wave  \n",
       "4     latest_wave  \n",
       "5     latest_wave  \n",
       "6     latest_wave  \n",
       "7     latest_wave  \n",
       "8     single_wave  \n",
       "9     single_wave  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname='migrantYN'\n",
    "var_set=['rabcountry']\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': {'1.in country': -1, \n",
    "                  '0.out of country': 1, \n",
    "                  'nan': None},\n",
    " 'notes': 'Born in Country of Interview',\n",
    " 'conventional_name': 'Foreign Born',\n",
    " 'domain': 'Demographic',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'recode_type': 'replace_only',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='migrantYN'\n",
    "var_set=['rabcountry']\n",
    "available_waves= [0]\n",
    "replace_dict=  None\n",
    "notes='Born in Country of Interview' \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [1.in country] with int .. (999 -> none)-1\n",
      "replace response [0.out of country] with int .. (999 -> none)1\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.in country': -1, '0.out of country': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'migrantYN', 'conventional_name': 'Foreign Born', 'varname_in_raw': nan, 'domain': 'Demographic', 'available_waves': [0], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': 'Born in Country of Interview', 'recode_date': '2023-01-10', 'var_set': ['rabcountry'], 'in_ELSA': True, 'in_HRS': True}\n",
      "\n",
      "3. statistics\n",
      "-1.0    124238\n",
      " 1.0     14485\n",
      "Name: migrantYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='migrantYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citizenship Status `citizenship`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "0.No->-1\n",
      "1.Yes->1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>conventional_name</th>\n",
       "      <th>varname_in_raw</th>\n",
       "      <th>domain</th>\n",
       "      <th>available_waves</th>\n",
       "      <th>recode_type</th>\n",
       "      <th>reverse_code</th>\n",
       "      <th>maximum_missing_response</th>\n",
       "      <th>replace_dict</th>\n",
       "      <th>standardise</th>\n",
       "      <th>notes</th>\n",
       "      <th>recode_date</th>\n",
       "      <th>var_set</th>\n",
       "      <th>in_ELSA</th>\n",
       "      <th>in_HRS</th>\n",
       "      <th>wave_controller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deathY</td>\n",
       "      <td>Death Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Others</td>\n",
       "      <td>[0]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[radyear]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>Age at Interview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8agey]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maleYN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.man': 1, '2.woman': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[ragender]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>migrantYN</td>\n",
       "      <td>Foreign Born</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.in country': -1, '0.out of country': 1, 'n...</td>\n",
       "      <td>True</td>\n",
       "      <td>Born in Country of Interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[rabcountry]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>everunemployed</td>\n",
       "      <td>History of Unemployment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lencurmarridge</td>\n",
       "      <td>length of current marriage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1mcurln]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>currentpaternered</td>\n",
       "      <td>Current Marital Status: With Partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8mstat]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zeduccat</td>\n",
       "      <td>Lower Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.Primary education': 1, '3.Upper secondary ...</td>\n",
       "      <td>True</td>\n",
       "      <td>not same as HRS, we use the ISCED 2 code for e...</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[raedisced]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rural</td>\n",
       "      <td>Residence in Rurual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.rural': 1, '0.urban': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>1:rural;-1:urban</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[h8rural]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>citizenship</td>\n",
       "      <td>Citizenship Status</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>whether citizen at baseline interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[racitizen]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             varname                         conventional_name  \\\n",
       "0             deathY                                Death Year   \n",
       "1                age                          Age at Interview   \n",
       "2             maleYN                                      Male   \n",
       "3          migrantYN                              Foreign Born   \n",
       "4     everunemployed                   History of Unemployment   \n",
       "5     lencurmarridge                length of current marriage   \n",
       "6  currentpaternered  Current Marital Status: With Partnership   \n",
       "7           Zeduccat                           Lower Education   \n",
       "8              rural                       Residence in Rurual   \n",
       "9        citizenship                        Citizenship Status   \n",
       "\n",
       "   varname_in_raw                   domain           available_waves  \\\n",
       "0             NaN                   Others                       [0]   \n",
       "1             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "2             NaN              Demographic                       [0]   \n",
       "3             NaN              Demographic                       [0]   \n",
       "4             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "5             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "6             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "7             NaN  Adulthood Socioeconomic                       [0]   \n",
       "8             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "9             NaN              Demographic                       [0]   \n",
       "\n",
       "    recode_type reverse_code maximum_missing_response  \\\n",
       "0    direct_use        False                     None   \n",
       "1    direct_use        False                     None   \n",
       "2  replace_only        False                     None   \n",
       "3  replace_only        False                     None   \n",
       "4    historical        False                     None   \n",
       "5    direct_use        False                     None   \n",
       "6  replace_only        False                     None   \n",
       "7  replace_only         True                     None   \n",
       "8  replace_only        False                     None   \n",
       "9  replace_only        False                     None   \n",
       "\n",
       "                                        replace_dict standardise  \\\n",
       "0                                               None       False   \n",
       "1                                               None        True   \n",
       "2           {'1.man': 1, '2.woman': -1, 'nan': None}        True   \n",
       "3  {'1.in country': -1, '0.out of country': 1, 'n...        True   \n",
       "4                                               None        True   \n",
       "5                                               None        True   \n",
       "6                                               None        True   \n",
       "7  {'1.Primary education': 1, '3.Upper secondary ...        True   \n",
       "8         {'1.rural': 1, '0.urban': -1, 'nan': None}        True   \n",
       "9              {'0.No': -1, '1.Yes': 1, 'nan': None}        True   \n",
       "\n",
       "                                               notes recode_date  \\\n",
       "0                                               None  2023-01-10   \n",
       "1                                               None  2023-01-10   \n",
       "2                                               None  2023-01-10   \n",
       "3                       Born in Country of Interview  2023-01-10   \n",
       "4                                               None  2023-01-10   \n",
       "5                                               None  2023-01-10   \n",
       "6                                               None  2023-01-10   \n",
       "7  not same as HRS, we use the ISCED 2 code for e...  2023-01-10   \n",
       "8                                   1:rural;-1:urban  2023-01-10   \n",
       "9              whether citizen at baseline interview  2023-01-10   \n",
       "\n",
       "                                             var_set in_ELSA in_HRS  \\\n",
       "0                                          [radyear]    True   True   \n",
       "1                                           [r8agey]    True   True   \n",
       "2                                         [ragender]    True   True   \n",
       "3                                       [rabcountry]    True   True   \n",
       "4  [r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...    True   True   \n",
       "5                                         [r1mcurln]   False  False   \n",
       "6                                          [r8mstat]    True  False   \n",
       "7                                        [raedisced]    True   True   \n",
       "8                                          [h8rural]   False  False   \n",
       "9                                        [racitizen]   False  False   \n",
       "\n",
       "  wave_controller  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4     latest_wave  \n",
       "5     latest_wave  \n",
       "6     latest_wave  \n",
       "7     latest_wave  \n",
       "8     latest_wave  \n",
       "9     single_wave  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname='citizenship'\n",
    "var_set=['racitizen']\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': {'0.No': -1, '1.Yes': 1, 'nan': None},\n",
    " 'notes': 'whether citizen at baseline interview',\n",
    " 'conventional_name': 'Citizenship Status',\n",
    " 'domain': 'Demographic',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'recode_type': 'replace_only',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': False,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='citizenship'\n",
    "var_set=['racitizen']\n",
    "available_waves= [0]\n",
    "replace_dict=  None\n",
    "notes='whether citizen at baseline interview' \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [0.No] with int .. (999 -> none)-1\n",
      "replace response [1.Yes] with int .. (999 -> none)1\n",
      "\n",
      "1.the replace dict is \n",
      "{'0.No': -1, '1.Yes': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'citizenship', 'conventional_name': 'Citizenship Status', 'varname_in_raw': nan, 'domain': 'Demographic', 'available_waves': [0], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': 'whether citizen at baseline interview', 'recode_date': '2023-01-10', 'var_set': ['racitizen'], 'in_ELSA': False, 'in_HRS': False}\n",
      "\n",
      "3. statistics\n",
      " 1.0    133671\n",
      "-1.0      4994\n",
      "Name: citizenship, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname = 'citizenship'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region of Residence `rural`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "1.rural->1\n",
      "0.urban->-1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>conventional_name</th>\n",
       "      <th>varname_in_raw</th>\n",
       "      <th>domain</th>\n",
       "      <th>available_waves</th>\n",
       "      <th>recode_type</th>\n",
       "      <th>reverse_code</th>\n",
       "      <th>maximum_missing_response</th>\n",
       "      <th>replace_dict</th>\n",
       "      <th>standardise</th>\n",
       "      <th>notes</th>\n",
       "      <th>recode_date</th>\n",
       "      <th>var_set</th>\n",
       "      <th>in_ELSA</th>\n",
       "      <th>in_HRS</th>\n",
       "      <th>wave_controller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deathY</td>\n",
       "      <td>Death Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Others</td>\n",
       "      <td>[0]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[radyear]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>Age at Interview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8agey]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maleYN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.man': 1, '2.woman': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[ragender]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>migrantYN</td>\n",
       "      <td>Foreign Born</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.in country': -1, '0.out of country': 1, 'n...</td>\n",
       "      <td>True</td>\n",
       "      <td>Born in Country of Interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[rabcountry]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>citizenship</td>\n",
       "      <td>Citizenship Status</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>whether citizen at baseline interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[racitizen]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>everunemployed</td>\n",
       "      <td>History of Unemployment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lencurmarridge</td>\n",
       "      <td>length of current marriage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1mcurln]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>currentpaternered</td>\n",
       "      <td>Current Marital Status: With Partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8mstat]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zeduccat</td>\n",
       "      <td>Lower Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.Primary education': 1, '3.Upper secondary ...</td>\n",
       "      <td>True</td>\n",
       "      <td>not same as HRS, we use the ISCED 2 code for e...</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[raedisced]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rural</td>\n",
       "      <td>Residence in Rurual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.rural': 1, '0.urban': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>1:rural;-1:urban</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[h8rural]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             varname                         conventional_name  \\\n",
       "0             deathY                                Death Year   \n",
       "1                age                          Age at Interview   \n",
       "2             maleYN                                      Male   \n",
       "3          migrantYN                              Foreign Born   \n",
       "4        citizenship                        Citizenship Status   \n",
       "5     everunemployed                   History of Unemployment   \n",
       "6     lencurmarridge                length of current marriage   \n",
       "7  currentpaternered  Current Marital Status: With Partnership   \n",
       "8           Zeduccat                           Lower Education   \n",
       "9              rural                       Residence in Rurual   \n",
       "\n",
       "   varname_in_raw                   domain           available_waves  \\\n",
       "0             NaN                   Others                       [0]   \n",
       "1             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "2             NaN              Demographic                       [0]   \n",
       "3             NaN              Demographic                       [0]   \n",
       "4             NaN              Demographic                       [0]   \n",
       "5             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "6             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "7             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "8             NaN  Adulthood Socioeconomic                       [0]   \n",
       "9             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "\n",
       "    recode_type reverse_code maximum_missing_response  \\\n",
       "0    direct_use        False                     None   \n",
       "1    direct_use        False                     None   \n",
       "2  replace_only        False                     None   \n",
       "3  replace_only        False                     None   \n",
       "4  replace_only        False                     None   \n",
       "5    historical        False                     None   \n",
       "6    direct_use        False                     None   \n",
       "7  replace_only        False                     None   \n",
       "8  replace_only         True                     None   \n",
       "9  replace_only        False                     None   \n",
       "\n",
       "                                        replace_dict standardise  \\\n",
       "0                                               None       False   \n",
       "1                                               None        True   \n",
       "2           {'1.man': 1, '2.woman': -1, 'nan': None}        True   \n",
       "3  {'1.in country': -1, '0.out of country': 1, 'n...        True   \n",
       "4              {'0.No': -1, '1.Yes': 1, 'nan': None}        True   \n",
       "5                                               None        True   \n",
       "6                                               None        True   \n",
       "7                                               None        True   \n",
       "8  {'1.Primary education': 1, '3.Upper secondary ...        True   \n",
       "9         {'1.rural': 1, '0.urban': -1, 'nan': None}        True   \n",
       "\n",
       "                                               notes recode_date  \\\n",
       "0                                               None  2023-01-10   \n",
       "1                                               None  2023-01-10   \n",
       "2                                               None  2023-01-10   \n",
       "3                       Born in Country of Interview  2023-01-10   \n",
       "4              whether citizen at baseline interview  2023-01-10   \n",
       "5                                               None  2023-01-10   \n",
       "6                                               None  2023-01-10   \n",
       "7                                               None  2023-01-10   \n",
       "8  not same as HRS, we use the ISCED 2 code for e...  2023-01-10   \n",
       "9                                   1:rural;-1:urban  2023-01-10   \n",
       "\n",
       "                                             var_set in_ELSA in_HRS  \\\n",
       "0                                          [radyear]    True   True   \n",
       "1                                           [r8agey]    True   True   \n",
       "2                                         [ragender]    True   True   \n",
       "3                                       [rabcountry]    True   True   \n",
       "4                                        [racitizen]   False  False   \n",
       "5  [r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...    True   True   \n",
       "6                                         [r1mcurln]   False  False   \n",
       "7                                          [r8mstat]    True  False   \n",
       "8                                        [raedisced]    True   True   \n",
       "9                                          [h8rural]   False  False   \n",
       "\n",
       "  wave_controller  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "5     latest_wave  \n",
       "6     latest_wave  \n",
       "7     latest_wave  \n",
       "8     latest_wave  \n",
       "9     latest_wave  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname='rural'\n",
    "var_set=['h1rural'.replace('1',latest_wave)]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'1.rural': 1, '0.urban': -1, 'nan': None},\n",
    " 'notes': '1:rural;-1:urban',\n",
    " 'conventional_name': 'Residence in Rurual',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'domain': 'Demographic',\n",
    " 'recode_type': 'replace_only',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': False,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-10'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "varname='rural'\n",
    "var_set=['h1rural'.replace('1',latest_wave)]\n",
    "available_waves= list(range(1,9))\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [1.rural] with int .. (999 -> none)1\n",
      "replace response [0.urban] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.rural': 1, '0.urban': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'rural', 'conventional_name': 'Residence in Rurual', 'varname_in_raw': nan, 'domain': 'Demographic', 'available_waves': [1, 2, 3, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': None, 'recode_date': '2023-01-10', 'var_set': ['h8rural'], 'in_ELSA': False, 'in_HRS': False}\n",
      "\n",
      "3. statistics\n",
      "-1.0    29359\n",
      " 1.0    15198\n",
      "Name: rural, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname = 'rural'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adulthood Socioeconomic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wealth `ZwealthT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='ZwealthT'\n",
    "var_set=['h1atotb'.replace('1',latest_wave)]\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Wealth',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'direct_use',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-12'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='ZwealthT'\n",
    "var_set=['h1atotb'.replace('1',latest_wave)]\n",
    "available_waves= list(range(1,9))\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4.659400e+04\n",
      "mean     3.061818e+05\n",
      "std      1.481495e+06\n",
      "min     -1.138827e+06\n",
      "25%      3.700000e+04\n",
      "50%      1.230000e+05\n",
      "75%      3.270000e+05\n",
      "max      2.067499e+08\n",
      "Name: ZwealthT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "varname='ZwealthT'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income `ZincomeT`\n",
    "\n",
    "special recoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='ZincomeT'\n",
    "var_set=['r1itearn','r1itsemp', 'r1itpena', 'r1itpubpen', 'r1itgxfr', 'r1itothr']\n",
    "var_set=[x.replace('1',latest_wave) for x in var_set]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [ 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': '(after tax) adding together Individual Earnings, Employer Capital Income, Pension or Annuity,Public Pensions,Other Government Transfers,Other Individual Income',\n",
    " 'conventional_name': 'Total Income',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'special_code',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-12'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='ZincomeT'\n",
    "var_set=['r1iearn, r1ipena, r1ipubpen, r1igxfr, r1iothr']\n",
    "var_set=[x.replace('1',latest_wave) for x in var_set]\n",
    "available_waves= list(range(1,9))\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.396200e+05\n",
       "mean     5.082528e+03\n",
       "std      2.184080e+04\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      0.000000e+00\n",
       "75%      4.236578e+03\n",
       "max      5.889591e+06\n",
       "Name: ZincomeT, dtype: float64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname='ZincomeT'\n",
    "var_dict=df_recode_record.loc[df_recode_record['varname']==varname,:].to_dict('records')[0]\n",
    "\n",
    "var_set=var_dict['var_set']\n",
    "temp = data[var_set].fillna(0)\n",
    "df[varname]=temp.apply(sum,axis=1)\n",
    "df[varname].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Household Income (Respondent & Spouse) `HIncome`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='HIncome'\n",
    "var_set=['h2ittot'.replace('2',latest_wave)]\n",
    "\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Total Household Income',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'direct_use',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': False,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-12'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='HIncome'\n",
    "var_set=['h2ittot'.replace('2',latest_wave)]\n",
    "\n",
    "available_waves= [2,4,5,6,7,8]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4.285400e+04\n",
      "mean     2.509210e+04\n",
      "std      4.551648e+04\n",
      "min      0.000000e+00\n",
      "25%      7.131789e+03\n",
      "50%      1.467293e+04\n",
      "75%      3.056559e+04\n",
      "max      5.889635e+06\n",
      "Name: HIncome, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "varname='HIncome'\n",
    "df,df_recode_record = recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education `Zeduccat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "1.Primary education->1\n",
      "3.Upper secondary education->3\n",
      "2.Lower secondary education->2\n",
      "5.First stage of tertiary education->5\n",
      "0.None->None\n",
      "6.Second stage of tertiary education->6\n",
      "4.Post-secondary non tertiary education->4\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    }
   ],
   "source": [
    "varname='Zeduccat'\n",
    "var_set=['raedisced']\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': {'1.Primary education': 1, \n",
    "                  '3.Upper secondary education': 3, \n",
    "                  '2.Lower secondary education': 2, \n",
    "                  '5.First stage of tertiary education': 5, \n",
    "                  '0.None': None, \n",
    "                  '6.Second stage of tertiary education': 6, \n",
    "                  '4.Post-secondary non tertiary education': 4, \n",
    "                  'nan': None},\n",
    " 'notes': \"not same as HRS, we use the ISCED 2 code for education category\",\n",
    " 'conventional_name': 'Lower Education',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'recode_type': 'replace_only',\n",
    " 'reverse_code': True,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS':True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.the replace dict is \n",
      "{'1.Primary education': 1, '3.Upper secondary education': 3, '2.Lower secondary education': 2, '5.First stage of tertiary education': 5, '0.None': None, '6.Second stage of tertiary education': 6, '4.Post-secondary non tertiary education': 4, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'Zeduccat', 'conventional_name': 'Lower Education', 'varname_in_raw': nan, 'domain': 'Adulthood Socioeconomic', 'available_waves': [0], 'recode_type': 'replace_only', 'reverse_code': True, 'maximum_missing_response': None, 'replace_dict': {'1.Primary education': 1, '3.Upper secondary education': 3, '2.Lower secondary education': 2, '5.First stage of tertiary education': 5, '0.None': None, '6.Second stage of tertiary education': 6, '4.Post-secondary non tertiary education': 4, 'nan': None}, 'standardise': True, 'notes': 'not same as HRS, we use the ISCED 2 code for education category', 'recode_date': '2023-01-10', 'var_set': ['raedisced']}\n",
      "\n",
      "3. statistics\n",
      "4.0    46941\n",
      "2.0    27578\n",
      "5.0    25455\n",
      "6.0    25082\n",
      "3.0     6080\n",
      "1.0      980\n",
      "Name: Zeduccat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='Zeduccat'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Marital Status: With Partnership `currentpaternered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='currentpaternered'\n",
    "var_set=['r1mstat'.replace('1',latest_wave)]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Current Marital Status: With Partnership',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'recode_type': 'replace_only',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': False,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='currentpaternered'\n",
    "var_set=['r1mstat'.replace('1',latest_wave)]\n",
    "available_waves= list(range(1,9))\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [5.divorced] with int .. (999 -> none)-1\n",
      "replace response [4.separated] with int .. (999 -> none)-1\n",
      "replace response [1.married] with int .. (999 -> none)1\n",
      "replace response [3.partnered] with int .. (999 -> none)1\n",
      "replace response [7.widowed] with int .. (999 -> none)-1\n",
      "replace response [8.never married] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'5.divorced': -1, '4.separated': -1, '1.married': 1, '3.partnered': 1, '7.widowed': -1, '8.never married': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'currentpaternered', 'conventional_name': 'Current Marital Status: With Partnership', 'varname_in_raw': nan, 'domain': 'Adulthood Socioeconomic', 'available_waves': [1, 2, 3, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': None, 'recode_date': '2023-01-10', 'var_set': ['r8mstat'], 'in_ELSA': True, 'in_HRS': False}\n",
      "\n",
      "3. statistics\n",
      " 1.0    33426\n",
      "-1.0    13274\n",
      "Name: currentpaternered, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='currentpaternered'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## length of current marriage `lencurmarridge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='lencurmarridge'\n",
    "var_set=['r1mcurln'.replace('8',latest_wave)]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'length of current marriage',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'recode_type': 'direct_use',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': False,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='lencurmarridge'\n",
    "var_set=['r1mcurln'.replace('8',latest_wave)]\n",
    "available_waves= list(range(1,9))\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    21710.000000\n",
      "mean        35.903685\n",
      "std         11.649478\n",
      "min          0.000000\n",
      "25%         29.000000\n",
      "50%         36.000000\n",
      "75%         44.000000\n",
      "max         85.000000\n",
      "Name: lencurmarridge, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "varname='lencurmarridge'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History of Unemployment `everunemployed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='everunemployed'\n",
    "var_set=['r{}unemp'.format(str(x)) for x in [1, 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'0.No': -1, '1.Yes': 1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'History of Unemployment',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'historical',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='everunemployed'\n",
    "var_set=['r{}unemp'.format(str(x)) for x in range(1,int(latest_wave)+1)]\n",
    "available_waves= list(range(1,9))\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.the replace dict is \n",
      "{'0.No': -1, '1.Yes': 1, 'nan': None}\n",
      "-1    132195\n",
      " 1      7425\n",
      "Name: everunemployed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='everunemployed'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History of Renting  `everrent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='everrent'\n",
    "var_set=['r{}hownrnt'.format(str(x)) for x in  [1, 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'3.other arrangements': -1, '2.rents home': 1, '1.owns home': -1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'History Of Renting',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'historical',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='everrent'\n",
    "var_set=['r{}hownrnt'.format(str(x)) for x in  [1, 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "available_waves=  [1, 2, 4, 5, 6, 7, 8]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [3.other arrangements] with int .. (999 -> none)-1\n",
      "replace response [2.rents home] with int .. (999 -> none)1\n",
      "replace response [1.owns home] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'3.other arrangements': -1, '2.rents home': 1, '1.owns home': -1, 'nan': None}\n",
      "-1    120718\n",
      " 1     18902\n",
      "Name: everrent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='everrent'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History of Financial Difficulties `everfindiff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "1.yes->1\n",
      "0.no->-1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    }
   ],
   "source": [
    "varname='everfindiff' \n",
    "var_set=['r{}sfnhe'.format(str(x)) for x in [3,7]]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [3, 7],\n",
    " 'replace_dict': {'1.yes': 1, '0.no': -1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'History of Financial Difficulties',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'historical',\n",
    " 'wave_controller': 'financial_difficulties_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-11'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='everfindiff' \n",
    "var_set=['r{}sfnhe'.format(str(x)) for x in [3,7]]\n",
    "\n",
    "available_waves= [3,7] \n",
    "replace_dict= None \n",
    "notes=None\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes) \n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record) \n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [1.yes] with int .. (999 -> none)1\n",
      "replace response [0.no] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.yes': 1, '0.no': -1, 'nan': None}\n",
      "-1    111889\n",
      " 1     27731\n",
      "Name: everfindiff, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='everfindiff'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History of Divorce `everdivorced`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "varname='everdivorced' \n",
    "var_set=['r{}mstat'.format(str(x)) for x in [1, 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'7.widowed': -1, '1.married': -1, '8.never married': -1, '3.partnered': -1, '5.divorced': 1, '4.separated': 1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'History Of Divorce',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'historical',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-11'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "varname='everdivorced' \n",
    "var_set=['r{}mstat'.format(str(x)) for x in [1, 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "available_waves= [1, 2, 4, 5, 6, 7, 8]\n",
    "replace_dict= None \n",
    "notes=None\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes) \n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record) \n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [7.widowed] with int .. (999 -> none)-1\n",
      "replace response [1.married] with int .. (999 -> none)-1\n",
      "replace response [8.never married] with int .. (999 -> none)-1\n",
      "replace response [3.partnered] with int .. (999 -> none)-1\n",
      "replace response [5.divorced] with int .. (999 -> none)1\n",
      "replace response [4.separated] with int .. (999 -> none)1\n",
      "\n",
      "1.the replace dict is \n",
      "{'7.widowed': -1, '1.married': -1, '8.never married': -1, '3.partnered': -1, '5.divorced': 1, '4.separated': 1, 'nan': None}\n",
      "-1    129122\n",
      " 1     10498\n",
      "Name: everdivorced, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='everdivorced'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Never Married `nevermarried`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='nevermarried' \n",
    "var_set=['r{}mstat'.format(latest_wave)]\n",
    "\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'7.widowed': -1, '1.married': -1, '8.never married': 1, '3.partnered': -1, '5.divorced': -1, '4.separated': -1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Never Married',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-11'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='nevermarried' \n",
    "var_set=['r{}mstat'.format(latest_wave)]\n",
    "\n",
    "available_waves= [1, 2, 4, 5, 6, 7, 8]\n",
    "replace_dict= None \n",
    "notes=None\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes) \n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record) \n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [7.widowed] with int .. (999 -> none)-1\n",
      "replace response [1.married] with int .. (999 -> none)-1\n",
      "replace response [8.never married] with int .. (999 -> none)1\n",
      "replace response [3.partnered] with int .. (999 -> none)-1\n",
      "replace response [5.divorced] with int .. (999 -> none)-1\n",
      "replace response [4.separated] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'7.widowed': -1, '1.married': -1, '8.never married': 1, '3.partnered': -1, '5.divorced': -1, '4.separated': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'nevermarried', 'conventional_name': 'Never Married', 'varname_in_raw': nan, 'domain': 'Adulthood Socioeconomic', 'available_waves': [1, 2, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': None, 'recode_date': '2023-01-11', 'var_set': ['r8mstat'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1.0    44889\n",
      " 1.0     1811\n",
      "Name: nevermarried, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='nevermarried'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adulthood Health Behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low/No Vigorous Activity `vigactivityYN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "3.1 per week->-1\n",
      "4.1-3 per mon->1\n",
      "2.> 1 per week->-1\n",
      "5.hardly ever or never->1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    }
   ],
   "source": [
    "varname='vigactivityYN'\n",
    "var_set=['r{}vgactx'.format(latest_wave)]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None},\n",
    " 'notes': '>=1 times/week, -1',\n",
    " 'conventional_name': 'Low/No Vigorous Activity',\n",
    " 'domain': 'Adulthood Health Behaviors',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='vigactivityYN'\n",
    "var_set=['r{}vgactx'.format(str(x)) for x in  [1, 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "available_waves=  [1, 2, 4, 5, 6, 7, 8]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [3.1 per week] with int .. (999 -> none)-1\n",
      "replace response [4.1-3 per mon] with int .. (999 -> none)1\n",
      "replace response [2.> 1 per week] with int .. (999 -> none)-1\n",
      "replace response [5.hardly ever or never] with int .. (999 -> none)1\n",
      "\n",
      "1.the replace dict is \n",
      "{'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'vigactivityYN', 'conventional_name': 'Low/No Vigorous Activity', 'varname_in_raw': nan, 'domain': 'Adulthood Health Behaviors', 'available_waves': [1, 2, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': None, 'recode_date': '2023-01-10', 'var_set': ['r8vgactx'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      " 1.0    25620\n",
      "-1.0    20965\n",
      "Name: vigactivityYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='vigactivityYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low/No Moderate Activity `modactivityYN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='modactivityYN'\n",
    "var_set=['r{}mdactx'.format(latest_wave)]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None},\n",
    " 'notes': '>=1 times/week, -1',\n",
    " 'conventional_name': 'Low/No Moderate Activity',\n",
    " 'domain': 'Adulthood Health Behaviors',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.the replace dict is \n",
      "{'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'modactivityYN', 'conventional_name': 'Low/No Moderate Activity', 'varname_in_raw': nan, 'domain': 'Adulthood Health Behaviors', 'available_waves': [1, 2, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': {'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None}, 'standardise': True, 'notes': '>=1 times/week, -1', 'recode_date': '2023-01-10', 'var_set': ['r8mdactx'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1.0    36372\n",
      " 1.0    10230\n",
      "Name: modactivityYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='modactivityYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alcohol Abuse `alcoholYN`\n",
    "\n",
    "Share also have vars indicating the binge drunk frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='alcoholYN'\n",
    "var_set=['r{}drinkb'.format(latest_wave)]\n",
    "\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Directly using the definition of binge drunk from SHARE',\n",
    " 'conventional_name': 'Alcohol Abuse',\n",
    " 'domain': 'Adulthood Health Behaviors',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='alcoholYN'\n",
    "var_set=['r{}drinkb'.format(latest_wave)]\n",
    "\n",
    "available_waves=  [ 2, 4, 5, 6, 7, 8]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [1.yes] with int .. (999 -> none)1\n",
      "replace response [0.no] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.yes': 1, '0.no': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'alcoholYN', 'conventional_name': 'Alcohol Abuse', 'varname_in_raw': nan, 'domain': 'Adulthood Health Behaviors', 'available_waves': [2, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': 'Directly using the definition of binge drunk from SHARE', 'recode_date': '2023-01-10', 'var_set': ['r8drinkb'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1.0    37046\n",
      " 1.0     9514\n",
      "Name: alcoholYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='alcoholYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History of drink `everalcoholYN`\n",
    "\n",
    "they also have var `r1drinkxw`:w1 R drinks alcohol weekly which has information from all waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "varname = 'everalcoholYN'\n",
    "var_set = ['r{}drinkev'.format(str(x)) for x in drink_wave]\n",
    "\n",
    "new_row = {'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [2, 4, 5],\n",
    " 'replace_dict': {'1.yes': 1, '0.no': -1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'History of drink',\n",
    " 'domain': 'Adulthood Health Behaviors',\n",
    " 'recode_type': 'historical',\n",
    " 'wave_controller': 'drink_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': False,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'everalcoholYN'\n",
    "var_set = ['r{}drinkev'.format(str(x)) for x in [2,4,5]]\n",
    "\n",
    "available_waves =  [2,4,5]\n",
    "replace_dict =  None\n",
    "notes = None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [1.yes] with int .. (999 -> none)1\n",
      "replace response [0.no] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.yes': 1, '0.no': -1, 'nan': None}\n",
      " 1    84616\n",
      "-1    55004\n",
      "Name: everalcoholYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='everalcoholYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History of Smoking  `eversmokeYN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='eversmokeYN'\n",
    "var_set=['r{}smokev'.format(str(x)) for x in [1 , 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'History of Smoking',\n",
    " 'domain': 'Adulthood Health Behaviors',\n",
    " 'recode_type': 'historical',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'eversmokeYN'\n",
    "var_set = ['r{}smokev'.format(str(x)) for x in [1 , 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "available_waves =  [1,2,4,5,6,7,8]\n",
    "replace_dict =  None\n",
    "notes = None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [0.No] with int .. (999 -> none)-1\n",
      "replace response [1.Yes] with int .. (999 -> none)1\n",
      "\n",
      "1.the replace dict is \n",
      "{'0.No': -1, '1.Yes': 1, 'nan': None}\n",
      "-1    77943\n",
      " 1    61677\n",
      "Name: eversmokeYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='eversmokeYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Smoker `currsmokeYN`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "0.No->-1\n",
      "1.Yes->1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    }
   ],
   "source": [
    "varname='currsmokeYN'\n",
    "var_set=['r{}smokev'.format(latest_wave)]\n",
    "\n",
    "new_row={'varname': 'currsmokeYN',\n",
    " 'var_set': ['r8smokev'],\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'0.No': -1, '1.Yes': 1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Current Smoker',\n",
    " 'domain': 'Adulthood Health Behaviors',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='currsmokeYN'\n",
    "var_set=['r{}smokev'.format(latest_wave)]\n",
    "\n",
    "\n",
    "available_waves=  [1, 2, 4, 5, 6, 7, 8]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [0.No] with int .. (999 -> none)-1\n",
      "replace response [1.Yes] with int .. (999 -> none)1\n",
      "\n",
      "1.the replace dict is \n",
      "{'0.No': -1, '1.Yes': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'currsmokeYN', 'conventional_name': 'Current Smoker', 'varname_in_raw': nan, 'domain': 'Adulthood Health Behaviors', 'available_waves': [1, 2, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': None, 'recode_date': '2023-01-10', 'var_set': ['r8smokev'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1.0    27553\n",
      " 1.0    19152\n",
      "Name: currsmokeYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='currsmokeYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sleep Problems `sleepYN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latest_wave' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_9313/2060109570.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mvarname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'sleepYN'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mvar_set\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'r{}sleep'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlatest_wave\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m new_row={'varname': varname,\n",
      "\u001B[0;31mNameError\u001B[0m: name 'latest_wave' is not defined"
     ]
    }
   ],
   "source": [
    "varname='sleepYN'\n",
    "var_set=['r{}sleep'.format(latest_wave)]\n",
    "\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'1.yes': 1, '0.no': -1, 'nan': None},\n",
    " 'notes': \"r been asked have you have trouble recently in sleeping\",\n",
    " 'conventional_name': 'Sleep Problems',\n",
    " 'domain': 'Adulthood Health Behaviors',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-11'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "available_waves=  [1, 2, 4, 5, 6, 7, 8]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [1.yes] with int .. (999 -> none)1\n",
      "replace response [0.no] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.yes': 1, '0.no': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'sleepYN', 'conventional_name': 'Sleep Problems', 'varname_in_raw': nan, 'domain': 'Adulthood Health Behaviors', 'available_waves': [1, 2, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': 'r been asked have you have trouble recently in sleeping', 'recode_date': '2023-01-11', 'var_set': ['r8sleep'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1.0    28982\n",
      " 1.0    16786\n",
      "Name: sleepYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='sleepYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Childhood Adversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# racsevent_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Childhood stressful events  `chilstrevents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='chilstrevents'\n",
    "var_set=['racsevent_s']\n",
    "\n",
    "new_row={'varname':varname,\n",
    " 'var_set':var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Sum of Childhood Stressful Events',\n",
    " 'domain': 'Childhood Adversity',\n",
    " 'recode_type': 'direct_use',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': False,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-11'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='chilstrevents'\n",
    "var_set=['racsevent_s']\n",
    "\n",
    "\n",
    "available_waves=  [0]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='chilstrevents'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maternal Education `Zmotherseduc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "6.Second stage of tertiary education->6\n",
      "2.Lower secondary education->2\n",
      "1.Primary education->1\n",
      "3.Upper secondary education->3\n",
      "0.None->None\n",
      "5.First stage of tertiary education->5\n",
      "4.Post-secondary non tertiary education->4\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    }
   ],
   "source": [
    "varname='Zmotherseduc'\n",
    "var_set=['ramomedisced']\n",
    "\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': {'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None},\n",
    " 'notes': 'isced standard',\n",
    " 'conventional_name': 'Lower Maternal Education',\n",
    " 'domain': 'Childhood Adversity',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'reverse_code': True,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-11'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='Zmotherseduc'\n",
    "var_set=['ramomedisced']\n",
    "\n",
    "\n",
    "available_waves=  [0]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [6.Second stage of tertiary education] with int .. (999 -> none)6\n",
      "replace response [2.Lower secondary education] with int .. (999 -> none)2\n",
      "replace response [1.Primary education] with int .. (999 -> none)1\n",
      "replace response [3.Upper secondary education] with int .. (999 -> none)3\n",
      "replace response [0.None] with int .. (999 -> none)999\n",
      "replace response [5.First stage of tertiary education] with int .. (999 -> none)5\n",
      "replace response [4.Post-secondary non tertiary education] with int .. (999 -> none)4\n",
      "\n",
      "1.the replace dict is \n",
      "{'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'Zmotherseduc', 'conventional_name': 'Maternal Education', 'varname_in_raw': nan, 'domain': 'Childhood Adversity', 'available_waves': [0], 'recode_type': 'replace_only', 'reverse_code': True, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': 'isced standard', 'recode_date': '2023-01-11', 'var_set': ['ramomedisced'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'single_wave'}\n",
      "\n",
      "3. statistics\n",
      "6.0    28811\n",
      "5.0    19041\n",
      "4.0    12686\n",
      "2.0     3460\n",
      "3.0      867\n",
      "1.0       74\n",
      "Name: Zmotherseduc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='Zmotherseduc'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paternal Education `Zfatherseduc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "6.Second stage of tertiary education->6\n",
      "2.Lower secondary education->2\n",
      "1.Primary education->1\n",
      "3.Upper secondary education->3\n",
      "0.None->None\n",
      "5.First stage of tertiary education->5\n",
      "4.Post-secondary non tertiary education->4\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    }
   ],
   "source": [
    "\n",
    "varname='Zfatherseduc'\n",
    "var_set=['radadedisced']\n",
    "\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': {'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None},\n",
    " 'notes': 'isced standard',\n",
    " 'conventional_name': 'Lower Paternal Education',\n",
    " 'domain': 'Childhood Adversity',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'reverse_code': True,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-11'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='Zfatherseduc'\n",
    "var_set=['radadedisced']\n",
    "\n",
    "\n",
    "available_waves =  [0]\n",
    "replace_dict =  None\n",
    "notes=None \n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [6.Second stage of tertiary education] with int .. (999 -> none)6\n",
      "replace response [2.Lower secondary education] with int .. (999 -> none)2\n",
      "replace response [1.Primary education] with int .. (999 -> none)1\n",
      "replace response [3.Upper secondary education] with int .. (999 -> none)3\n",
      "replace response [0.None] with int .. (999 -> none)999\n",
      "replace response [5.First stage of tertiary education] with int .. (999 -> none)5\n",
      "replace response [4.Post-secondary non tertiary education] with int .. (999 -> none)4\n",
      "\n",
      "1.the replace dict is \n",
      "{'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'Zfatherseduc', 'conventional_name': 'Lower Paternal Education', 'varname_in_raw': nan, 'domain': 'Childhood Adversity', 'available_waves': [0], 'recode_type': 'replace_only', 'reverse_code': True, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': 'isced code', 'recode_date': '2023-01-11', 'var_set': ['radadedisced'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'single_wave'}\n",
      "\n",
      "3. statistics\n",
      "6.0    24435\n",
      "4.0    19622\n",
      "5.0    13075\n",
      "2.0     7116\n",
      "3.0     1285\n",
      "1.0      504\n",
      "Name: Zfatherseduc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='Zfatherseduc'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Father Occupational Status  `fathersocc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "7.Craft or related trades worker->5\n",
      "6.Skilled agricultural or fishery worker->5\n",
      "11.Spontaneous only: there was no main breadwinner->None\n",
      "2.Professional->2\n",
      "9.Elementary occupation->6\n",
      "10.Armed forces->4\n",
      "4.Clerk->3\n",
      "8.Plant/machine operator or assembler->6\n",
      "5.Service, shop or market sales worker->3\n",
      "3.Technician or associate professional->2\n",
      "1.Legislator, senior official or manager->1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    }
   ],
   "source": [
    "varname='fathersocc'\n",
    "var_set=['ramaoccup']\n",
    "\n",
    "new_row = {'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': {'7.Craft or related trades worker': 5, '6.Skilled agricultural or fishery worker': 5, '11.Spontaneous only: there was no main breadwinner': None, '2.Professional': 2, '9.Elementary occupation': 6, '10.Armed forces': 4, '4.Clerk': 3, '8.Plant/machine operator or assembler': 6, '5.Service, shop or market sales worker': 3, '3.Technician or associate professional': 2, '1.Legislator, senior official or manager': 1, 'nan': None},\n",
    " 'notes': 'not just for father, but the main carer',\n",
    " 'conventional_name': 'Lower Main Carer Occupational Status',\n",
    " 'domain': 'Childhood Adversity',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-11'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='fathersocc'\n",
    "var_set=['radadoccup']\n",
    "\n",
    "\n",
    "available_waves=  [0]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [7.Craft or related trades worker] with int .. (999 -> none)5\n",
      "replace response [6.Skilled agricultural or fishery worker] with int .. (999 -> none)5\n",
      "replace response [11.Spontaneous only: there was no main breadwinner] with int .. (999 -> none)999\n",
      "replace response [2.Professional] with int .. (999 -> none)2\n",
      "replace response [9.Elementary occupation] with int .. (999 -> none)6\n",
      "replace response [10.Armed forces] with int .. (999 -> none)4\n",
      "replace response [4.Clerk] with int .. (999 -> none)3\n",
      "replace response [8.Plant/machine operator or assembler] with int .. (999 -> none)6\n",
      "replace response [5.Service, shop or market sales worker] with int .. (999 -> none)3\n",
      "replace response [3.Technician or associate professional] with int .. (999 -> none)2\n",
      "replace response [1.Legislator, senior official or manager] with int .. (999 -> none)1\n",
      "\n",
      "1.the replace dict is \n",
      "{'7.Craft or related trades worker': 5, '6.Skilled agricultural or fishery worker': 5, '11.Spontaneous only: there was no main breadwinner': None, '2.Professional': 2, '9.Elementary occupation': 6, '10.Armed forces': 4, '4.Clerk': 3, '8.Plant/machine operator or assembler': 6, '5.Service, shop or market sales worker': 3, '3.Technician or associate professional': 2, '1.Legislator, senior official or manager': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'fathersocc', 'conventional_name': 'Lower Main Carer Occupational Status', 'varname_in_raw': nan, 'domain': 'Childhood Adversity', 'available_waves': [0], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': 'not just for father, but the main carer', 'recode_date': '2023-01-11', 'var_set': ['ramaoccup'], 'in_ELSA': False, 'in_HRS': True, 'wave_controller': 'single_wave'}\n",
      "\n",
      "3. statistics\n",
      "5.0    35257\n",
      "6.0    15415\n",
      "2.0    10414\n",
      "3.0     9521\n",
      "1.0     4053\n",
      "4.0      435\n",
      "Name: fathersocc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='fathersocc'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adulthood Psychological "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loneliness `Zloneliness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname= 'Zloneliness'\n",
    "varset=['r4leftoutt', \n",
    "         'r4complac',\n",
    "         'r4leftout'] \n",
    "varset=[x.replace('4',latest_wave) for x in varset]\n",
    "\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': varset,\n",
    " 'available_waves': [4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'leftout has data from wave 1',\n",
    " 'conventional_name': 'Loneliness',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'multi_response',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': 2,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-11'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname= 'Zloneliness'\n",
    "varset=['r4leftoutt', \n",
    "         'r4complac',\n",
    "         'r4leftout'] \n",
    "varset=[x.replace('4',latest_wave) for x in varset]\n",
    "\n",
    "\n",
    "\n",
    "available_waves=  [4,5,6,7,8]\n",
    "replace_dict=  None\n",
    "notes = None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "want to check the missings ? 1/0 1\n",
      "0. missing information -------- start\n",
      "3    93858\n",
      "0    45347\n",
      "1      316\n",
      "2       99\n",
      "Name: missing_count, dtype: int64\n",
      "1. maximum_missing_response 2\n",
      "2. reverse_control False\n",
      "3. the replace dict is {'1.hardly ever or never': 1, '3.often': 3, '2.some of the time': 2}\n"
     ]
    }
   ],
   "source": [
    "varname= 'Zloneliness'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Life Satisfaction `Zlifesatis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname= 'Zlifesatis'\n",
    "varset=['r{}satlifez'.format(latest_wave)]\n",
    "\n",
    "\n",
    "new_row={'varname':varname,\n",
    " 'var_set': varset,\n",
    " 'available_waves': [2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'This is an one-question Z-score, different to the HRS definition',\n",
    " 'conventional_name': 'Life Satisfaction',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'direct_use',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-11'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname= 'Zlifesatis'\n",
    "varset=['r{}satlifez'.format(latest_wave)]\n",
    "\n",
    "\n",
    "available_waves=  [2,4,5,6,7,8]\n",
    "replace_dict=  None\n",
    "notes = \"This is a Z-score, different to the HRS definition\" \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4.543600e+04\n",
      "mean     1.386655e-15\n",
      "std      1.000000e+00\n",
      "min     -4.601587e+00\n",
      "25%     -4.799497e-01\n",
      "50%      1.088556e-01\n",
      "75%      6.976609e-01\n",
      "max      1.286466e+00\n",
      "Name: Zlifesatis, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "varname= 'Zlifesatis'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Affect `Znegaffect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname= 'Znegaffect'\n",
    "varset=['r{}eurod'.format(latest_wave)]\n",
    "\n",
    "\n",
    "new_row={'varname':varname,\n",
    " 'var_set': varset,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Different to HRS, this is a depression indicative sum score',\n",
    " 'conventional_name': 'Depression Score',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'direct_use',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-11'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname= 'Znegaffect'\n",
    "varset=['r{}eurod'.format(latest_wave)]\n",
    "\n",
    "\n",
    "available_waves=  [1,2,4,5,6,7,8]\n",
    "replace_dict=  None\n",
    "notes = \"Different to HRS, this is a depression indicative sum score\" \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    46733.000000\n",
      "mean         2.448420\n",
      "std          2.263815\n",
      "min          0.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          4.000000\n",
      "max         12.000000\n",
      "Name: Znegaffect, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "varname= 'Znegaffect'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data Recode Zone\n",
    "\n",
    "we try to:\n",
    "\n",
    "1. put all recoded raw data in the df_raw_recoded, identified by the merged_id \n",
    "2. all infomations about recoding still stored in the df_recode_record \n",
    "3. column names are formatted as 'varname_wave'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_raw_recoded = pd.DataFrame()\n",
    "df_raw_recoded['mergeid']=df_temp['mergeid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vars left to be recoded:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Life Satisfaction',\n",
       " 'Religiousity',\n",
       " 'Perceived Constraints',\n",
       " 'Perceived Mastery',\n",
       " 'Trait Anxiety',\n",
       " 'Adult Psychosocial Adversity',\n",
       " 'Hopelessness',\n",
       " 'Loneliness',\n",
       " 'Agreeableness',\n",
       " 'Extroversion',\n",
       " 'Neuroticism',\n",
       " 'Openness',\n",
       " 'Conscientiousness',\n",
       " 'Pessimism',\n",
       " 'Optimism',\n",
       " 'Negative Affect',\n",
       " 'Positive Affect']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth',None)\n",
    "\n",
    "df_raw_recoded=pd.read_csv(share_path/'raw_recoded_data.csv')\n",
    "df_vars_found_in_raw=pd.read_csv(Path.cwd()/'vars_found_in_raw'/'SHARE.csv')\n",
    "\n",
    "lst_vars_found_in_raw=list(df_vars_found_in_raw['varname'].unique())\n",
    "lst_vars_not_recoded =[x for x in lst_vars_found_in_raw if not all(list(df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']=='Perceived Constraints','recoded'])) ]\n",
    "\n",
    "print(f'vars left to be recoded:')\n",
    "lst_vars_not_recoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def return_var_set_lst(record):\n",
    "    var_set_dict = {}\n",
    "    for index,row in record.iterrows():\n",
    "        var_set_dict[int(row['wave'])] = {row['file_name']:ast.literal_eval( row['var_set'])}\n",
    "    \n",
    "    return var_set_dict,list(var_set_dict.keys())\n",
    "\n",
    "def folder_name(latest_wave):\n",
    "    return f'sharew{latest_wave}_rel8-0-0_ALL_datasets_stata'\n",
    "\n",
    "def get_raw_info(row,latest_wave):\n",
    "    \"\"\"\n",
    "    return var_set and file_name from row and latest wave\n",
    "    \"\"\"\n",
    "    temp_lst = list(row['var_set'][0][latest_wave].items())[0]\n",
    "    var_set, file_name = temp_lst[1], temp_lst[0]\n",
    "    return var_set, file_name\n",
    "\n",
    "### replace functions ---------------------------\n",
    "def replace_procedure(sliced_data,file_name,latest_wave,row):\n",
    "    print('Replace Procedures start..\\n')\n",
    "    response_list = get_unique_valaues(sliced_data)\n",
    "    print(f'all responses are: {response_list}')\n",
    "\n",
    "    # check whether we have define it before \n",
    "    try:\n",
    "        replace_dict=row['replace_dict'][file_name]\n",
    "        print(f'we have found the dict for wave {latest_wave}:')\n",
    "        print(replace_dict)\n",
    "    except:\n",
    "        print(f'no replace_dict been found for wave {latest_wave}')\n",
    "    \n",
    "    if row['replace_dict']:\n",
    "        print(row['replace_dict'])\n",
    "        using_original_dict_control = input(f'here are the available dicts, do you wish to use? 1->yes 0->no')\n",
    "        if using_original_dict_control == '1':\n",
    "            key=input('type key of it')\n",
    "            row['replace_dict'][file_name] = row['replace_dict'][key]\n",
    "    \n",
    "    #new dict?\n",
    "    replace_control=input(f'do you wish to generate/re-define a replace_dict for wave {latest_wave}? 1->yes others->no')\n",
    "    if replace_control=='1':\n",
    "        row =raw_replace(row,file_name)\n",
    "    \n",
    "    #replace\n",
    "    replace_=input(f'do you wish to replace data in {latest_wave}? 1->yes others->no')\n",
    "    if replace_ =='1':\n",
    "        sliced_data = sliced_data.replace(row['replace_dict'][file_name])\n",
    "    print('Replace Procedures end..\\n')\n",
    "    return row,sliced_data\n",
    "\n",
    "def generate_replace_dict_for_historical_response_raw(sliced_row,sliced_data):\n",
    "    \"\"\"\n",
    "    for raw: generate the replace_dict if there is nothing in sliced_row['replace_dict']/returned object is not dict\n",
    "    difference with the original: we move the existence detection out the function\n",
    "    \"\"\"\n",
    " \n",
    "    replace_dict={}\n",
    "    response_list = get_unique_valaues(sliced_data)\n",
    "    for response in response_list:\n",
    "        Pass_control=True\n",
    "        while Pass_control:\n",
    "            replace_val=input(f'replace response [{response}] with int .. (999 -> none)')\n",
    "            try:\n",
    "                replace_val=int(replace_val)\n",
    "                Pass_control=False\n",
    "            except:\n",
    "                print('error in the response, please try again')\n",
    "\n",
    "        replace_dict[response]= None if replace_val==999 else replace_val \n",
    "\n",
    "    return replace_dict\n",
    "\n",
    "def raw_replace(row,file_name):\n",
    "    \"\"\"\n",
    "    replace the data using the row['replace_dict']\n",
    "    \"\"\"\n",
    "    # get the replace_dict by inputting or from df_recode_record\n",
    "    replace_dict=generate_replace_dict_for_historical_response_raw(row,sliced_data)\n",
    "    replace_dict['nan']=None\n",
    "    \n",
    "    if not row['replace_dict']:\n",
    "        row['replace_dict']={}\n",
    "    \n",
    "    row['replace_dict'][file_name]=replace_dict\n",
    "\n",
    "    return row\n",
    "\n",
    "### replace functions --------------------------- end\n",
    "\n",
    "def mark_df_vars_found_in_raw(varname_in_raw_recoder,latest_wave):\n",
    "    \"\"\"\n",
    "    mark the df_vars_found_in_raw for the 'recoded' column\n",
    "    \"\"\"\n",
    "    c1 = df_vars_found_in_raw['varname']==varname_in_raw_recoder\n",
    "    c2 = df_vars_found_in_raw['wave']==latest_wave\n",
    "    df_vars_found_in_raw.loc[c1 & c2,'recoded']=True\n",
    "    df_vars_found_in_raw.to_csv(Path.cwd()/'vars_found_in_raw'/'SHARE.csv',index=False)\n",
    "    \n",
    "def raw_save_each_var():\n",
    "    mark_df_vars_found_in_raw(varname_in_raw_recoder,latest_wave)\n",
    "    df_recode_record=add_row_to_df_record(row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceived Mastery `Zperceivedmastery`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Perceived Mastery</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['eg_G13']</td>\n",
       "      <td>{'eg_G13': 'Keeping under control'}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              varname  wave                     file_name     var_set  \\\n",
       "15  Perceived Mastery     8  sharew8_rel8-0-0_dropoff.dta  ['eg_G13']   \n",
       "\n",
       "                                  Notes  recoded  \n",
       "15  {'eg_G13': 'Keeping under control'}     True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 raw record\n",
    "varname_in_raw_recoder= 'Perceived Mastery'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 new record\n",
    "varname = 'Zperceivedmastery'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_8512/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "row={'varname': 'Zperceivedmastery',\n",
    " 'var_set': [{8: {'sharew8_rel8-0-0_dropoff.dta': ['eg_G13']}}],\n",
    " 'available_waves': [8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Lower Sense of Mastery',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'reverse_code': True,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}\n",
    "df_recode_record=add_row_to_df_record(row,df_recode_record) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rarely or never    359\n",
       "6.0                153\n",
       "5.0                 54\n",
       "4.0                 30\n",
       "3.0                 22\n",
       "Very often          17\n",
       "2.0                 13\n",
       "Name: eg_G13, dtype: int64"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_wave = 8\n",
    "#0. retreive data\n",
    "varname = row['varname']\n",
    "var_set, file_name = get_raw_info(row,latest_wave)\n",
    "df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "sliced_data = df_temp[var_set]\n",
    "df_temp = df_temp[['mergeid']]\n",
    "sliced_data[var_set[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#1. replace\n",
    "row,sliced_data = replace_procedure(sliced_data,file_name,latest_wave,row)\n",
    "\n",
    "#2. deal with maximum missing response\n",
    "if len(var_set)>1:\n",
    "    missing_count(sliced_data)\n",
    "    \n",
    "    if row['maximum_missing_response']:\n",
    "        print(f'the maximum missing response is {row[\"maximum_missing_response\"]}')\n",
    "    else:\n",
    "        missing_count_controller = int(input('please specify the missing count (999 is none)'))\n",
    "        row['maximum_missing_response']= missing_count_controller if not missing_count_controller==999 else None\n",
    "\n",
    "#3. deal with reverse_code\n",
    "print(f'the reverse code is {row[\"reverse_code\"]}')\n",
    "reverse_control = input('wish to redefine reverse_conde controller? 1->Change any.other->Not Change')\n",
    "row[\"reverse_code\"]= not row[\"reverse_code\"] if reverse_control=='1' else row[\"reverse_code\"]\n",
    "\n",
    "# reverse control\n",
    "if row[\"reverse_code\"]:\n",
    "    unique_vals = get_unique_valaues(sliced_data)\n",
    "    print(\"4. unique_vals are {}\".format(unique_vals))\n",
    "    replace_dict = generate_value_replace_dict(unique_vals)\n",
    "    print(\"5. dict is {}\".format(replace_dict))\n",
    "    sliced_data.replace(replace_dict,inplace=True)\n",
    "\n",
    "#categorical column pretreatment\n",
    "for column in sliced_data.columns:\n",
    "    if isinstance(sliced_data[column].dtype,pd.api.types.CategoricalDtype):\n",
    "        sliced_data[column]=np.asarray(sliced_data[column])\n",
    "# multiple response\n",
    "if len(var_set)==1:\n",
    "    df_temp[f'{varname}_{latest_wave}']=sliced_data[var_set[0]]\n",
    "else:    \n",
    "    df_temp[f'{varname}_{latest_wave}']=sliced_data.apply(average_response_by_row,axis=1,maximum_missing_response=row[\"maximum_missing_response\"])\n",
    "\n",
    "# savezone\n",
    "df_raw_recoded=pd.merge(left=df_raw_recoded,right=df_temp,on='mergeid',how='outer')\n",
    "mark_df_vars_found_in_raw(varname_in_raw_recoder,latest_wave)\n",
    "df_recode_record=add_row_to_df_record(row,df_recode_record)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0    359\n",
       "6.0    153\n",
       "5.0     54\n",
       "4.0     30\n",
       "3.0     22\n",
       "1.0     17\n",
       "2.0     13\n",
       "Name: Zperceivedmastery_8, dtype: int64"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_recoded[f'{varname}_{latest_wave}'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceived Constraints  `Zperceivedconstraints`\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>1</td>\n",
       "      <td>sharew1_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q2_b', 'q2_c']</td>\n",
       "      <td>{'q2_b': 'I feel that what happens to me is out of my control', 'q2_c': 'I feel left out of things'}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>2</td>\n",
       "      <td>sharew2_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac015_']</td>\n",
       "      <td>{'ac015_': 'Out of control'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>4</td>\n",
       "      <td>sharew4_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac015_']</td>\n",
       "      <td>{'ac015_': 'Out of control'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>5</td>\n",
       "      <td>sharew5_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac015_']</td>\n",
       "      <td>{'ac015_': 'Out of control'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>6</td>\n",
       "      <td>sharew6_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac015_']</td>\n",
       "      <td>{'ac015_': 'Out of control'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>7</td>\n",
       "      <td>sharew7_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac015_']</td>\n",
       "      <td>{'ac015_': 'Out of control'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac015_']</td>\n",
       "      <td>{'ac015_': 'Out of control'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  varname  wave                     file_name  \\\n",
       "8   Perceived Constraints     1  sharew1_rel8-0-0_dropoff.dta   \n",
       "9   Perceived Constraints     2       sharew2_rel8-0-0_ac.dta   \n",
       "10  Perceived Constraints     4       sharew4_rel8-0-0_ac.dta   \n",
       "11  Perceived Constraints     5       sharew5_rel8-0-0_ac.dta   \n",
       "12  Perceived Constraints     6       sharew6_rel8-0-0_ac.dta   \n",
       "13  Perceived Constraints     7       sharew7_rel8-0-0_ac.dta   \n",
       "14  Perceived Constraints     8       sharew8_rel8-0-0_ac.dta   \n",
       "\n",
       "             var_set  \\\n",
       "8   ['q2_b', 'q2_c']   \n",
       "9         ['ac015_']   \n",
       "10        ['ac015_']   \n",
       "11        ['ac015_']   \n",
       "12        ['ac015_']   \n",
       "13        ['ac015_']   \n",
       "14        ['ac015_']   \n",
       "\n",
       "                                                                                                   Notes  \\\n",
       "8   {'q2_b': 'I feel that what happens to me is out of my control', 'q2_c': 'I feel left out of things'}   \n",
       "9                                                                           {'ac015_': 'Out of control'}   \n",
       "10                                                                          {'ac015_': 'Out of control'}   \n",
       "11                                                                          {'ac015_': 'Out of control'}   \n",
       "12                                                                          {'ac015_': 'Out of control'}   \n",
       "13                                                                          {'ac015_': 'Out of control'}   \n",
       "14                                                                          {'ac015_': 'Out of control'}   \n",
       "\n",
       "    recoded  \n",
       "8      True  \n",
       "9     False  \n",
       "10    False  \n",
       "11    False  \n",
       "12    False  \n",
       "13    False  \n",
       "14    False  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conventional_name= 'Perceived Constraints'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==conventional_name,]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_dropoff.dta->{'Never': 1, 'Rarely': 2, 'Sometimes': 3, 'Often': 4, 'Not answered': None, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_8512/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "row={'varname': 'Zperceivedconstraints',\n",
    " 'var_set': [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q2_b', 'q2_c']},\n",
    " 2: {'sharew2_rel8-0-0_ac.dta': ['ac015_']},\n",
    " 4: {'sharew4_rel8-0-0_ac.dta': ['ac015_']},\n",
    " 5: {'sharew5_rel8-0-0_ac.dta': ['ac015_']},\n",
    " 6: {'sharew6_rel8-0-0_ac.dta': ['ac015_']},\n",
    " 7: {'sharew7_rel8-0-0_ac.dta': ['ac015_']},\n",
    " 8: {'sharew8_rel8-0-0_ac.dta': ['ac015_']}}],\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Perceived Constraints',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': False,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-18'}\n",
    "df_recode_record=add_row_to_df_record(row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Row Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wave 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_wave = 1\n",
    "\n",
    "varname = row['varname']\n",
    "var_set, file_name = get_raw_info(row,latest_wave)\n",
    "df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "df_temp = df_temp[['mergeid']]\n",
    "sliced_data = df_temp[var_set]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Never', 'Rarely', 'Sometimes', 'Often', 'Not answered']\n",
      "no replace_dict been found\n",
      "do you wish to generate/re-define a replace_dict for wave 1? 1->yes others->no1\n",
      "replace response [Never] with int .. (999 -> none)1\n",
      "replace response [Rarely] with int .. (999 -> none)2\n",
      "replace response [Sometimes] with int .. (999 -> none)3\n",
      "replace response [Often] with int .. (999 -> none)4\n",
      "replace response [Not answered] with int .. (999 -> none)999\n",
      "do you wish to replace data in 1? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    19388\n",
      "2      443\n",
      "1      361\n",
      "Name: missing_count, dtype: int64\n",
      "please specify the missing count (999 is none)2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_8512/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#1. replace\n",
    "row,sliced_data = replace_procedure(sliced_data,file_name,latest_wave,row)\n",
    "\n",
    "#2. deal with maximum missing response\n",
    "if len(var_set)>1:\n",
    "    missing_count(sliced_data)\n",
    "    \n",
    "    if row['maximum_missing_response']:\n",
    "        print(f'the maximum missing response is {row[\"maximum_missing_response\"]}')\n",
    "    else:\n",
    "        missing_count_controller = int(input('please specify the missing count (999 is none)'))\n",
    "        row['maximum_missing_response']= missing_count_controller if not missing_count_controller==999 else None\n",
    "\n",
    "#3. deal with reverse_code\n",
    "print(f'the reverse code is {row[\"reverse_code\"]}')\n",
    "reverse_control = input('wish to redefine reverse_conde controller? 1->Change any.other->Not Change')\n",
    "row[\"reverse_code\"]= not row[\"reverse_code\"] if reverse_control=='1' else row[\"reverse_code\"]\n",
    "\n",
    "# reverse control\n",
    "if row[\"reverse_code\"]:\n",
    "    unique_vals = get_unique_valaues(sliced_data)\n",
    "    print(\"4. unique_vals are {}\".format(unique_vals))\n",
    "    replace_dict = generate_value_replace_dict(unique_vals)\n",
    "    print(\"5. dict is {}\".format(replace_dict))\n",
    "    sliced_data.replace(replace_dict,inplace=True)\n",
    "\n",
    "# multiple response\n",
    "if len(varset)==1:\n",
    "    df_temp[f'{varname}_{latest_wave}']=sliced_data[varset[0]]\n",
    "else:    \n",
    "    df_temp[f'{varname}_{latest_wave}']=sliced_data.apply(average_response_by_row,axis=1,maximum_missing_response=row[\"maximum_missing_response\"])\n",
    "\n",
    "# savezone\n",
    "df_raw_recoded=pd.merge(left=df_raw_recoded,right=df_temp,on='mergeid',how='outer')\n",
    "mark_df_vars_found_in_raw(varname_in_raw_recoder,latest_wave)\n",
    "df_recode_record=add_row_to_df_record(row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trait Anxiety `Zanxiety`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Trait Anxiety</td>\n",
       "      <td>4</td>\n",
       "      <td>sharew4_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh023_', 'mh024_', 'mh025_', 'mh026_', 'mh027_']</td>\n",
       "      <td>{'mh023_': 'Fear of the worst happening', 'mh024_': 'Nervous', 'mh025_': 'Hands trembling', 'mh026_': 'Fear of dying', 'mh027_': 'Felt faint'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Trait Anxiety</td>\n",
       "      <td>5</td>\n",
       "      <td>sharew5_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh023_', 'mh024_', 'mh025_', 'mh026_', 'mh027_']</td>\n",
       "      <td>{'mh023_': 'Fear of the worst happening', 'mh024_': 'Nervous', 'mh025_': 'Hands trembling', 'mh026_': 'Fear of dying', 'mh027_': 'Felt faint'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          varname  wave                file_name  \\\n",
       "16  Trait Anxiety     4  sharew4_rel8-0-0_mh.dta   \n",
       "17  Trait Anxiety     5  sharew5_rel8-0-0_mh.dta   \n",
       "\n",
       "                                               var_set  \\\n",
       "16  ['mh023_', 'mh024_', 'mh025_', 'mh026_', 'mh027_']   \n",
       "17  ['mh023_', 'mh024_', 'mh025_', 'mh026_', 'mh027_']   \n",
       "\n",
       "                                                                                                                                             Notes  \\\n",
       "16  {'mh023_': 'Fear of the worst happening', 'mh024_': 'Nervous', 'mh025_': 'Hands trembling', 'mh026_': 'Fear of dying', 'mh027_': 'Felt faint'}   \n",
       "17  {'mh023_': 'Fear of the worst happening', 'mh024_': 'Nervous', 'mh025_': 'Hands trembling', 'mh026_': 'Fear of dying', 'mh027_': 'Felt faint'}   \n",
       "\n",
       "    recoded  \n",
       "16    False  \n",
       "17    False  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Trait Anxiety'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zanxiety'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "row = {'varname': 'Zanxiety',\n",
    " 'var_set': [{4: {'sharew4_rel8-0-0_mh.dta': ['mh023_',\n",
    "     'mh024_',\n",
    "     'mh025_',\n",
    "     'mh026_',\n",
    "     'mh027_']},\n",
    "   5: {'sharew5_rel8-0-0_mh.dta': ['mh023_',\n",
    "     'mh024_',\n",
    "     'mh025_',\n",
    "     'mh026_',\n",
    "     'mh027_']}}],\n",
    " 'available_waves': [4, 5],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Trait Anxiety',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}\n",
    "df_recode_record=add_row_to_df_record(row,df_recode_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest_wave = 4\n",
    "latest_wave = 5\n",
    "#0. retreive data\n",
    "varname = row['varname']\n",
    "var_set, file_name = get_raw_info(row,latest_wave)\n",
    "df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "sliced_data = df_temp[var_set]\n",
    "df_temp = df_temp[['mergeid']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for column in sliced_data.columns:\n",
    "    print(sliced_data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded):\n",
    "    #1. replace\n",
    "    row,sliced_data = replace_procedure(sliced_data,file_name,latest_wave,row)\n",
    "\n",
    "    #2. deal with maximum missing response\n",
    "    if len(var_set)>1:\n",
    "        missing_count(sliced_data)\n",
    "\n",
    "        if row['maximum_missing_response']:\n",
    "            print(f'the maximum missing response is {row[\"maximum_missing_response\"]}')\n",
    "        else:\n",
    "            missing_count_controller = int(input('please specify the missing count (999 is none)'))\n",
    "            row['maximum_missing_response']= missing_count_controller if not missing_count_controller==999 else None\n",
    "\n",
    "    #3. deal with reverse_code\n",
    "    print(f'the reverse code is {row[\"reverse_code\"]}')\n",
    "    reverse_control = input('wish to redefine reverse_conde controller? 1->Change any.other->Not Change')\n",
    "    row[\"reverse_code\"]= not row[\"reverse_code\"] if reverse_control=='1' else row[\"reverse_code\"]\n",
    "\n",
    "    # reverse control\n",
    "    if row[\"reverse_code\"]:\n",
    "        unique_vals = get_unique_valaues(sliced_data)\n",
    "        print(\"4. unique_vals are {}\".format(unique_vals))\n",
    "        replace_dict = generate_value_replace_dict(unique_vals)\n",
    "        print(\"5. dict is {}\".format(replace_dict))\n",
    "        sliced_data.replace(replace_dict,inplace=True)\n",
    "\n",
    "    # categorical column pretreatment\n",
    "    for column in sliced_data.columns:\n",
    "        if isinstance(sliced_data[column].dtype,pd.api.types.CategoricalDtype):\n",
    "            sliced_data[column]=np.asarray(sliced_data[column])\n",
    "    # multiple response\n",
    "    if len(var_set)==1:\n",
    "        df_temp[f'{varname}_{latest_wave}']=sliced_data[var_set[0]]\n",
    "    else:    \n",
    "        df_temp[f'{varname}_{latest_wave}']=sliced_data.apply(average_response_by_row,axis=1,maximum_missing_response=row[\"maximum_missing_response\"])\n",
    "\n",
    "    # savezone\n",
    "    df_raw_recoded=pd.merge(left=df_raw_recoded,right=df_temp,on='mergeid',how='outer')\n",
    "    mark_df_vars_found_in_raw(varname_in_raw_recoder,latest_wave)\n",
    "    df_recode_record=add_row_to_df_record(row,df_recode_record)\n",
    "    return df_recode_record,df_raw_recoded\n",
    "\n",
    "# raw_multi_response_procedure(sliced_data,file_name,latest_wave,row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hopelessness `Zhopelessness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>1</td>\n",
       "      <td>sharew1_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh003_']</td>\n",
       "      <td>{'mh003_': 'Hopes for the future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>2</td>\n",
       "      <td>sharew2_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh003_']</td>\n",
       "      <td>{'mh003_': 'Hopes for the future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>4</td>\n",
       "      <td>sharew4_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh003_']</td>\n",
       "      <td>{'mh003_': 'Hopes for the future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>5</td>\n",
       "      <td>sharew5_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh003_']</td>\n",
       "      <td>{'mh003_': 'Hopes for the future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>6</td>\n",
       "      <td>sharew6_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh003_']</td>\n",
       "      <td>{'mh003_': 'Hopes for the future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>7</td>\n",
       "      <td>sharew7_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh003_']</td>\n",
       "      <td>{'mh003_': 'Hopes for the future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh003_']</td>\n",
       "      <td>{'mh003_': 'Hopes for the future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         varname  wave                file_name     var_set  \\\n",
       "20  Hopelessness     1  sharew1_rel8-0-0_mh.dta  ['mh003_']   \n",
       "21  Hopelessness     2  sharew2_rel8-0-0_mh.dta  ['mh003_']   \n",
       "22  Hopelessness     4  sharew4_rel8-0-0_mh.dta  ['mh003_']   \n",
       "23  Hopelessness     5  sharew5_rel8-0-0_mh.dta  ['mh003_']   \n",
       "24  Hopelessness     6  sharew6_rel8-0-0_mh.dta  ['mh003_']   \n",
       "25  Hopelessness     7  sharew7_rel8-0-0_mh.dta  ['mh003_']   \n",
       "26  Hopelessness     8  sharew8_rel8-0-0_mh.dta  ['mh003_']   \n",
       "\n",
       "                                 Notes  recoded  \n",
       "20  {'mh003_': 'Hopes for the future'}    False  \n",
       "21  {'mh003_': 'Hopes for the future'}    False  \n",
       "22  {'mh003_': 'Hopes for the future'}    False  \n",
       "23  {'mh003_': 'Hopes for the future'}    False  \n",
       "24  {'mh003_': 'Hopes for the future'}    False  \n",
       "25  {'mh003_': 'Hopes for the future'}    False  \n",
       "26  {'mh003_': 'Hopes for the future'}    False  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Hopelessness'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zhopelessness'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Zhopelessness',\n",
    " 'var_set': [{1: {'sharew1_rel8-0-0_mh.dta': ['mh003_']},\n",
    "   2: {'sharew2_rel8-0-0_mh.dta': ['mh003_']},\n",
    "   4: {'sharew4_rel8-0-0_mh.dta': ['mh003_']},\n",
    "   5: {'sharew5_rel8-0-0_mh.dta': ['mh003_']},\n",
    "   6: {'sharew6_rel8-0-0_mh.dta': ['mh003_']},\n",
    "   7: {'sharew7_rel8-0-0_mh.dta': ['mh003_']},\n",
    "   8: {'sharew8_rel8-0-0_mh.dta': ['mh003_']}}],\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Hopelessness',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': True,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 2-------\n",
      "0         No hopes mentioned\n",
      "1        Any hopes mentioned\n",
      "2        Any hopes mentioned\n",
      "3         No hopes mentioned\n",
      "4        Any hopes mentioned\n",
      "                ...         \n",
      "37138    Any hopes mentioned\n",
      "37139    Any hopes mentioned\n",
      "37140    Any hopes mentioned\n",
      "37141    Any hopes mentioned\n",
      "37142    Any hopes mentioned\n",
      "Name: mh003_, Length: 37143, dtype: category\n",
      "Categories (4, object): ['Refusal' < 'Don't know' < 'Any hopes mentioned' < 'No hopes mentioned']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Refusal', \"Don't know\", 'No hopes mentioned', 'Any hopes mentioned']\n",
      "no replace_dict been found for wave 2\n",
      "{'sharew1_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew1_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 2? 1->yes others->no0\n",
      "do you wish to replace data in 2? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew2_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 4-------\n",
      "0        Any hopes mentioned\n",
      "1        Any hopes mentioned\n",
      "2        Any hopes mentioned\n",
      "3        Any hopes mentioned\n",
      "4        Any hopes mentioned\n",
      "                ...         \n",
      "57995     No hopes mentioned\n",
      "57996     No hopes mentioned\n",
      "57997    Any hopes mentioned\n",
      "57998    Any hopes mentioned\n",
      "57999    Any hopes mentioned\n",
      "Name: mh003_, Length: 58000, dtype: category\n",
      "Categories (4, object): ['Refusal' < 'Don't know' < 'Any hopes mentioned' < 'No hopes mentioned']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Refusal', \"Don't know\", 'No hopes mentioned', 'Any hopes mentioned']\n",
      "no replace_dict been found for wave 4\n",
      "{'sharew1_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew2_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew1_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 4? 1->yes others->no0\n",
      "do you wish to replace data in 4? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew2_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew4_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 5-------\n",
      "0        Any hopes mentioned\n",
      "1        Any hopes mentioned\n",
      "2        Any hopes mentioned\n",
      "3        Any hopes mentioned\n",
      "4        Any hopes mentioned\n",
      "                ...         \n",
      "66060    Any hopes mentioned\n",
      "66061    Any hopes mentioned\n",
      "66062    Any hopes mentioned\n",
      "66063    Any hopes mentioned\n",
      "66064     No hopes mentioned\n",
      "Name: mh003_, Length: 66065, dtype: category\n",
      "Categories (4, object): ['Refusal' < 'Don't know' < 'Any hopes mentioned' < 'No hopes mentioned']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Refusal', \"Don't know\", 'No hopes mentioned', 'Any hopes mentioned']\n",
      "no replace_dict been found for wave 5\n",
      "{'sharew1_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew2_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew4_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew1_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 5? 1->yes others->no0\n",
      "do you wish to replace data in 5? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew2_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew4_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 6-------\n",
      "0        Any hopes mentioned\n",
      "1        Any hopes mentioned\n",
      "2        Any hopes mentioned\n",
      "3        Any hopes mentioned\n",
      "4        Any hopes mentioned\n",
      "                ...         \n",
      "68080     No hopes mentioned\n",
      "68081    Any hopes mentioned\n",
      "68082    Any hopes mentioned\n",
      "68083     No hopes mentioned\n",
      "68084     No hopes mentioned\n",
      "Name: mh003_, Length: 68085, dtype: category\n",
      "Categories (4, object): ['Refusal' < 'Don't know' < 'Any hopes mentioned' < 'No hopes mentioned']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Refusal', \"Don't know\", 'No hopes mentioned', 'Any hopes mentioned']\n",
      "no replace_dict been found for wave 6\n",
      "{'sharew1_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew2_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew4_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew1_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 6? 1->yes others->no0\n",
      "do you wish to replace data in 6? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew2_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew4_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew6_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 7-------\n",
      "0        NaN\n",
      "1        NaN\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "        ... \n",
      "77197    NaN\n",
      "77198    NaN\n",
      "77199    NaN\n",
      "77200    NaN\n",
      "77201    NaN\n",
      "Name: mh003_, Length: 77202, dtype: category\n",
      "Categories (4, object): ['Refusal' < 'Don't know' < 'Any hopes mentioned' < 'No hopes mentioned']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Refusal', \"Don't know\", 'No hopes mentioned', 'Any hopes mentioned']\n",
      "no replace_dict been found for wave 7\n",
      "{'sharew1_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew2_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew4_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew6_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew1_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 7? 1->yes others->no0\n",
      "do you wish to replace data in 7? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew2_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew4_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew6_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew7_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 8-------\n",
      "0        Any hopes mentioned\n",
      "1        Any hopes mentioned\n",
      "2        Any hopes mentioned\n",
      "3                 Don't know\n",
      "4         No hopes mentioned\n",
      "                ...         \n",
      "46728    Any hopes mentioned\n",
      "46729     No hopes mentioned\n",
      "46730     No hopes mentioned\n",
      "46731    Any hopes mentioned\n",
      "46732     No hopes mentioned\n",
      "Name: mh003_, Length: 46733, dtype: category\n",
      "Categories (4, object): ['Refusal' < 'Don't know' < 'Any hopes mentioned' < 'No hopes mentioned']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Refusal', \"Don't know\", 'No hopes mentioned', 'Any hopes mentioned']\n",
      "no replace_dict been found for wave 8\n",
      "{'sharew1_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew2_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew4_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew6_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew7_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew1_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 8? 1->yes others->no0\n",
      "do you wish to replace data in 8? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew2_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew4_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew6_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew7_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew8_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#for latest_wave in row['available_waves']:\n",
    "for latest_wave in [2, 4, 5, 6, 7, 8]:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loneliness  `Zloneliness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Loneliness</td>\n",
       "      <td>4</td>\n",
       "      <td>sharew4_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q5a', 'q5b', 'q5c', 'q5d']</td>\n",
       "      <td>{'q5a': 'How much of time: feel you lack companionship', 'q5b': 'How much of time: feel left out', 'q5c': 'How much of time: feel isolated from others', 'q5d': 'How much of time: feel lonely'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Loneliness</td>\n",
       "      <td>5</td>\n",
       "      <td>sharew5_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh034_', 'mh035_', 'mh036_', 'mh037_']</td>\n",
       "      <td>{'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Loneliness</td>\n",
       "      <td>6</td>\n",
       "      <td>sharew6_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh034_', 'mh035_', 'mh036_', 'mh037_']</td>\n",
       "      <td>{'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Loneliness</td>\n",
       "      <td>7</td>\n",
       "      <td>sharew7_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh034_', 'mh035_', 'mh036_', 'mh037_']</td>\n",
       "      <td>{'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Loneliness</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh034_', 'mh035_', 'mh036_', 'mh037_']</td>\n",
       "      <td>{'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       varname  wave                     file_name  \\\n",
       "27  Loneliness     4  sharew4_rel8-0-0_dropoff.dta   \n",
       "28  Loneliness     5       sharew5_rel8-0-0_mh.dta   \n",
       "29  Loneliness     6       sharew6_rel8-0-0_mh.dta   \n",
       "30  Loneliness     7       sharew7_rel8-0-0_mh.dta   \n",
       "31  Loneliness     8       sharew8_rel8-0-0_mh.dta   \n",
       "\n",
       "                                     var_set  \\\n",
       "27              ['q5a', 'q5b', 'q5c', 'q5d']   \n",
       "28  ['mh034_', 'mh035_', 'mh036_', 'mh037_']   \n",
       "29  ['mh034_', 'mh035_', 'mh036_', 'mh037_']   \n",
       "30  ['mh034_', 'mh035_', 'mh036_', 'mh037_']   \n",
       "31  ['mh034_', 'mh035_', 'mh036_', 'mh037_']   \n",
       "\n",
       "                                                                                                                                                                                               Notes  \\\n",
       "27  {'q5a': 'How much of time: feel you lack companionship', 'q5b': 'How much of time: feel left out', 'q5c': 'How much of time: feel isolated from others', 'q5d': 'How much of time: feel lonely'}   \n",
       "28                                                           {'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}   \n",
       "29                                                           {'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}   \n",
       "30                                                           {'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}   \n",
       "31                                                           {'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}   \n",
       "\n",
       "    recoded  \n",
       "27    False  \n",
       "28    False  \n",
       "29    False  \n",
       "30    False  \n",
       "31    False  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Loneliness'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zloneliness'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = {'varname': 'Zloneliness',\n",
    " 'var_set': [{4: {'sharew4_rel8-0-0_dropoff.dta': ['q5a',\n",
    "     'q5b',\n",
    "     'q5c',\n",
    "     'q5d']},\n",
    "   5: {'sharew5_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']},\n",
    "   6: {'sharew6_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']},\n",
    "   7: {'sharew7_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']},\n",
    "   8: {'sharew8_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']}}],\n",
    " 'available_waves': [4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'loneliness',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': 4,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 5-------\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "66060        Some of the time\n",
      "66061    Hardly ever or never\n",
      "66062        Some of the time\n",
      "66063                   Often\n",
      "66064    Hardly ever or never\n",
      "Name: mh034_, Length: 66065, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "66060        Some of the time\n",
      "66061    Hardly ever or never\n",
      "66062    Hardly ever or never\n",
      "66063                   Often\n",
      "66064    Hardly ever or never\n",
      "Name: mh035_, Length: 66065, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "66060    Hardly ever or never\n",
      "66061    Hardly ever or never\n",
      "66062    Hardly ever or never\n",
      "66063        Some of the time\n",
      "66064    Hardly ever or never\n",
      "Name: mh036_, Length: 66065, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "66060    Hardly ever or never\n",
      "66061    Hardly ever or never\n",
      "66062        Some of the time\n",
      "66063        Some of the time\n",
      "66064    Hardly ever or never\n",
      "Name: mh037_, Length: 66065, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Hardly ever or never', 'Often', 'Refusal', \"Don't know\", 'Some of the time']\n",
      "no replace_dict been found for wave 5\n",
      "{'sharew4_rel8-0-0_dropoff.dta': {'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no0\n",
      "do you wish to generate/re-define a replace_dict for wave 5? 1->yes others->no1\n",
      "replace response [Hardly ever or never] with int .. (999 -> none)1\n",
      "replace response [Often] with int .. (999 -> none)3\n",
      "replace response [Refusal] with int .. (999 -> none)999\n",
      "replace response [Don't know] with int .. (999 -> none)999\n",
      "replace response [Some of the time] with int .. (999 -> none)2\n",
      "do you wish to replace data in 5? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    64364\n",
      "4     1373\n",
      "1      231\n",
      "2       52\n",
      "3       45\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 4\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew4_rel8-0-0_dropoff.dta->{'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 6-------\n",
      "0            Some of the time\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4            Some of the time\n",
      "                 ...         \n",
      "68080                   Often\n",
      "68081        Some of the time\n",
      "68082    Hardly ever or never\n",
      "68083    Hardly ever or never\n",
      "68084    Hardly ever or never\n",
      "Name: mh034_, Length: 68085, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0            Some of the time\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "68080        Some of the time\n",
      "68081    Hardly ever or never\n",
      "68082    Hardly ever or never\n",
      "68083    Hardly ever or never\n",
      "68084    Hardly ever or never\n",
      "Name: mh035_, Length: 68085, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "68080        Some of the time\n",
      "68081    Hardly ever or never\n",
      "68082    Hardly ever or never\n",
      "68083    Hardly ever or never\n",
      "68084    Hardly ever or never\n",
      "Name: mh036_, Length: 68085, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0            Some of the time\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4            Some of the time\n",
      "                 ...         \n",
      "68080                   Often\n",
      "68081    Hardly ever or never\n",
      "68082    Hardly ever or never\n",
      "68083    Hardly ever or never\n",
      "68084    Hardly ever or never\n",
      "Name: mh037_, Length: 68085, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Hardly ever or never', 'Often', 'Refusal', \"Don't know\", 'Some of the time']\n",
      "no replace_dict been found for wave 6\n",
      "{'sharew4_rel8-0-0_dropoff.dta': {'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew5_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 6? 1->yes others->no0\n",
      "do you wish to replace data in 6? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    64864\n",
      "4     3059\n",
      "1      130\n",
      "2       22\n",
      "3       10\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 4\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew4_rel8-0-0_dropoff.dta->{'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "sharew6_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 7-------\n",
      "0        NaN\n",
      "1        NaN\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "        ... \n",
      "77197    NaN\n",
      "77198    NaN\n",
      "77199    NaN\n",
      "77200    NaN\n",
      "77201    NaN\n",
      "Name: mh034_, Length: 77202, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        NaN\n",
      "1        NaN\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "        ... \n",
      "77197    NaN\n",
      "77198    NaN\n",
      "77199    NaN\n",
      "77200    NaN\n",
      "77201    NaN\n",
      "Name: mh035_, Length: 77202, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        NaN\n",
      "1        NaN\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "        ... \n",
      "77197    NaN\n",
      "77198    NaN\n",
      "77199    NaN\n",
      "77200    NaN\n",
      "77201    NaN\n",
      "Name: mh036_, Length: 77202, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        NaN\n",
      "1        NaN\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "        ... \n",
      "77197    NaN\n",
      "77198    NaN\n",
      "77199    NaN\n",
      "77200    NaN\n",
      "77201    NaN\n",
      "Name: mh037_, Length: 77202, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Hardly ever or never', 'Often', 'Refusal', \"Don't know\", 'Some of the time']\n",
      "no replace_dict been found for wave 7\n",
      "{'sharew4_rel8-0-0_dropoff.dta': {'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}, 'sharew6_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew5_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 7? 1->yes others->no0\n",
      "do you wish to replace data in 7? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "4    63574\n",
      "0    13568\n",
      "1       38\n",
      "3       13\n",
      "2        9\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 4\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew4_rel8-0-0_dropoff.dta->{'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "sharew6_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "sharew7_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 8-------\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3                  Don't know\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "46728    Hardly ever or never\n",
      "46729        Some of the time\n",
      "46730                   Often\n",
      "46731    Hardly ever or never\n",
      "46732        Some of the time\n",
      "Name: mh034_, Length: 46733, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3                  Don't know\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "46728    Hardly ever or never\n",
      "46729        Some of the time\n",
      "46730        Some of the time\n",
      "46731    Hardly ever or never\n",
      "46732                   Often\n",
      "Name: mh035_, Length: 46733, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3                  Don't know\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "46728    Hardly ever or never\n",
      "46729        Some of the time\n",
      "46730                   Often\n",
      "46731        Some of the time\n",
      "46732    Hardly ever or never\n",
      "Name: mh036_, Length: 46733, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3                  Don't know\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "46728    Hardly ever or never\n",
      "46729        Some of the time\n",
      "46730                   Often\n",
      "46731        Some of the time\n",
      "46732                   Often\n",
      "Name: mh037_, Length: 46733, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Hardly ever or never', 'Often', 'Refusal', \"Don't know\", 'Some of the time']\n",
      "no replace_dict been found for wave 8\n",
      "{'sharew4_rel8-0-0_dropoff.dta': {'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}, 'sharew6_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}, 'sharew7_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew5_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 8? 1->yes others->no0\n",
      "do you wish to replace data in 8? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    45525\n",
      "4     1009\n",
      "1      150\n",
      "2       32\n",
      "3       17\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 4\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew4_rel8-0-0_dropoff.dta->{'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "sharew6_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "sharew7_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "sharew8_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for latest_wave in [5,6,7,8]:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreeableness  `Zagreeableness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>7</td>\n",
       "      <td>sharew7_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac702_', 'ac711_']</td>\n",
       "      <td>{'ac702_': 'general trusting', 'ac711_': 'considerate and kind to almost everyone'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac702_', 'ac711_']</td>\n",
       "      <td>{'ac702_': 'general trusting', 'ac711_': 'considerate and kind to almost everyone'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          varname  wave                file_name               var_set  \\\n",
       "32  Agreeableness     7  sharew7_rel8-0-0_ac.dta  ['ac702_', 'ac711_']   \n",
       "33  Agreeableness     8  sharew8_rel8-0-0_ac.dta  ['ac702_', 'ac711_']   \n",
       "\n",
       "                                                                                  Notes  \\\n",
       "32  {'ac702_': 'general trusting', 'ac711_': 'considerate and kind to almost everyone'}   \n",
       "33  {'ac702_': 'general trusting', 'ac711_': 'considerate and kind to almost everyone'}   \n",
       "\n",
       "    recoded  \n",
       "32    False  \n",
       "33    False  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Agreeableness'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zagreeableness'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Zagreeableness',\n",
    " 'var_set': [{7: {'sharew7_rel8-0-0_ac.dta': ['ac702_', 'ac711_']},\n",
    "   8: {'sharew8_rel8-0-0_ac.dta': ['ac702_', 'ac711_']}}],\n",
    " 'available_waves': [7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Agreeableness',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 7-------\n",
      "0                    Agree a little\n",
      "1        Neither agree nor disagree\n",
      "2                    Agree strongly\n",
      "3                    Agree a little\n",
      "4                    Agree a little\n",
      "                    ...            \n",
      "77197                Agree strongly\n",
      "77198    Neither agree nor disagree\n",
      "77199    Neither agree nor disagree\n",
      "77200    Neither agree nor disagree\n",
      "77201             Disagree a little\n",
      "Name: ac702_, Length: 77202, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "0                    Agree a little\n",
      "1                    Agree strongly\n",
      "2                    Agree strongly\n",
      "3                    Agree a little\n",
      "4                    Agree a little\n",
      "                    ...            \n",
      "77197                Agree strongly\n",
      "77198    Neither agree nor disagree\n",
      "77199                Agree strongly\n",
      "77200    Neither agree nor disagree\n",
      "77201                Agree strongly\n",
      "Name: ac711_, Length: 77202, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Disagree a little', 'Agree a little', 'Refusal', 'Neither agree nor disagree', 'Agree strongly', 'Disagree strongly', \"Don't know\"]\n",
      "no replace_dict been found for wave 7\n",
      "do you wish to generate/re-define a replace_dict for wave 7? 1->yes others->no1\n",
      "replace response [Disagree a little] with int .. (999 -> none)4\n",
      "replace response [Agree a little] with int .. (999 -> none)2\n",
      "replace response [Refusal] with int .. (999 -> none)999\n",
      "replace response [Neither agree nor disagree] with int .. (999 -> none)3\n",
      "replace response [Agree strongly] with int .. (999 -> none)1\n",
      "replace response [Disagree strongly] with int .. (999 -> none)5\n",
      "replace response [Don't know] with int .. (999 -> none)999\n",
      "do you wish to replace data in 7? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    74773\n",
      "2     2242\n",
      "1      187\n",
      "Name: missing_count, dtype: int64\n",
      "please specify the missing count (999 is none)2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 8-------\n",
      "0                               NaN\n",
      "1                               NaN\n",
      "2                               NaN\n",
      "3                               NaN\n",
      "4                               NaN\n",
      "                    ...            \n",
      "46728                Agree a little\n",
      "46729                Agree a little\n",
      "46730                Agree strongly\n",
      "46731             Disagree a little\n",
      "46732    Neither agree nor disagree\n",
      "Name: ac702_, Length: 46733, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "0                               NaN\n",
      "1                               NaN\n",
      "2                               NaN\n",
      "3                               NaN\n",
      "4                               NaN\n",
      "                    ...            \n",
      "46728    Neither agree nor disagree\n",
      "46729                Agree a little\n",
      "46730                Agree strongly\n",
      "46731                Agree a little\n",
      "46732                Agree strongly\n",
      "Name: ac711_, Length: 46733, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Disagree a little', 'Agree a little', 'Refusal', 'Neither agree nor disagree', 'Agree strongly', 'Disagree strongly', \"Don't know\"]\n",
      "no replace_dict been found for wave 8\n",
      "{'sharew7_rel8-0-0_ac.dta': {'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, \"Don't know\": None, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew7_rel8-0-0_ac.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 8? 1->yes others->no0\n",
      "do you wish to replace data in 8? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "2    36814\n",
      "0     9894\n",
      "1       25\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew7_rel8-0-0_ac.dta->{'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, \"Don't know\": None, 'nan': None}\n",
      "sharew8_rel8-0-0_ac.dta->{'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, \"Don't know\": None, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count            46733\n",
      "unique           46733\n",
      "top       AT-001215-01\n",
      "freq                 1\n",
      "Name: mergeid, dtype: object\n",
      "count    9919.000000\n",
      "mean        2.141446\n",
      "std         0.800002\n",
      "min         1.000000\n",
      "25%         1.500000\n",
      "50%         2.000000\n",
      "75%         2.500000\n",
      "max         5.000000\n",
      "Name: Zagreeableness_8, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for column in df_temp.columns:\n",
    "    print(df_temp[column].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extroversion  `Zextroversion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Extroversion</td>\n",
       "      <td>7</td>\n",
       "      <td>sharew7_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac706_', 'ac711_']</td>\n",
       "      <td>{'ac706_': 'outgoing, sociable', 'ac711_': 'considerate and kind to almost everyone'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Extroversion</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac706_', 'ac711_']</td>\n",
       "      <td>{'ac706_': 'outgoing, sociable', 'ac711_': 'considerate and kind to almost everyone'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         varname  wave                file_name               var_set  \\\n",
       "34  Extroversion     7  sharew7_rel8-0-0_ac.dta  ['ac706_', 'ac711_']   \n",
       "35  Extroversion     8  sharew8_rel8-0-0_ac.dta  ['ac706_', 'ac711_']   \n",
       "\n",
       "                                                                                    Notes  \\\n",
       "34  {'ac706_': 'outgoing, sociable', 'ac711_': 'considerate and kind to almost everyone'}   \n",
       "35  {'ac706_': 'outgoing, sociable', 'ac711_': 'considerate and kind to almost everyone'}   \n",
       "\n",
       "    recoded  \n",
       "34    False  \n",
       "35    False  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Extroversion'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zextroversion'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Zextroversion',\n",
    " 'var_set': [{7: {'sharew7_rel8-0-0_ac.dta': ['ac706_', 'ac711_']},\n",
    "   8: {'sharew8_rel8-0-0_ac.dta': ['ac706_', 'ac711_']}}],\n",
    " 'available_waves': [7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Extroversion',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 7-------\n",
      "0        Neither agree nor disagree\n",
      "1                    Agree strongly\n",
      "2        Neither agree nor disagree\n",
      "3                    Agree a little\n",
      "4                    Agree a little\n",
      "                    ...            \n",
      "77197                Agree strongly\n",
      "77198             Disagree a little\n",
      "77199                Agree strongly\n",
      "77200    Neither agree nor disagree\n",
      "77201                Agree a little\n",
      "Name: ac706_, Length: 77202, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "0                    Agree a little\n",
      "1                    Agree strongly\n",
      "2                    Agree strongly\n",
      "3                    Agree a little\n",
      "4                    Agree a little\n",
      "                    ...            \n",
      "77197                Agree strongly\n",
      "77198    Neither agree nor disagree\n",
      "77199                Agree strongly\n",
      "77200    Neither agree nor disagree\n",
      "77201                Agree strongly\n",
      "Name: ac711_, Length: 77202, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Disagree a little', 'Agree a little', 'Refusal', 'Neither agree nor disagree', 'Agree strongly', 'Disagree strongly', \"Don't know\"]\n",
      "no replace_dict been found for wave 7\n",
      "do you wish to generate/re-define a replace_dict for wave 7? 1->yes others->no1\n",
      "replace response [Disagree a little] with int .. (999 -> none)4\n",
      "replace response [Agree a little] with int .. (999 -> none)2\n",
      "replace response [Refusal] with int .. (999 -> none)999\n",
      "replace response [Neither agree nor disagree] with int .. (999 -> none)3\n",
      "replace response [Agree strongly] with int .. (999 -> none)1\n",
      "replace response [Disagree strongly] with int .. (999 -> none)5\n",
      "replace response [Don't know] with int .. (999 -> none)999\n",
      "do you wish to replace data in 7? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    74800\n",
      "2     2253\n",
      "1      149\n",
      "Name: missing_count, dtype: int64\n",
      "please specify the missing count (999 is none)2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 8-------\n",
      "0                               NaN\n",
      "1                               NaN\n",
      "2                               NaN\n",
      "3                               NaN\n",
      "4                               NaN\n",
      "                    ...            \n",
      "46728                Agree a little\n",
      "46729                Agree a little\n",
      "46730    Neither agree nor disagree\n",
      "46731                Agree a little\n",
      "46732                Agree strongly\n",
      "Name: ac706_, Length: 46733, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "0                               NaN\n",
      "1                               NaN\n",
      "2                               NaN\n",
      "3                               NaN\n",
      "4                               NaN\n",
      "                    ...            \n",
      "46728    Neither agree nor disagree\n",
      "46729                Agree a little\n",
      "46730                Agree strongly\n",
      "46731                Agree a little\n",
      "46732                Agree strongly\n",
      "Name: ac711_, Length: 46733, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Disagree a little', 'Agree a little', 'Refusal', 'Neither agree nor disagree', 'Agree strongly', 'Disagree strongly', \"Don't know\"]\n",
      "no replace_dict been found for wave 8\n",
      "{'sharew7_rel8-0-0_ac.dta': {'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, \"Don't know\": None, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew7_rel8-0-0_ac.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 8? 1->yes others->no0\n",
      "do you wish to replace data in 8? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "2    36814\n",
      "0     9898\n",
      "1       21\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew7_rel8-0-0_ac.dta->{'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, \"Don't know\": None, 'nan': None}\n",
      "sharew8_rel8-0-0_ac.dta->{'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, \"Don't know\": None, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuroticism  `Zneuroticism`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>7</td>\n",
       "      <td>sharew7_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac709_', 'ac704_']</td>\n",
       "      <td>{'ac709_': 'gets nervous easily', 'ac704_': 'relaxed, handles stress well (reverse code)'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac709_', 'ac704_']</td>\n",
       "      <td>{'ac709_': 'gets nervous easily', 'ac704_': 'relaxed, handles stress well (reverse code)'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        varname  wave                file_name               var_set  \\\n",
       "36  Neuroticism     7  sharew7_rel8-0-0_ac.dta  ['ac709_', 'ac704_']   \n",
       "37  Neuroticism     8  sharew8_rel8-0-0_ac.dta  ['ac709_', 'ac704_']   \n",
       "\n",
       "                                                                                         Notes  \\\n",
       "36  {'ac709_': 'gets nervous easily', 'ac704_': 'relaxed, handles stress well (reverse code)'}   \n",
       "37  {'ac709_': 'gets nervous easily', 'ac704_': 'relaxed, handles stress well (reverse code)'}   \n",
       "\n",
       "    recoded  \n",
       "36    False  \n",
       "37    False  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Neuroticism'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zneuroticism'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Zneuroticism',\n",
    " 'var_set': [{7: {'sharew7_rel8-0-0_ac.dta': ['ac709_', 'ac704_']},\n",
    "   8: {'sharew8_rel8-0-0_ac.dta': ['ac709_', 'ac704_']}}],\n",
    " 'available_waves': [7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Neuroticism',\n",
    " 'domain': 'Adulthood Adverse Experiences',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 7-------\n",
      "0                 Disagree a little\n",
      "1                    Agree a little\n",
      "2                 Disagree strongly\n",
      "3                    Agree a little\n",
      "4                 Disagree a little\n",
      "                    ...            \n",
      "77197             Disagree strongly\n",
      "77198             Disagree strongly\n",
      "77199             Disagree strongly\n",
      "77200    Neither agree nor disagree\n",
      "77201             Disagree a little\n",
      "Name: ac709_, Length: 77202, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "0        Neither agree nor disagree\n",
      "1                 Disagree strongly\n",
      "2                    Agree strongly\n",
      "3                    Agree a little\n",
      "4                    Agree a little\n",
      "                    ...            \n",
      "77197                Agree a little\n",
      "77198    Neither agree nor disagree\n",
      "77199                Agree strongly\n",
      "77200    Neither agree nor disagree\n",
      "77201                Agree strongly\n",
      "Name: ac704_, Length: 77202, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Disagree a little', 'Agree a little', 'Refusal', 'Disagree strongly', 'Neither agree nor disagree', 'Agree strongly', \"Don't know\"]\n",
      "no replace_dict been found for wave 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[84], line 12\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m column \u001B[38;5;129;01min\u001B[39;00m sliced_data\u001B[38;5;241m.\u001B[39mcolumns:\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28mprint\u001B[39m(sliced_data[column])\n\u001B[0;32m---> 12\u001B[0m df_recode_record,df_raw_recoded\u001B[38;5;241m=\u001B[39m\u001B[43mraw_multi_response_procedure\u001B[49m\u001B[43m(\u001B[49m\u001B[43msliced_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43mfile_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43mlatest_wave\u001B[49m\u001B[43m,\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdf_recode_record\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdf_raw_recoded\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[47], line 3\u001B[0m, in \u001B[0;36mraw_multi_response_procedure\u001B[0;34m(sliced_data, file_name, latest_wave, row, df_recode_record, df_raw_recoded)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraw_multi_response_procedure\u001B[39m(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;66;03m#1. replace\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m     row,sliced_data \u001B[38;5;241m=\u001B[39m \u001B[43mreplace_procedure\u001B[49m\u001B[43m(\u001B[49m\u001B[43msliced_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43mfile_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43mlatest_wave\u001B[49m\u001B[43m,\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m#2. deal with maximum missing response\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(var_set)\u001B[38;5;241m>\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "Cell \u001B[0;32mIn[54], line 43\u001B[0m, in \u001B[0;36mreplace_procedure\u001B[0;34m(sliced_data, file_name, latest_wave, row)\u001B[0m\n\u001B[1;32m     40\u001B[0m         row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreplace_dict\u001B[39m\u001B[38;5;124m'\u001B[39m][file_name] \u001B[38;5;241m=\u001B[39m row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreplace_dict\u001B[39m\u001B[38;5;124m'\u001B[39m][key]\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m#new dict?\u001B[39;00m\n\u001B[0;32m---> 43\u001B[0m replace_control\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdo you wish to generate/re-define a replace_dict for wave \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mlatest_wave\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m? 1->yes others->no\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m replace_control\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     45\u001B[0m     row \u001B[38;5;241m=\u001B[39mraw_replace(row,file_name)\n",
      "File \u001B[0;32m~/anaconda3/envs/OX_thesis/lib/python3.8/site-packages/ipykernel/kernelbase.py:1175\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[0;34m(self, prompt)\u001B[0m\n\u001B[1;32m   1171\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_allow_stdin:\n\u001B[1;32m   1172\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(\n\u001B[1;32m   1173\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1174\u001B[0m     )\n\u001B[0;32m-> 1175\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1176\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1178\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1179\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1180\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/OX_thesis/lib/python3.8/site-packages/ipykernel/kernelbase.py:1217\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[0;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[1;32m   1214\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m   1215\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[1;32m   1216\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[0;32m-> 1217\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m   1218\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1219\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sliced_data.columns:\n",
    "    print(sliced_data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_multi_response_procedure(sliced_data,file_name,latest_wave,row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Openness  `Zopenness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Openness</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac710_', 'ac705_']</td>\n",
       "      <td>{'ac710_': 'active imagination', 'ac705_': 'few artistic interests (reverse code)'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Openness</td>\n",
       "      <td>7</td>\n",
       "      <td>sharew7_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac710_', 'ac705_']</td>\n",
       "      <td>{'ac710_': 'active imagination', 'ac705_': 'few artistic interests (reverse code)'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     varname  wave                file_name               var_set  \\\n",
       "38  Openness     8  sharew8_rel8-0-0_ac.dta  ['ac710_', 'ac705_']   \n",
       "39  Openness     7  sharew7_rel8-0-0_ac.dta  ['ac710_', 'ac705_']   \n",
       "\n",
       "                                                                                  Notes  \\\n",
       "38  {'ac710_': 'active imagination', 'ac705_': 'few artistic interests (reverse code)'}   \n",
       "39  {'ac710_': 'active imagination', 'ac705_': 'few artistic interests (reverse code)'}   \n",
       "\n",
       "    recoded  \n",
       "38    False  \n",
       "39    False  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Openness'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = 'Zopenness'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sliced_data.columns:\n",
    "    print(sliced_data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_multi_response_procedure(sliced_data,file_name,latest_wave,row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conscientiousness  `Zneuroticism`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname_in_raw_recoder= ''\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = ''\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sliced_data.columns:\n",
    "    print(sliced_data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_multi_response_procedure(sliced_data,file_name,latest_wave,row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pessimism  `Zpessimism`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Pessimism</td>\n",
       "      <td>1</td>\n",
       "      <td>sharew1_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q3_d', 'q3_f']</td>\n",
       "      <td>{'q3_d': 'I hardly ever expect things to go my way', 'q3_f': 'I rarely count on good things happening to me'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Pessimism</td>\n",
       "      <td>2</td>\n",
       "      <td>sharew2_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q3_d', 'q3_f']</td>\n",
       "      <td>{'q3_d': 'I hardly ever expect things to go my way', 'q3_f': 'I rarely count on good things happening to me'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      varname  wave                     file_name           var_set  \\\n",
       "42  Pessimism     1  sharew1_rel8-0-0_dropoff.dta  ['q3_d', 'q3_f']   \n",
       "43  Pessimism     2  sharew2_rel8-0-0_dropoff.dta  ['q3_d', 'q3_f']   \n",
       "\n",
       "                                                                                                            Notes  \\\n",
       "42  {'q3_d': 'I hardly ever expect things to go my way', 'q3_f': 'I rarely count on good things happening to me'}   \n",
       "43  {'q3_d': 'I hardly ever expect things to go my way', 'q3_f': 'I rarely count on good things happening to me'}   \n",
       "\n",
       "    recoded  \n",
       "42    False  \n",
       "43    False  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Pessimism'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zpessimism'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Zpessimism',\n",
    " 'var_set': [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q3_d', 'q3_f']},\n",
    "   2: {'sharew2_rel8-0-0_dropoff.dta': ['q3_d', 'q3_f']}}],\n",
    " 'available_waves': [1, 2],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Pessimism',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 1-------\n",
      "0        Neither agree nor disagree\n",
      "1                             Agree\n",
      "2                             Agree\n",
      "3                          Disagree\n",
      "4                             Agree\n",
      "                    ...            \n",
      "20187                Strongly agree\n",
      "20188                         Agree\n",
      "20189                         Agree\n",
      "20190    Neither agree nor disagree\n",
      "20191                         Agree\n",
      "Name: q3_d, Length: 20192, dtype: category\n",
      "Categories (6, object): ['Not answered' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0        Neither agree nor disagree\n",
      "1        Neither agree nor disagree\n",
      "2        Neither agree nor disagree\n",
      "3                          Disagree\n",
      "4                    Strongly agree\n",
      "                    ...            \n",
      "20187                Strongly agree\n",
      "20188    Neither agree nor disagree\n",
      "20189    Neither agree nor disagree\n",
      "20190                      Disagree\n",
      "20191                         Agree\n",
      "Name: q3_f, Length: 20192, dtype: category\n",
      "Categories (6, object): ['Not answered' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Strongly agree', 'Strongly disagree', 'Neither agree nor disagree', 'Disagree', 'Not answered', 'Agree']\n",
      "no replace_dict been found for wave 1\n",
      "do you wish to generate/re-define a replace_dict for wave 1? 1->yes others->no1\n",
      "replace response [Strongly agree] with int .. (999 -> none)5\n",
      "replace response [Strongly disagree] with int .. (999 -> none)1\n",
      "replace response [Neither agree nor disagree] with int .. (999 -> none)3\n",
      "replace response [Disagree] with int .. (999 -> none)2\n",
      "replace response [Not answered] with int .. (999 -> none)999\n",
      "replace response [Agree] with int .. (999 -> none)4\n",
      "do you wish to replace data in 1? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    19458\n",
      "2      460\n",
      "1      274\n",
      "Name: missing_count, dtype: int64\n",
      "please specify the missing count (999 is none)2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 2-------\n",
      "0                            Agree\n",
      "1                            Agree\n",
      "2                         Disagree\n",
      "3       Neither agree nor disagree\n",
      "4                            Agree\n",
      "                   ...            \n",
      "8861    Neither agree nor disagree\n",
      "8862                      Disagree\n",
      "8863                      Disagree\n",
      "8864                         Agree\n",
      "8865                      Disagree\n",
      "Name: q3_d, Length: 8866, dtype: category\n",
      "Categories (7, object): ['Not answered' < 'Don't know' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0       Neither agree nor disagree\n",
      "1                            Agree\n",
      "2       Neither agree nor disagree\n",
      "3                            Agree\n",
      "4       Neither agree nor disagree\n",
      "                   ...            \n",
      "8861                         Agree\n",
      "8862    Neither agree nor disagree\n",
      "8863                         Agree\n",
      "8864                         Agree\n",
      "8865    Neither agree nor disagree\n",
      "Name: q3_f, Length: 8866, dtype: category\n",
      "Categories (7, object): ['Not answered' < 'Don't know' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Strongly agree', 'Strongly disagree', 'Neither agree nor disagree', 'Disagree', \"Don't know\", 'Not answered', 'Agree']\n",
      "no replace_dict been found for wave 2\n",
      "{'sharew1_rel8-0-0_dropoff.dta': {'Strongly agree': 5, 'Strongly disagree': 1, 'Neither agree nor disagree': 3, 'Disagree': 2, 'Not answered': None, 'Agree': 4, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no0\n",
      "do you wish to generate/re-define a replace_dict for wave 2? 1->yes others->no1\n",
      "replace response [Strongly agree] with int .. (999 -> none)5\n",
      "replace response [Strongly disagree] with int .. (999 -> none)1\n",
      "replace response [Neither agree nor disagree] with int .. (999 -> none)3\n",
      "replace response [Disagree] with int .. (999 -> none)2\n",
      "replace response [Don't know] with int .. (999 -> none)999\n",
      "replace response [Not answered] with int .. (999 -> none)999\n",
      "replace response [Agree] with int .. (999 -> none)4\n",
      "do you wish to replace data in 2? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    8625\n",
      "2     122\n",
      "1     119\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_dropoff.dta->{'Strongly agree': 5, 'Strongly disagree': 1, 'Neither agree nor disagree': 3, 'Disagree': 2, 'Not answered': None, 'Agree': 4, 'nan': None}\n",
      "sharew2_rel8-0-0_dropoff.dta->{'Strongly agree': 5, 'Strongly disagree': 1, 'Neither agree nor disagree': 3, 'Disagree': 2, \"Don't know\": None, 'Not answered': None, 'Agree': 4, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimism  `Zoptimism`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Optimism</td>\n",
       "      <td>1</td>\n",
       "      <td>sharew1_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q3_a', 'q3_b', 'q3_c', 'q3_e', 'q3_g']</td>\n",
       "      <td>{'q3_a': 'I pursue my goals with lots of energy', 'q3_b': 'In uncertain times, I usually expect the best', 'q3_c': \"I'm always optimistic about my future \", 'q3_e': 'I still find ways to solve a problem if others have given up', 'q3_g': 'Given my previous experiences I feel well prepared for my future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Optimism</td>\n",
       "      <td>2</td>\n",
       "      <td>sharew2_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q3_a', 'q3_b', 'q3_c', 'q3_e', 'q3_g']</td>\n",
       "      <td>{'q3_a': 'I pursue my goals with lots of energy', 'q3_b': 'In uncertain times, I usually expect the best', 'q3_c': \"I'm always optimistic about my future \", 'q3_e': 'I still find ways to solve a problem if others have given up', 'q3_g': 'Given my previous experiences I feel well prepared for my future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     varname  wave                     file_name  \\\n",
       "44  Optimism     1  sharew1_rel8-0-0_dropoff.dta   \n",
       "45  Optimism     2  sharew2_rel8-0-0_dropoff.dta   \n",
       "\n",
       "                                     var_set  \\\n",
       "44  ['q3_a', 'q3_b', 'q3_c', 'q3_e', 'q3_g']   \n",
       "45  ['q3_a', 'q3_b', 'q3_c', 'q3_e', 'q3_g']   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                               Notes  \\\n",
       "44  {'q3_a': 'I pursue my goals with lots of energy', 'q3_b': 'In uncertain times, I usually expect the best', 'q3_c': \"I'm always optimistic about my future \", 'q3_e': 'I still find ways to solve a problem if others have given up', 'q3_g': 'Given my previous experiences I feel well prepared for my future'}   \n",
       "45  {'q3_a': 'I pursue my goals with lots of energy', 'q3_b': 'In uncertain times, I usually expect the best', 'q3_c': \"I'm always optimistic about my future \", 'q3_e': 'I still find ways to solve a problem if others have given up', 'q3_g': 'Given my previous experiences I feel well prepared for my future'}   \n",
       "\n",
       "    recoded  \n",
       "44    False  \n",
       "45    False  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Optimism'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zoptimism'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Zoptimism',\n",
    " 'var_set': [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q3_a',\n",
    "     'q3_b',\n",
    "     'q3_c',\n",
    "     'q3_e',\n",
    "     'q3_g']},\n",
    "   2: {'sharew2_rel8-0-0_dropoff.dta': ['q3_a',\n",
    "     'q3_b',\n",
    "     'q3_c',\n",
    "     'q3_e',\n",
    "     'q3_g']}}],\n",
    " 'available_waves': [1, 2],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Optimism',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 1-------\n",
      "0        Neither agree nor disagree\n",
      "1        Neither agree nor disagree\n",
      "2                    Strongly agree\n",
      "3                    Strongly agree\n",
      "4        Neither agree nor disagree\n",
      "                    ...            \n",
      "20187                Strongly agree\n",
      "20188                         Agree\n",
      "20189                         Agree\n",
      "20190                Strongly agree\n",
      "20191                Strongly agree\n",
      "Name: q3_a, Length: 20192, dtype: category\n",
      "Categories (6, object): ['Not answered' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0        Neither agree nor disagree\n",
      "1                             Agree\n",
      "2                      Not answered\n",
      "3                             Agree\n",
      "4                             Agree\n",
      "                    ...            \n",
      "20187                      Disagree\n",
      "20188                Strongly agree\n",
      "20189                         Agree\n",
      "20190                         Agree\n",
      "20191    Neither agree nor disagree\n",
      "Name: q3_b, Length: 20192, dtype: category\n",
      "Categories (6, object): ['Not answered' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0                             Agree\n",
      "1                             Agree\n",
      "2                             Agree\n",
      "3                    Strongly agree\n",
      "4                             Agree\n",
      "                    ...            \n",
      "20187    Neither agree nor disagree\n",
      "20188                Strongly agree\n",
      "20189                         Agree\n",
      "20190                Strongly agree\n",
      "20191                         Agree\n",
      "Name: q3_c, Length: 20192, dtype: category\n",
      "Categories (6, object): ['Not answered' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0        Neither agree nor disagree\n",
      "1                             Agree\n",
      "2                             Agree\n",
      "3                    Strongly agree\n",
      "4                             Agree\n",
      "                    ...            \n",
      "20187                         Agree\n",
      "20188    Neither agree nor disagree\n",
      "20189                         Agree\n",
      "20190                         Agree\n",
      "20191                Strongly agree\n",
      "Name: q3_e, Length: 20192, dtype: category\n",
      "Categories (6, object): ['Not answered' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0                 Agree\n",
      "1                 Agree\n",
      "2        Strongly agree\n",
      "3                 Agree\n",
      "4        Strongly agree\n",
      "              ...      \n",
      "20187    Strongly agree\n",
      "20188    Strongly agree\n",
      "20189             Agree\n",
      "20190    Strongly agree\n",
      "20191    Strongly agree\n",
      "Name: q3_g, Length: 20192, dtype: category\n",
      "Categories (6, object): ['Not answered' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Strongly agree', 'Strongly disagree', 'Neither agree nor disagree', 'Disagree', 'Not answered', 'Agree']\n",
      "no replace_dict been found for wave 1\n",
      "do you wish to generate/re-define a replace_dict for wave 1? 1->yes others->no1\n",
      "replace response [Strongly agree] with int .. (999 -> none)1\n",
      "replace response [Strongly disagree] with int .. (999 -> none)5\n",
      "replace response [Neither agree nor disagree] with int .. (999 -> none)3\n",
      "replace response [Disagree] with int .. (999 -> none)4\n",
      "replace response [Not answered] with int .. (999 -> none)999\n",
      "replace response [Agree] with int .. (999 -> none)2\n",
      "do you wish to replace data in 1? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    19267\n",
      "1      376\n",
      "5      356\n",
      "4       72\n",
      "2       71\n",
      "3       50\n",
      "Name: missing_count, dtype: int64\n",
      "please specify the missing count (999 is none)4\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 2-------\n",
      "0                   Strongly agree\n",
      "1                            Agree\n",
      "2                            Agree\n",
      "3                   Strongly agree\n",
      "4                            Agree\n",
      "                   ...            \n",
      "8861    Neither agree nor disagree\n",
      "8862                         Agree\n",
      "8863                         Agree\n",
      "8864                Strongly agree\n",
      "8865    Neither agree nor disagree\n",
      "Name: q3_a, Length: 8866, dtype: category\n",
      "Categories (7, object): ['Not answered' < 'Don't know' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0       Neither agree nor disagree\n",
      "1                            Agree\n",
      "2                            Agree\n",
      "3                   Strongly agree\n",
      "4                            Agree\n",
      "                   ...            \n",
      "8861                         Agree\n",
      "8862    Neither agree nor disagree\n",
      "8863    Neither agree nor disagree\n",
      "8864                         Agree\n",
      "8865                         Agree\n",
      "Name: q3_b, Length: 8866, dtype: category\n",
      "Categories (7, object): ['Not answered' < 'Don't know' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0                            Agree\n",
      "1                            Agree\n",
      "2                            Agree\n",
      "3                   Strongly agree\n",
      "4                            Agree\n",
      "                   ...            \n",
      "8861                         Agree\n",
      "8862    Neither agree nor disagree\n",
      "8863                         Agree\n",
      "8864                         Agree\n",
      "8865                         Agree\n",
      "Name: q3_c, Length: 8866, dtype: category\n",
      "Categories (7, object): ['Not answered' < 'Don't know' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0                            Agree\n",
      "1       Neither agree nor disagree\n",
      "2                            Agree\n",
      "3                            Agree\n",
      "4                            Agree\n",
      "                   ...            \n",
      "8861                         Agree\n",
      "8862                         Agree\n",
      "8863                         Agree\n",
      "8864                         Agree\n",
      "8865                         Agree\n",
      "Name: q3_e, Length: 8866, dtype: category\n",
      "Categories (7, object): ['Not answered' < 'Don't know' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0       Neither agree nor disagree\n",
      "1                            Agree\n",
      "2                            Agree\n",
      "3                   Strongly agree\n",
      "4                            Agree\n",
      "                   ...            \n",
      "8861                         Agree\n",
      "8862                         Agree\n",
      "8863                         Agree\n",
      "8864                         Agree\n",
      "8865                         Agree\n",
      "Name: q3_g, Length: 8866, dtype: category\n",
      "Categories (7, object): ['Not answered' < 'Don't know' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Strongly agree', 'Strongly disagree', 'Neither agree nor disagree', 'Disagree', \"Don't know\", 'Not answered', 'Agree']\n",
      "no replace_dict been found for wave 2\n",
      "{'sharew1_rel8-0-0_dropoff.dta': {'Strongly agree': 1, 'Strongly disagree': 5, 'Neither agree nor disagree': 3, 'Disagree': 4, 'Not answered': None, 'Agree': 2, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no0\n",
      "do you wish to generate/re-define a replace_dict for wave 2? 1->yes others->no1\n",
      "replace response [Strongly agree] with int .. (999 -> none)1\n",
      "replace response [Strongly disagree] with int .. (999 -> none)5\n",
      "replace response [Neither agree nor disagree] with int .. (999 -> none)3\n",
      "replace response [Disagree] with int .. (999 -> none)4\n",
      "replace response [Don't know] with int .. (999 -> none)999\n",
      "replace response [Not answered] with int .. (999 -> none)999\n",
      "replace response [Agree] with int .. (999 -> none)2\n",
      "do you wish to replace data in 2? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    8514\n",
      "1     187\n",
      "5      86\n",
      "2      34\n",
      "4      27\n",
      "3      18\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 4\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change9\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_dropoff.dta->{'Strongly agree': 1, 'Strongly disagree': 5, 'Neither agree nor disagree': 3, 'Disagree': 4, 'Not answered': None, 'Agree': 2, 'nan': None}\n",
      "sharew2_rel8-0-0_dropoff.dta->{'Strongly agree': 1, 'Strongly disagree': 5, 'Neither agree nor disagree': 3, 'Disagree': 4, \"Don't know\": None, 'Not answered': None, 'Agree': 2, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Affect `Znegaffect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Negative Affect</td>\n",
       "      <td>1</td>\n",
       "      <td>sharew1_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q4_a', 'q4_b', 'q4_c', 'q4_e', 'q4_f', 'q4_h', 'q4_i', 'q4_j', 'q4_k', 'q4_m']</td>\n",
       "      <td>{'q4_a': 'I felt depressed', 'q4_b': 'I felt that everything I did was an effort', 'q4_c': 'My sleep was restless', 'q4_e': 'I felt lonely', 'q4_f': 'I felt people were unfriendly', 'q4_h': 'I felt sad', 'q4_i': 'I felt that people disliked me', 'q4_j': 'I could not get going', 'q4_k': 'I did not feel like eating/my appetite was poor', 'q4_m': 'I felt tired'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            varname  wave                     file_name  \\\n",
       "46  Negative Affect     1  sharew1_rel8-0-0_dropoff.dta   \n",
       "\n",
       "                                                                             var_set  \\\n",
       "46  ['q4_a', 'q4_b', 'q4_c', 'q4_e', 'q4_f', 'q4_h', 'q4_i', 'q4_j', 'q4_k', 'q4_m']   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                        Notes  \\\n",
       "46  {'q4_a': 'I felt depressed', 'q4_b': 'I felt that everything I did was an effort', 'q4_c': 'My sleep was restless', 'q4_e': 'I felt lonely', 'q4_f': 'I felt people were unfriendly', 'q4_h': 'I felt sad', 'q4_i': 'I felt that people disliked me', 'q4_j': 'I could not get going', 'q4_k': 'I did not feel like eating/my appetite was poor', 'q4_m': 'I felt tired'}   \n",
       "\n",
       "    recoded  \n",
       "46    False  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Negative Affect'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Znegaffect'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Znegaffect',\n",
    " 'var_set': [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q4_a',\n",
    "     'q4_b',\n",
    "     'q4_c',\n",
    "     'q4_e',\n",
    "     'q4_f',\n",
    "     'q4_h',\n",
    "     'q4_i',\n",
    "     'q4_j',\n",
    "     'q4_k',\n",
    "     'q4_m']}}],\n",
    " 'available_waves': [1],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Negative Affect',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 1-------\n",
      "0        Almost none of the time\n",
      "1        Almost none of the time\n",
      "2        Almost none of the time\n",
      "3        Almost none of the time\n",
      "4               Some of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190    Almost none of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_a, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1               Some of the time\n",
      "2        Almost none of the time\n",
      "3        Almost none of the time\n",
      "4               Most of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190           Some of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_b, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1        Almost none of the time\n",
      "2               Some of the time\n",
      "3        Almost none of the time\n",
      "4               Most of the time\n",
      "                  ...           \n",
      "20187           Some of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190    Almost none of the time\n",
      "20191           Some of the time\n",
      "Name: q4_c, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1               Some of the time\n",
      "2        Almost none of the time\n",
      "3        Almost none of the time\n",
      "4               Some of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190    Almost none of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_e, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1        Almost none of the time\n",
      "2        Almost none of the time\n",
      "3        Almost none of the time\n",
      "4               Some of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190           Some of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_f, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1        Almost none of the time\n",
      "2               Some of the time\n",
      "3        Almost none of the time\n",
      "4               Some of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190           Some of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_h, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1        Almost none of the time\n",
      "2        Almost none of the time\n",
      "3        Almost none of the time\n",
      "4               Some of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190           Some of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_i, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1        Almost none of the time\n",
      "2               Some of the time\n",
      "3        Almost none of the time\n",
      "4               Most of the time\n",
      "                  ...           \n",
      "20187           Some of the time\n",
      "20188    Almost none of the time\n",
      "20189               Not answered\n",
      "20190    Almost none of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_j, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1        Almost none of the time\n",
      "2        Almost none of the time\n",
      "3        Almost none of the time\n",
      "4               Some of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190    Almost none of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_k, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0               Some of the time\n",
      "1               Some of the time\n",
      "2               Some of the time\n",
      "3               Some of the time\n",
      "4               Some of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190           Some of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_m, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Almost none of the time', 'Almost all of the time', 'Most of the time', 'Not answered', 'Some of the time']\n",
      "no replace_dict been found for wave 1\n",
      "do you wish to generate/re-define a replace_dict for wave 1? 1->yes others->no1\n",
      "replace response [Almost none of the time] with int .. (999 -> none)1\n",
      "replace response [Almost all of the time] with int .. (999 -> none)4\n",
      "replace response [Most of the time] with int .. (999 -> none)3\n",
      "replace response [Not answered] with int .. (999 -> none)999\n",
      "replace response [Some of the time] with int .. (999 -> none)2\n",
      "do you wish to replace data in 1? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0     18691\n",
      "1       841\n",
      "10      264\n",
      "2       167\n",
      "9        46\n",
      "3        45\n",
      "8        34\n",
      "4        31\n",
      "5        31\n",
      "6        24\n",
      "7        18\n",
      "Name: missing_count, dtype: int64\n",
      "please specify the missing count (999 is none)9\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive Affect `Zposaffect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Positive Affect</td>\n",
       "      <td>1</td>\n",
       "      <td>sharew1_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q4_l', 'q4_g', 'q4_d']</td>\n",
       "      <td>{'q4_l': 'I had a lot of energy', 'q4_g': 'I enjoyed life', 'q4_d': 'I was happy'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            varname  wave                     file_name  \\\n",
       "47  Positive Affect     1  sharew1_rel8-0-0_dropoff.dta   \n",
       "\n",
       "                     var_set  \\\n",
       "47  ['q4_l', 'q4_g', 'q4_d']   \n",
       "\n",
       "                                                                                 Notes  \\\n",
       "47  {'q4_l': 'I had a lot of energy', 'q4_g': 'I enjoyed life', 'q4_d': 'I was happy'}   \n",
       "\n",
       "    recoded  \n",
       "47    False  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Positive Affect'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zposaffect'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Zposaffect',\n",
    " 'var_set': [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q4_l', 'q4_g', 'q4_d']}}],\n",
    " 'available_waves': [1],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Positive Affect',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 1-------\n",
      "0              Most of the time\n",
      "1              Most of the time\n",
      "2        Almost all of the time\n",
      "3        Almost all of the time\n",
      "4              Some of the time\n",
      "                  ...          \n",
      "20187          Most of the time\n",
      "20188          Most of the time\n",
      "20189          Most of the time\n",
      "20190    Almost all of the time\n",
      "20191          Most of the time\n",
      "Name: q4_l, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost all of the time\n",
      "1              Some of the time\n",
      "2        Almost all of the time\n",
      "3        Almost all of the time\n",
      "4        Almost all of the time\n",
      "                  ...          \n",
      "20187    Almost all of the time\n",
      "20188          Some of the time\n",
      "20189          Most of the time\n",
      "20190    Almost all of the time\n",
      "20191    Almost all of the time\n",
      "Name: q4_g, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0              Most of the time\n",
      "1              Most of the time\n",
      "2              Most of the time\n",
      "3        Almost all of the time\n",
      "4              Most of the time\n",
      "                  ...          \n",
      "20187          Some of the time\n",
      "20188          Most of the time\n",
      "20189          Most of the time\n",
      "20190          Most of the time\n",
      "20191          Some of the time\n",
      "Name: q4_d, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Almost none of the time', 'Almost all of the time', 'Most of the time', 'Not answered', 'Some of the time']\n",
      "no replace_dict been found for wave 1\n",
      "do you wish to generate/re-define a replace_dict for wave 1? 1->yes others->no1\n",
      "replace response [Almost none of the time] with int .. (999 -> none)4\n",
      "replace response [Almost all of the time] with int .. (999 -> none)1\n",
      "replace response [Most of the time] with int .. (999 -> none)2\n",
      "replace response [Not answered] with int .. (999 -> none)999\n",
      "replace response [Some of the time] with int .. (999 -> none)3\n",
      "do you wish to replace data in 1? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    19330\n",
      "1      425\n",
      "3      324\n",
      "2      113\n",
      "Name: missing_count, dtype: int64\n",
      "please specify the missing count (999 is none)2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sliced_data.columns:\n",
    "    print(sliced_data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_multi_response_procedure(sliced_data,file_name,latest_wave,row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult Psychosocial Adversity `sumadultAE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname_in_raw_recoder= ''\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = ''\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sliced_data.columns:\n",
    "    print(sliced_data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_multi_response_procedure(sliced_data,file_name,latest_wave,row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recode_record.to_csv(share_path/'recode_record.csv',index=False)\n",
    "df_raw_recoded.to_csv(share_path/'raw_recoded_data.csv',index=False)\n",
    "df_vars_found_in_raw.to_csv(Path.cwd()/'vars_found_in_raw'/'SHARE.csv',index=False)\n",
    "df.to_pickle(share_path/'recoded_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp Func Zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_recode_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total\n",
      "you have code 41 vars in total\n",
      "you have code 34 vars that are in HRS \n",
      "you have code 22 vars that are in ELSA \n",
      "\n",
      "Today\n",
      "you have code 10 vars in total\n",
      "you have code 10 vars that are in HRS \n",
      "you have code 0 vars that are in ELSA \n"
     ]
    }
   ],
   "source": [
    "print('In total')\n",
    "print('you have code {} vars in total'.format(len(df_recode_record)))\n",
    "print('you have code {} vars that are in HRS '.format(len(df_recode_record.loc[df_recode_record['in_HRS']==True])))\n",
    "print('you have code {} vars that are in ELSA '.format(len(df_recode_record.loc[df_recode_record['in_ELSA']==True])))\n",
    "\n",
    "print('\\nToday')\n",
    "df_recode_today=df_recode_record.loc[df_recode_record['recode_date']==today].copy()\n",
    "print('you have code {} vars in total'.format(len(df_recode_today)))\n",
    "print('you have code {} vars that are in HRS '.format(len(df_recode_today.loc[df_recode_today['in_HRS']==True])))\n",
    "print('you have code {} vars that are in ELSA '.format(len(df_recode_today.loc[df_recode_today['in_ELSA']==True])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>conventional_name</th>\n",
       "      <th>varname_in_raw</th>\n",
       "      <th>domain</th>\n",
       "      <th>available_waves</th>\n",
       "      <th>recode_type</th>\n",
       "      <th>reverse_code</th>\n",
       "      <th>maximum_missing_response</th>\n",
       "      <th>replace_dict</th>\n",
       "      <th>standardise</th>\n",
       "      <th>notes</th>\n",
       "      <th>recode_date</th>\n",
       "      <th>var_set</th>\n",
       "      <th>in_ELSA</th>\n",
       "      <th>in_HRS</th>\n",
       "      <th>wave_controller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lencurmarridge</td>\n",
       "      <td>length of current marriage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r1mcurln']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>currentpaternered</td>\n",
       "      <td>Current Marital Status: With Partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r8mstat']</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zeduccat</td>\n",
       "      <td>Lower Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.Primary education': 1, '3.Upper secondary education': 3, '2.Lower secondary education': 2, '5.First stage of tertiary education': 5, '0.None': None, '6.Second stage of tertiary education': 6, '4.Post-secondary non tertiary education': 4, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>not same as HRS, we use the ISCED 2 code for education category</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['raedisced']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rural</td>\n",
       "      <td>Residence in Rurual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.rural': 1, '0.urban': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>1:rural;-1:urban</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['h8rural']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>citizenship</td>\n",
       "      <td>Citizenship Status</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>whether citizen at baseline interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['racitizen']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>migrantYN</td>\n",
       "      <td>Foreign Born</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.in country': -1, '0.out of country': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>Born in Country of Interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['rabcountry']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>maleYN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.man': 1, '2.woman': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['ragender']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deathY</td>\n",
       "      <td>Death Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Others</td>\n",
       "      <td>[0]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['radyear']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>age</td>\n",
       "      <td>Age at Interview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r8agey']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>everunemployed</td>\n",
       "      <td>History of Unemployment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r1unemp', 'r2unemp', 'r4unemp', 'r5unemp', 'r6unemp', 'r7unemp', 'r8unemp']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vigactivityYN</td>\n",
       "      <td>Low/No Vigorous Activity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Health Behaviors</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'3.1 per week': -1, '4.1-3 per mon': 1, '2.&gt; 1 per week': -1, '5.hardly ever or never': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>&gt;=1 times/week, -1</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r8vgactx']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>modactivityYN</td>\n",
       "      <td>Low/No Moderate Activity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Health Behaviors</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'3.1 per week': -1, '4.1-3 per mon': 1, '2.&gt; 1 per week': -1, '5.hardly ever or never': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>&gt;=1 times/week, -1</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r8mdactx']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>alcoholYN</td>\n",
       "      <td>Alcohol Abuse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Health Behaviors</td>\n",
       "      <td>[2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.yes': 1, '0.no': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>Directly using the definition of binge drunk from SHARE</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r8drinkb']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>eversmokeYN</td>\n",
       "      <td>History of Smoking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Health Behaviors</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r1smokev', 'r2smokev', 'r4smokev', 'r5smokev', 'r6smokev', 'r7smokev', 'r8smokev']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>currsmokeYN</td>\n",
       "      <td>Current Smoker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Health Behaviors</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r8smokev']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>everalcoholYN</td>\n",
       "      <td>History of drink</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Health Behaviors</td>\n",
       "      <td>[2, 4, 5]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.yes': 1, '0.no': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r2drinkev', 'r4drinkev', 'r5drinkev']</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>drink_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>chilstrevents</td>\n",
       "      <td>Sum of Childhood Stressful Events</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Childhood Adversity</td>\n",
       "      <td>[0]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['racsevent_s']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>everfindiff</td>\n",
       "      <td>History of Financial Difficulties</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[3, 7]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.yes': 1, '0.no': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['r3sfnhe', 'r7sfnhe']</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>financial_difficulties_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>everrent</td>\n",
       "      <td>History Of Renting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'3.other arrangements': -1, '2.rents home': 1, '1.owns home': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r1hownrnt', 'r2hownrnt', 'r4hownrnt', 'r5hownrnt', 'r6hownrnt', 'r7hownrnt', 'r8hownrnt']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sleepYN</td>\n",
       "      <td>Sleep Problems</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Health Behaviors</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.yes': 1, '0.no': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>r been asked have you have trouble recently in sleeping</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['r8sleep']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>everdivorced</td>\n",
       "      <td>History Of Divorce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'7.widowed': -1, '1.married': -1, '8.never married': -1, '3.partnered': -1, '5.divorced': 1, '4.separated': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['r1mstat', 'r2mstat', 'r4mstat', 'r5mstat', 'r6mstat', 'r7mstat', 'r8mstat']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nevermarried</td>\n",
       "      <td>Never Married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'7.widowed': -1, '1.married': -1, '8.never married': 1, '3.partnered': -1, '5.divorced': -1, '4.separated': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['r8mstat']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Zlifesatis</td>\n",
       "      <td>Life Satisfaction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>This is an one-question Z-score, different to the HRS definition</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['r8satlifez']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Zmotherseduc</td>\n",
       "      <td>Lower Maternal Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Childhood Adversity</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>isced standard</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['ramomedisced']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Zfatherseduc</td>\n",
       "      <td>Lower Paternal Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Childhood Adversity</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>isced standard</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['radadedisced']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fathersocc</td>\n",
       "      <td>Lower Main Carer Occupational Status</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Childhood Adversity</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'7.Craft or related trades worker': 5, '6.Skilled agricultural or fishery worker': 5, '11.Spontaneous only: there was no main breadwinner': None, '2.Professional': 2, '9.Elementary occupation': 6, '10.Armed forces': 4, '4.Clerk': 3, '8.Plant/machine operator or assembler': 6, '5.Service, shop or market sales worker': 3, '3.Technician or associate professional': 2, '1.Legislator, senior official or manager': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>not just for father, but the main carer</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['ramaoccup']</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ZwealthT</td>\n",
       "      <td>Wealth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>['h8atotb']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ZincomeT</td>\n",
       "      <td>Total Income</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>special_code</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(after tax) adding together Individual Earnings, Employer Capital Income, Pension or Annuity,Public Pensions,Other Government Transfers,Other Individual Income</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>['r8itearn', 'r8itsemp', 'r8itpena', 'r8itpubpen', 'r8itgxfr', 'r8itothr']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HIncome</td>\n",
       "      <td>Total Household Income</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>['h8ittot']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Row Recode, Manual</td>\n",
       "      <td>2023-02-18</td>\n",
       "      <td>[{1: ['q2_b', 'q2_c'], 2: ['ac015_'], 4: ['ac015_'], 5: ['ac015_'], 6: ['ac015_'], 7: ['ac015_'], 8: ['ac015_']}]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Zperceivedconstraints</td>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'sharew1_rel8-0-0_dropoff.dta': {1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 'nan': None}}</td>\n",
       "      <td>False</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-18</td>\n",
       "      <td>[{1: {'sharew1_rel8-0-0_dropoff.dta': ['q2_b', 'q2_c']}, 2: {'sharew2_rel8-0-0_ac.dta': ['ac015_']}, 4: {'sharew4_rel8-0-0_ac.dta': ['ac015_']}, 5: {'sharew5_rel8-0-0_ac.dta': ['ac015_']}, 6: {'sharew6_rel8-0-0_ac.dta': ['ac015_']}, 7: {'sharew7_rel8-0-0_ac.dta': ['ac015_']}, 8: {'sharew8_rel8-0-0_ac.dta': ['ac015_']}}]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Zanxiety</td>\n",
       "      <td>Trait Anxiety</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>{'sharew4_rel8-0-0_mh.dta': {'Hardly ever': 2, 'Refusal': None, 'Never': 1, 'Most of the time': 4, 'Don't know': None, 'Some of the time': 3, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Hardly ever': 2, 'Refusal': None, 'Never': 1, 'Most of the time': 4, 'Don't know': None, 'Some of the time': 3, 'nan': None}}</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{4: {'sharew4_rel8-0-0_mh.dta': ['mh023_', 'mh024_', 'mh025_', 'mh026_', 'mh027_']}, 5: {'sharew5_rel8-0-0_mh.dta': ['mh023_', 'mh024_', 'mh025_', 'mh026_', 'mh027_']}}]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Zhopelessness</td>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'sharew1_rel8-0-0_mh.dta': {'Refusal': None, 'Don't know': None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew2_rel8-0-0_mh.dta': {'Refusal': None, 'Don't know': None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew4_rel8-0-0_mh.dta': {'Refusal': None, 'Don't know': None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Refusal': None, 'Don't know': None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew6_rel8-0-0_mh.dta': {'Refusal': None, 'Don't know': None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew7_rel8-0-0_mh.dta': {'Refusal': None, 'Don't know': None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew8_rel8-0-0_mh.dta': {'Refusal': None, 'Don't know': None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}}</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{1: {'sharew1_rel8-0-0_mh.dta': ['mh003_']}, 2: {'sharew2_rel8-0-0_mh.dta': ['mh003_']}, 4: {'sharew4_rel8-0-0_mh.dta': ['mh003_']}, 5: {'sharew5_rel8-0-0_mh.dta': ['mh003_']}, 6: {'sharew6_rel8-0-0_mh.dta': ['mh003_']}, 7: {'sharew7_rel8-0-0_mh.dta': ['mh003_']}, 8: {'sharew8_rel8-0-0_mh.dta': ['mh003_']}}]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Zloneliness</td>\n",
       "      <td>loneliness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[4, 5, 6, 7, 8]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>{'sharew4_rel8-0-0_dropoff.dta': {'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, 'Don't know': None, 'Some of the time': 2, 'nan': None}, 'sharew6_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, 'Don't know': None, 'Some of the time': 2, 'nan': None}, 'sharew7_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, 'Don't know': None, 'Some of the time': 2, 'nan': None}, 'sharew8_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, 'Don't know': None, 'Some of the time': 2, 'nan': None}}</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{4: {'sharew4_rel8-0-0_dropoff.dta': ['q5a', 'q5b', 'q5c', 'q5d']}, 5: {'sharew5_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']}, 6: {'sharew6_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']}, 7: {'sharew7_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']}, 8: {'sharew8_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']}}]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Zagreeableness</td>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'sharew7_rel8-0-0_ac.dta': {'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, 'Don't know': None, 'nan': None}, 'sharew8_rel8-0-0_ac.dta': {'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, 'Don't know': None, 'nan': None}}</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{7: {'sharew7_rel8-0-0_ac.dta': ['ac702_', 'ac711_']}, 8: {'sharew8_rel8-0-0_ac.dta': ['ac702_', 'ac711_']}}]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Zextroversion</td>\n",
       "      <td>Extroversion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'sharew7_rel8-0-0_ac.dta': {'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, 'Don't know': None, 'nan': None}, 'sharew8_rel8-0-0_ac.dta': {'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, 'Don't know': None, 'nan': None}}</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{7: {'sharew7_rel8-0-0_ac.dta': ['ac706_', 'ac711_']}, 8: {'sharew8_rel8-0-0_ac.dta': ['ac706_', 'ac711_']}}]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Zneuroticism</td>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Adverse Experiences</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{7: {'sharew7_rel8-0-0_ac.dta': ['ac709_', 'ac704_']}, 8: {'sharew8_rel8-0-0_ac.dta': ['ac709_', 'ac704_']}}]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Zpessimism</td>\n",
       "      <td>Pessimism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'sharew1_rel8-0-0_dropoff.dta': {'Strongly agree': 5, 'Strongly disagree': 1, 'Neither agree nor disagree': 3, 'Disagree': 2, 'Not answered': None, 'Agree': 4, 'nan': None}, 'sharew2_rel8-0-0_dropoff.dta': {'Strongly agree': 5, 'Strongly disagree': 1, 'Neither agree nor disagree': 3, 'Disagree': 2, 'Don't know': None, 'Not answered': None, 'Agree': 4, 'nan': None}}</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{1: {'sharew1_rel8-0-0_dropoff.dta': ['q3_d', 'q3_f']}, 2: {'sharew2_rel8-0-0_dropoff.dta': ['q3_d', 'q3_f']}}]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Zoptimism</td>\n",
       "      <td>Optimism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>{'sharew1_rel8-0-0_dropoff.dta': {'Strongly agree': 1, 'Strongly disagree': 5, 'Neither agree nor disagree': 3, 'Disagree': 4, 'Not answered': None, 'Agree': 2, 'nan': None}, 'sharew2_rel8-0-0_dropoff.dta': {'Strongly agree': 1, 'Strongly disagree': 5, 'Neither agree nor disagree': 3, 'Disagree': 4, 'Don't know': None, 'Not answered': None, 'Agree': 2, 'nan': None}}</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{1: {'sharew1_rel8-0-0_dropoff.dta': ['q3_a', 'q3_b', 'q3_c', 'q3_e', 'q3_g']}, 2: {'sharew2_rel8-0-0_dropoff.dta': ['q3_a', 'q3_b', 'q3_c', 'q3_e', 'q3_g']}}]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Znegaffect</td>\n",
       "      <td>Negative Affect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[1]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>{'sharew1_rel8-0-0_dropoff.dta': {'Almost none of the time': 1, 'Almost all of the time': 4, 'Most of the time': 3, 'Not answered': None, 'Some of the time': 2, 'nan': None}}</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{1: {'sharew1_rel8-0-0_dropoff.dta': ['q4_a', 'q4_b', 'q4_c', 'q4_e', 'q4_f', 'q4_h', 'q4_i', 'q4_j', 'q4_k', 'q4_m']}}]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Zposaffect</td>\n",
       "      <td>Positive Affect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[1]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'sharew1_rel8-0-0_dropoff.dta': {'Almost none of the time': 4, 'Almost all of the time': 1, 'Most of the time': 2, 'Not answered': None, 'Some of the time': 3, 'nan': None}}</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{1: {'sharew1_rel8-0-0_dropoff.dta': ['q4_l', 'q4_g', 'q4_d']}}]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  varname                         conventional_name  \\\n",
       "0          lencurmarridge                length of current marriage   \n",
       "1       currentpaternered  Current Marital Status: With Partnership   \n",
       "2                Zeduccat                           Lower Education   \n",
       "3                   rural                       Residence in Rurual   \n",
       "4             citizenship                        Citizenship Status   \n",
       "5               migrantYN                              Foreign Born   \n",
       "6                  maleYN                                      Male   \n",
       "7                  deathY                                Death Year   \n",
       "8                     age                          Age at Interview   \n",
       "9          everunemployed                   History of Unemployment   \n",
       "10          vigactivityYN                  Low/No Vigorous Activity   \n",
       "11          modactivityYN                  Low/No Moderate Activity   \n",
       "12              alcoholYN                             Alcohol Abuse   \n",
       "13            eversmokeYN                        History of Smoking   \n",
       "14            currsmokeYN                            Current Smoker   \n",
       "15          everalcoholYN                          History of drink   \n",
       "16          chilstrevents         Sum of Childhood Stressful Events   \n",
       "17            everfindiff         History of Financial Difficulties   \n",
       "18               everrent                        History Of Renting   \n",
       "19                sleepYN                            Sleep Problems   \n",
       "20           everdivorced                        History Of Divorce   \n",
       "21           nevermarried                             Never Married   \n",
       "22             Zlifesatis                         Life Satisfaction   \n",
       "23           Zmotherseduc                  Lower Maternal Education   \n",
       "24           Zfatherseduc                  Lower Paternal Education   \n",
       "25             fathersocc      Lower Main Carer Occupational Status   \n",
       "26               ZwealthT                                    Wealth   \n",
       "27               ZincomeT                              Total Income   \n",
       "28                HIncome                    Total Household Income   \n",
       "29  Perceived Constraints                     Perceived Constraints   \n",
       "30  Zperceivedconstraints                     Perceived Constraints   \n",
       "31               Zanxiety                             Trait Anxiety   \n",
       "32          Zhopelessness                              Hopelessness   \n",
       "33            Zloneliness                                loneliness   \n",
       "34         Zagreeableness                             Agreeableness   \n",
       "35          Zextroversion                              Extroversion   \n",
       "36           Zneuroticism                               Neuroticism   \n",
       "37             Zpessimism                                 Pessimism   \n",
       "38              Zoptimism                                  Optimism   \n",
       "39             Znegaffect                           Negative Affect   \n",
       "40             Zposaffect                           Positive Affect   \n",
       "\n",
       "    varname_in_raw                         domain           available_waves  \\\n",
       "0              NaN        Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "1              NaN        Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "2              NaN        Adulthood Socioeconomic                       [0]   \n",
       "3              NaN                    Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "4              NaN                    Demographic                       [0]   \n",
       "5              NaN                    Demographic                       [0]   \n",
       "6              NaN                    Demographic                       [0]   \n",
       "7              NaN                         Others                       [0]   \n",
       "8              NaN                    Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "9              NaN        Adulthood Socioeconomic     [1, 2, 4, 5, 6, 7, 8]   \n",
       "10             NaN     Adulthood Health Behaviors     [1, 2, 4, 5, 6, 7, 8]   \n",
       "11             NaN     Adulthood Health Behaviors     [1, 2, 4, 5, 6, 7, 8]   \n",
       "12             NaN     Adulthood Health Behaviors        [2, 4, 5, 6, 7, 8]   \n",
       "13             NaN     Adulthood Health Behaviors     [1, 2, 4, 5, 6, 7, 8]   \n",
       "14             NaN     Adulthood Health Behaviors     [1, 2, 4, 5, 6, 7, 8]   \n",
       "15             NaN     Adulthood Health Behaviors                 [2, 4, 5]   \n",
       "16             NaN            Childhood Adversity                       [0]   \n",
       "17             NaN        Adulthood Socioeconomic                    [3, 7]   \n",
       "18             NaN        Adulthood Socioeconomic     [1, 2, 4, 5, 6, 7, 8]   \n",
       "19             NaN     Adulthood Health Behaviors     [1, 2, 4, 5, 6, 7, 8]   \n",
       "20             NaN        Adulthood Socioeconomic     [1, 2, 4, 5, 6, 7, 8]   \n",
       "21             NaN        Adulthood Socioeconomic     [1, 2, 4, 5, 6, 7, 8]   \n",
       "22             NaN        Adulthood Psychological        [2, 4, 5, 6, 7, 8]   \n",
       "23             NaN            Childhood Adversity                       [0]   \n",
       "24             NaN            Childhood Adversity                       [0]   \n",
       "25             NaN            Childhood Adversity                       [0]   \n",
       "26             NaN        Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "27             NaN        Adulthood Socioeconomic        [2, 4, 5, 6, 7, 8]   \n",
       "28             NaN        Adulthood Socioeconomic        [2, 4, 5, 6, 7, 8]   \n",
       "29             NaN        Adulthood Psychological     [1, 2, 4, 5, 6, 7, 8]   \n",
       "30             NaN        Adulthood Psychological     [1, 2, 4, 5, 6, 7, 8]   \n",
       "31             NaN        Adulthood Psychological                    [4, 5]   \n",
       "32             NaN        Adulthood Psychological     [1, 2, 4, 5, 6, 7, 8]   \n",
       "33             NaN        Adulthood Psychological           [4, 5, 6, 7, 8]   \n",
       "34             NaN        Adulthood Psychological                    [7, 8]   \n",
       "35             NaN        Adulthood Psychological                    [7, 8]   \n",
       "36             NaN  Adulthood Adverse Experiences                    [7, 8]   \n",
       "37             NaN        Adulthood Psychological                    [1, 2]   \n",
       "38             NaN        Adulthood Psychological                    [1, 2]   \n",
       "39             NaN        Adulthood Psychological                       [1]   \n",
       "40             NaN        Adulthood Psychological                       [1]   \n",
       "\n",
       "     recode_type reverse_code  maximum_missing_response  \\\n",
       "0     direct_use        False                       NaN   \n",
       "1   replace_only        False                       NaN   \n",
       "2   replace_only         True                       NaN   \n",
       "3   replace_only        False                       NaN   \n",
       "4   replace_only        False                       NaN   \n",
       "5   replace_only        False                       NaN   \n",
       "6   replace_only        False                       NaN   \n",
       "7     direct_use        False                       NaN   \n",
       "8     direct_use        False                       NaN   \n",
       "9     historical        False                       NaN   \n",
       "10  replace_only        False                       NaN   \n",
       "11  replace_only        False                       NaN   \n",
       "12  replace_only        False                       NaN   \n",
       "13    historical        False                       NaN   \n",
       "14  replace_only        False                       NaN   \n",
       "15    historical        False                       NaN   \n",
       "16    direct_use        False                       NaN   \n",
       "17    historical        False                       NaN   \n",
       "18    historical        False                       NaN   \n",
       "19  replace_only        False                       NaN   \n",
       "20    historical        False                       NaN   \n",
       "21  replace_only        False                       NaN   \n",
       "22    direct_use        False                       NaN   \n",
       "23  replace_only         True                       NaN   \n",
       "24  replace_only         True                       NaN   \n",
       "25  replace_only        False                       NaN   \n",
       "26    direct_use        False                       NaN   \n",
       "27  special_code        False                       NaN   \n",
       "28    direct_use        False                       NaN   \n",
       "29    row_manual        False                       NaN   \n",
       "30    row_manual        False                       NaN   \n",
       "31    row_manual        False                       3.0   \n",
       "32    row_manual        False                       NaN   \n",
       "33    row_manual        False                       4.0   \n",
       "34    row_manual        False                       2.0   \n",
       "35    row_manual        False                       2.0   \n",
       "36    row_manual        False                       NaN   \n",
       "37    row_manual        False                       2.0   \n",
       "38    row_manual        False                       4.0   \n",
       "39    row_manual        False                       9.0   \n",
       "40    row_manual        False                       2.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             replace_dict  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          {'1.Primary education': 1, '3.Upper secondary education': 3, '2.Lower secondary education': 2, '5.First stage of tertiary education': 5, '0.None': None, '6.Second stage of tertiary education': 6, '4.Post-secondary non tertiary education': 4, 'nan': None}   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              {'1.rural': 1, '0.urban': -1, 'nan': None}   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   {'0.No': -1, '1.Yes': 1, 'nan': None}   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {'1.in country': -1, '0.out of country': 1, 'nan': None}   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {'1.man': 1, '2.woman': -1, 'nan': None}   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   {'0.No': -1, '1.Yes': 1, 'nan': None}   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               {'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None}   \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               {'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None}   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  {'1.yes': 1, '0.no': -1, 'nan': None}   \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  {'0.No': -1, '1.Yes': 1, 'nan': None}   \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  {'0.No': -1, '1.Yes': 1, 'nan': None}   \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  {'1.yes': 1, '0.no': -1, 'nan': None}   \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    NaN   \n",
       "17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  {'1.yes': 1, '0.no': -1, 'nan': None}   \n",
       "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        {'3.other arrangements': -1, '2.rents home': 1, '1.owns home': -1, 'nan': None}   \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  {'1.yes': 1, '0.no': -1, 'nan': None}   \n",
       "20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {'7.widowed': -1, '1.married': -1, '8.never married': -1, '3.partnered': -1, '5.divorced': 1, '4.separated': 1, 'nan': None}   \n",
       "21                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          {'7.widowed': -1, '1.married': -1, '8.never married': 1, '3.partnered': -1, '5.divorced': -1, '4.separated': -1, 'nan': None}   \n",
       "22                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    NaN   \n",
       "23                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         {'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None}   \n",
       "24                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         {'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None}   \n",
       "25                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {'7.Craft or related trades worker': 5, '6.Skilled agricultural or fishery worker': 5, '11.Spontaneous only: there was no main breadwinner': None, '2.Professional': 2, '9.Elementary occupation': 6, '10.Armed forces': 4, '4.Clerk': 3, '8.Plant/machine operator or assembler': 6, '5.Service, shop or market sales worker': 3, '3.Technician or associate professional': 2, '1.Legislator, senior official or manager': 1, 'nan': None}   \n",
       "26                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    NaN   \n",
       "27                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    NaN   \n",
       "28                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    NaN   \n",
       "29                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    NaN   \n",
       "30                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        {'sharew1_rel8-0-0_dropoff.dta': {1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 'nan': None}}   \n",
       "31                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 {'sharew4_rel8-0-0_mh.dta': {'Hardly ever': 2, 'Refusal': None, 'Never': 1, 'Most of the time': 4, 'Don't know': None, 'Some of the time': 3, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Hardly ever': 2, 'Refusal': None, 'Never': 1, 'Most of the time': 4, 'Don't know': None, 'Some of the time': 3, 'nan': None}}   \n",
       "32  {'sharew1_rel8-0-0_mh.dta': {'Refusal': None, 'Don't know': None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew2_rel8-0-0_mh.dta': {'Refusal': None, 'Don't know': None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew4_rel8-0-0_mh.dta': {'Refusal': None, 'Don't know': None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Refusal': None, 'Don't know': None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew6_rel8-0-0_mh.dta': {'Refusal': None, 'Don't know': None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew7_rel8-0-0_mh.dta': {'Refusal': None, 'Don't know': None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew8_rel8-0-0_mh.dta': {'Refusal': None, 'Don't know': None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}}   \n",
       "33                                                                                                                                                                                                                                {'sharew4_rel8-0-0_dropoff.dta': {'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, 'Don't know': None, 'Some of the time': 2, 'nan': None}, 'sharew6_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, 'Don't know': None, 'Some of the time': 2, 'nan': None}, 'sharew7_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, 'Don't know': None, 'Some of the time': 2, 'nan': None}, 'sharew8_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, 'Don't know': None, 'Some of the time': 2, 'nan': None}}   \n",
       "34                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   {'sharew7_rel8-0-0_ac.dta': {'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, 'Don't know': None, 'nan': None}, 'sharew8_rel8-0-0_ac.dta': {'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, 'Don't know': None, 'nan': None}}   \n",
       "35                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   {'sharew7_rel8-0-0_ac.dta': {'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, 'Don't know': None, 'nan': None}, 'sharew8_rel8-0-0_ac.dta': {'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, 'Don't know': None, 'nan': None}}   \n",
       "36                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   None   \n",
       "37                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       {'sharew1_rel8-0-0_dropoff.dta': {'Strongly agree': 5, 'Strongly disagree': 1, 'Neither agree nor disagree': 3, 'Disagree': 2, 'Not answered': None, 'Agree': 4, 'nan': None}, 'sharew2_rel8-0-0_dropoff.dta': {'Strongly agree': 5, 'Strongly disagree': 1, 'Neither agree nor disagree': 3, 'Disagree': 2, 'Don't know': None, 'Not answered': None, 'Agree': 4, 'nan': None}}   \n",
       "38                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       {'sharew1_rel8-0-0_dropoff.dta': {'Strongly agree': 1, 'Strongly disagree': 5, 'Neither agree nor disagree': 3, 'Disagree': 4, 'Not answered': None, 'Agree': 2, 'nan': None}, 'sharew2_rel8-0-0_dropoff.dta': {'Strongly agree': 1, 'Strongly disagree': 5, 'Neither agree nor disagree': 3, 'Disagree': 4, 'Don't know': None, 'Not answered': None, 'Agree': 2, 'nan': None}}   \n",
       "39                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         {'sharew1_rel8-0-0_dropoff.dta': {'Almost none of the time': 1, 'Almost all of the time': 4, 'Most of the time': 3, 'Not answered': None, 'Some of the time': 2, 'nan': None}}   \n",
       "40                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         {'sharew1_rel8-0-0_dropoff.dta': {'Almost none of the time': 4, 'Almost all of the time': 1, 'Most of the time': 2, 'Not answered': None, 'Some of the time': 3, 'nan': None}}   \n",
       "\n",
       "   standardise  \\\n",
       "0         True   \n",
       "1         True   \n",
       "2         True   \n",
       "3         True   \n",
       "4         True   \n",
       "5         True   \n",
       "6         True   \n",
       "7        False   \n",
       "8         True   \n",
       "9         True   \n",
       "10        True   \n",
       "11        True   \n",
       "12        True   \n",
       "13        True   \n",
       "14        True   \n",
       "15        True   \n",
       "16        True   \n",
       "17        True   \n",
       "18        True   \n",
       "19        True   \n",
       "20        True   \n",
       "21        True   \n",
       "22        True   \n",
       "23        True   \n",
       "24        True   \n",
       "25        True   \n",
       "26        True   \n",
       "27        True   \n",
       "28        True   \n",
       "29       False   \n",
       "30       False   \n",
       "31        True   \n",
       "32        True   \n",
       "33        True   \n",
       "34        True   \n",
       "35        True   \n",
       "36        True   \n",
       "37        True   \n",
       "38        True   \n",
       "39        True   \n",
       "40        True   \n",
       "\n",
       "                                                                                                                                                              notes  \\\n",
       "0                                                                                                                                                               NaN   \n",
       "1                                                                                                                                                               NaN   \n",
       "2                                                                                                   not same as HRS, we use the ISCED 2 code for education category   \n",
       "3                                                                                                                                                  1:rural;-1:urban   \n",
       "4                                                                                                                             whether citizen at baseline interview   \n",
       "5                                                                                                                                      Born in Country of Interview   \n",
       "6                                                                                                                                                               NaN   \n",
       "7                                                                                                                                                               NaN   \n",
       "8                                                                                                                                                               NaN   \n",
       "9                                                                                                                                                               NaN   \n",
       "10                                                                                                                                               >=1 times/week, -1   \n",
       "11                                                                                                                                               >=1 times/week, -1   \n",
       "12                                                                                                          Directly using the definition of binge drunk from SHARE   \n",
       "13                                                                                                                                                              NaN   \n",
       "14                                                                                                                                                              NaN   \n",
       "15                                                                                                                                                              NaN   \n",
       "16                                                                                                                                                              NaN   \n",
       "17                                                                                                                                                              NaN   \n",
       "18                                                                                                                                                              NaN   \n",
       "19                                                                                                          r been asked have you have trouble recently in sleeping   \n",
       "20                                                                                                                                                              NaN   \n",
       "21                                                                                                                                                              NaN   \n",
       "22                                                                                                 This is an one-question Z-score, different to the HRS definition   \n",
       "23                                                                                                                                                   isced standard   \n",
       "24                                                                                                                                                   isced standard   \n",
       "25                                                                                                                          not just for father, but the main carer   \n",
       "26                                                                                                                                                              NaN   \n",
       "27  (after tax) adding together Individual Earnings, Employer Capital Income, Pension or Annuity,Public Pensions,Other Government Transfers,Other Individual Income   \n",
       "28                                                                                                                                                              NaN   \n",
       "29                                                                                                                                               Row Recode, Manual   \n",
       "30                                                                                                                                               Raw Recode, Manual   \n",
       "31                                                                                                                                               Raw Recode, Manual   \n",
       "32                                                                                                                                               Raw Recode, Manual   \n",
       "33                                                                                                                                               Raw Recode, Manual   \n",
       "34                                                                                                                                               Raw Recode, Manual   \n",
       "35                                                                                                                                               Raw Recode, Manual   \n",
       "36                                                                                                                                               Raw Recode, Manual   \n",
       "37                                                                                                                                               Raw Recode, Manual   \n",
       "38                                                                                                                                               Raw Recode, Manual   \n",
       "39                                                                                                                                               Raw Recode, Manual   \n",
       "40                                                                                                                                               Raw Recode, Manual   \n",
       "\n",
       "   recode_date  \\\n",
       "0   2023-01-10   \n",
       "1   2023-01-10   \n",
       "2   2023-01-10   \n",
       "3   2023-01-10   \n",
       "4   2023-01-10   \n",
       "5   2023-01-10   \n",
       "6   2023-01-10   \n",
       "7   2023-01-10   \n",
       "8   2023-01-10   \n",
       "9   2023-01-10   \n",
       "10  2023-01-10   \n",
       "11  2023-01-10   \n",
       "12  2023-01-10   \n",
       "13  2023-01-10   \n",
       "14  2023-01-10   \n",
       "15  2023-01-10   \n",
       "16  2023-01-11   \n",
       "17  2023-01-11   \n",
       "18  2023-01-10   \n",
       "19  2023-01-11   \n",
       "20  2023-01-11   \n",
       "21  2023-01-11   \n",
       "22  2023-01-11   \n",
       "23  2023-01-11   \n",
       "24  2023-01-11   \n",
       "25  2023-01-11   \n",
       "26  2023-01-12   \n",
       "27  2023-01-12   \n",
       "28  2023-01-12   \n",
       "29  2023-02-18   \n",
       "30  2023-02-18   \n",
       "31  2023-02-19   \n",
       "32  2023-02-19   \n",
       "33  2023-02-19   \n",
       "34  2023-02-19   \n",
       "35  2023-02-19   \n",
       "36  2023-02-19   \n",
       "37  2023-02-19   \n",
       "38  2023-02-19   \n",
       "39  2023-02-19   \n",
       "40  2023-02-19   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                          var_set  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                    ['r1mcurln']   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                     ['r8mstat']   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                   ['raedisced']   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                     ['h8rural']   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                   ['racitizen']   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                  ['rabcountry']   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                    ['ragender']   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                     ['radyear']   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                      ['r8agey']   \n",
       "9                                                                                                                                                                                                                                                                                                   ['r1unemp', 'r2unemp', 'r4unemp', 'r5unemp', 'r6unemp', 'r7unemp', 'r8unemp']   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                   ['r8vgactx']   \n",
       "11                                                                                                                                                                                                                                                                                                                                                                   ['r8mdactx']   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                   ['r8drinkb']   \n",
       "13                                                                                                                                                                                                                                                                                           ['r1smokev', 'r2smokev', 'r4smokev', 'r5smokev', 'r6smokev', 'r7smokev', 'r8smokev']   \n",
       "14                                                                                                                                                                                                                                                                                                                                                                   ['r8smokev']   \n",
       "15                                                                                                                                                                                                                                                                                                                                        ['r2drinkev', 'r4drinkev', 'r5drinkev']   \n",
       "16                                                                                                                                                                                                                                                                                                                                                                ['racsevent_s']   \n",
       "17                                                                                                                                                                                                                                                                                                                                                         ['r3sfnhe', 'r7sfnhe']   \n",
       "18                                                                                                                                                                                                                                                                                    ['r1hownrnt', 'r2hownrnt', 'r4hownrnt', 'r5hownrnt', 'r6hownrnt', 'r7hownrnt', 'r8hownrnt']   \n",
       "19                                                                                                                                                                                                                                                                                                                                                                    ['r8sleep']   \n",
       "20                                                                                                                                                                                                                                                                                                  ['r1mstat', 'r2mstat', 'r4mstat', 'r5mstat', 'r6mstat', 'r7mstat', 'r8mstat']   \n",
       "21                                                                                                                                                                                                                                                                                                                                                                    ['r8mstat']   \n",
       "22                                                                                                                                                                                                                                                                                                                                                                 ['r8satlifez']   \n",
       "23                                                                                                                                                                                                                                                                                                                                                               ['ramomedisced']   \n",
       "24                                                                                                                                                                                                                                                                                                                                                               ['radadedisced']   \n",
       "25                                                                                                                                                                                                                                                                                                                                                                  ['ramaoccup']   \n",
       "26                                                                                                                                                                                                                                                                                                                                                                    ['h8atotb']   \n",
       "27                                                                                                                                                                                                                                                                                                     ['r8itearn', 'r8itsemp', 'r8itpena', 'r8itpubpen', 'r8itgxfr', 'r8itothr']   \n",
       "28                                                                                                                                                                                                                                                                                                                                                                    ['h8ittot']   \n",
       "29                                                                                                                                                                                                                                                              [{1: ['q2_b', 'q2_c'], 2: ['ac015_'], 4: ['ac015_'], 5: ['ac015_'], 6: ['ac015_'], 7: ['ac015_'], 8: ['ac015_']}]   \n",
       "30                                              [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q2_b', 'q2_c']}, 2: {'sharew2_rel8-0-0_ac.dta': ['ac015_']}, 4: {'sharew4_rel8-0-0_ac.dta': ['ac015_']}, 5: {'sharew5_rel8-0-0_ac.dta': ['ac015_']}, 6: {'sharew6_rel8-0-0_ac.dta': ['ac015_']}, 7: {'sharew7_rel8-0-0_ac.dta': ['ac015_']}, 8: {'sharew8_rel8-0-0_ac.dta': ['ac015_']}}]   \n",
       "31                                                                                                                                                                                                     [{4: {'sharew4_rel8-0-0_mh.dta': ['mh023_', 'mh024_', 'mh025_', 'mh026_', 'mh027_']}, 5: {'sharew5_rel8-0-0_mh.dta': ['mh023_', 'mh024_', 'mh025_', 'mh026_', 'mh027_']}}]   \n",
       "32                                                         [{1: {'sharew1_rel8-0-0_mh.dta': ['mh003_']}, 2: {'sharew2_rel8-0-0_mh.dta': ['mh003_']}, 4: {'sharew4_rel8-0-0_mh.dta': ['mh003_']}, 5: {'sharew5_rel8-0-0_mh.dta': ['mh003_']}, 6: {'sharew6_rel8-0-0_mh.dta': ['mh003_']}, 7: {'sharew7_rel8-0-0_mh.dta': ['mh003_']}, 8: {'sharew8_rel8-0-0_mh.dta': ['mh003_']}}]   \n",
       "33  [{4: {'sharew4_rel8-0-0_dropoff.dta': ['q5a', 'q5b', 'q5c', 'q5d']}, 5: {'sharew5_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']}, 6: {'sharew6_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']}, 7: {'sharew7_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']}, 8: {'sharew8_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']}}]   \n",
       "34                                                                                                                                                                                                                                                                 [{7: {'sharew7_rel8-0-0_ac.dta': ['ac702_', 'ac711_']}, 8: {'sharew8_rel8-0-0_ac.dta': ['ac702_', 'ac711_']}}]   \n",
       "35                                                                                                                                                                                                                                                                 [{7: {'sharew7_rel8-0-0_ac.dta': ['ac706_', 'ac711_']}, 8: {'sharew8_rel8-0-0_ac.dta': ['ac706_', 'ac711_']}}]   \n",
       "36                                                                                                                                                                                                                                                                 [{7: {'sharew7_rel8-0-0_ac.dta': ['ac709_', 'ac704_']}, 8: {'sharew8_rel8-0-0_ac.dta': ['ac709_', 'ac704_']}}]   \n",
       "37                                                                                                                                                                                                                                                               [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q3_d', 'q3_f']}, 2: {'sharew2_rel8-0-0_dropoff.dta': ['q3_d', 'q3_f']}}]   \n",
       "38                                                                                                                                                                                                               [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q3_a', 'q3_b', 'q3_c', 'q3_e', 'q3_g']}, 2: {'sharew2_rel8-0-0_dropoff.dta': ['q3_a', 'q3_b', 'q3_c', 'q3_e', 'q3_g']}}]   \n",
       "39                                                                                                                                                                                                                                                      [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q4_a', 'q4_b', 'q4_c', 'q4_e', 'q4_f', 'q4_h', 'q4_i', 'q4_j', 'q4_k', 'q4_m']}}]   \n",
       "40                                                                                                                                                                                                                                                                                                              [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q4_l', 'q4_g', 'q4_d']}}]   \n",
       "\n",
       "   in_ELSA in_HRS              wave_controller  \n",
       "0    False  False                  latest_wave  \n",
       "1     True  False                  latest_wave  \n",
       "2     True   True                  latest_wave  \n",
       "3    False  False                  latest_wave  \n",
       "4    False  False                  single_wave  \n",
       "5     True   True                  single_wave  \n",
       "6     True   True                  single_wave  \n",
       "7     True   True                  single_wave  \n",
       "8     True   True                  latest_wave  \n",
       "9     True   True                  latest_wave  \n",
       "10    True   True                  latest_wave  \n",
       "11    True   True                  latest_wave  \n",
       "12    True   True                  latest_wave  \n",
       "13    True   True                  latest_wave  \n",
       "14    True   True                  latest_wave  \n",
       "15    True  False                   drink_wave  \n",
       "16   False  False                  single_wave  \n",
       "17   False   True  financial_difficulties_wave  \n",
       "18    True   True                  latest_wave  \n",
       "19    True   True                  latest_wave  \n",
       "20    True   True                  latest_wave  \n",
       "21    True   True                  latest_wave  \n",
       "22    True   True                  latest_wave  \n",
       "23    True   True                  single_wave  \n",
       "24    True   True                  single_wave  \n",
       "25   False   True                  single_wave  \n",
       "26    True   True                  latest_wave  \n",
       "27    True   True                  latest_wave  \n",
       "28   False  False                  latest_wave  \n",
       "29   False   True                       manual  \n",
       "30   False   True                  latest_wave  \n",
       "31   False   True                       manual  \n",
       "32   False   True                       manual  \n",
       "33   False   True                       manual  \n",
       "34   False   True                       manual  \n",
       "35   False   True                       manual  \n",
       "36   False   True                       manual  \n",
       "37   False   True                       manual  \n",
       "38   False   True                       manual  \n",
       "39   False   True                       manual  \n",
       "40   False   True                       manual  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recode_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhid</th>\n",
       "      <th>pn</th>\n",
       "      <th>mergeid</th>\n",
       "      <th>deathY</th>\n",
       "      <th>Zeduccat</th>\n",
       "      <th>currentpaternered</th>\n",
       "      <th>lencurmarridge</th>\n",
       "      <th>migrantYN</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>rural</th>\n",
       "      <th>...</th>\n",
       "      <th>everdivorced</th>\n",
       "      <th>nevermarried</th>\n",
       "      <th>Zlifesatis</th>\n",
       "      <th>Znegaffect</th>\n",
       "      <th>Zmotherseduc</th>\n",
       "      <th>Zfatherseduc</th>\n",
       "      <th>fathersocc</th>\n",
       "      <th>ZwealthT</th>\n",
       "      <th>ZincomeT</th>\n",
       "      <th>HIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000327</td>\n",
       "      <td>01</td>\n",
       "      <td>AT-000327-01</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000327</td>\n",
       "      <td>02</td>\n",
       "      <td>AT-000327-02</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000674</td>\n",
       "      <td>01</td>\n",
       "      <td>AT-000674-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001215</td>\n",
       "      <td>01</td>\n",
       "      <td>AT-001215-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.479950</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>20400.0</td>\n",
       "      <td>20400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001492</td>\n",
       "      <td>01</td>\n",
       "      <td>AT-001492-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.108856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139615</th>\n",
       "      <td>995042</td>\n",
       "      <td>01</td>\n",
       "      <td>SK-995042-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.246366</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>91100.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>10440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139616</th>\n",
       "      <td>995042</td>\n",
       "      <td>02</td>\n",
       "      <td>SK-995042-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.108856</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>91100.0</td>\n",
       "      <td>6240.0</td>\n",
       "      <td>10440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139617</th>\n",
       "      <td>996004</td>\n",
       "      <td>01</td>\n",
       "      <td>SK-996004-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.068755</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139618</th>\n",
       "      <td>999958</td>\n",
       "      <td>01</td>\n",
       "      <td>SK-999958-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139619</th>\n",
       "      <td>999958</td>\n",
       "      <td>02</td>\n",
       "      <td>SK-999958-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139620 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          hhid  pn       mergeid  deathY  Zeduccat  currentpaternered  \\\n",
       "0       000327  01  AT-000327-01  2007.0  4.0      NaN                  \n",
       "1       000327  02  AT-000327-02  2012.0  4.0      NaN                  \n",
       "2       000674  01  AT-000674-01 NaN      2.0      NaN                  \n",
       "3       001215  01  AT-001215-01 NaN      2.0      -1.0                 \n",
       "4       001492  01  AT-001492-01 NaN      4.0       1.0                 \n",
       "...        ...  ..           ...  ..      ...       ...                 \n",
       "139615  995042  01  SK-995042-01 NaN      4.0       1.0                 \n",
       "139616  995042  02  SK-995042-02 NaN      4.0       1.0                 \n",
       "139617  996004  01  SK-996004-01 NaN      4.0      -1.0                 \n",
       "139618  999958  01  SK-999958-01 NaN      4.0      NaN                  \n",
       "139619  999958  02  SK-999958-02 NaN      4.0      NaN                  \n",
       "\n",
       "        lencurmarridge  migrantYN  citizenship  rural  ...  everdivorced  \\\n",
       "0       29.0           -1.0        1.0         NaN     ... -1              \n",
       "1       29.0           -1.0        1.0         NaN     ... -1              \n",
       "2      NaN             -1.0        1.0         NaN     ... -1              \n",
       "3      NaN              1.0       -1.0         NaN     ... -1              \n",
       "4      NaN             -1.0        1.0         -1.0    ... -1              \n",
       "...     ..              ...        ...          ...    ... ..              \n",
       "139615 NaN             -1.0        1.0         -1.0    ... -1              \n",
       "139616 NaN             -1.0        1.0         -1.0    ... -1              \n",
       "139617 NaN             -1.0        1.0         -1.0    ...  1              \n",
       "139618 NaN             -1.0        1.0         NaN     ... -1              \n",
       "139619 NaN             -1.0        1.0         NaN     ... -1              \n",
       "\n",
       "        nevermarried  Zlifesatis  Znegaffect  Zmotherseduc  Zfatherseduc  \\\n",
       "0      NaN           NaN         NaN         NaN           NaN             \n",
       "1      NaN           NaN         NaN         NaN           NaN             \n",
       "2      NaN           NaN         NaN          5.0           5.0            \n",
       "3       1.0          -0.479950    2.0         5.0           4.0            \n",
       "4      -1.0           0.108856    1.0         4.0           2.0            \n",
       "...     ...                ...    ...         ...           ...            \n",
       "139615 -1.0          -2.246366    11.0        4.0           4.0            \n",
       "139616 -1.0           0.108856    4.0         4.0           4.0            \n",
       "139617 -1.0          -1.068755    6.0         5.0           5.0            \n",
       "139618 NaN           NaN         NaN         NaN           NaN             \n",
       "139619 NaN           NaN         NaN         NaN           NaN             \n",
       "\n",
       "        fathersocc  ZwealthT  ZincomeT  HIncome  \n",
       "0      NaN         NaN        0.0      NaN       \n",
       "1      NaN         NaN        0.0      NaN       \n",
       "2      NaN         NaN        0.0      NaN       \n",
       "3       3.0         5000.0    20400.0   20400.0  \n",
       "4      NaN          113500.0  0.0       30800.0  \n",
       "...     ..               ...  ...           ...  \n",
       "139615  6.0         91100.0   4200.0    10440.0  \n",
       "139616  6.0         91100.0   6240.0    10440.0  \n",
       "139617  6.0         27000.0   0.0       3.0      \n",
       "139618  5.0        NaN        0.0      NaN       \n",
       "139619  5.0        NaN        0.0      NaN       \n",
       "\n",
       "[139620 rows x 32 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "289px",
    "width": "497px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
