{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and initial specification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviornment  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.6 (v3.8.6:db455296be, Sep 23 2020, 13:31:39) \\n[Clang 6.0 (clang-600.0.57)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version\n",
      "------------------------ --------\n",
      "anyio                    3.6.2\n",
      "appnope                  0.1.3\n",
      "argon2-cffi              21.3.0\n",
      "argon2-cffi-bindings     21.2.0\n",
      "arrow                    1.2.3\n",
      "asttokens                2.2.1\n",
      "attrs                    22.2.0\n",
      "backcall                 0.2.0\n",
      "beautifulsoup4           4.11.2\n",
      "bleach                   6.0.0\n",
      "cffi                     1.15.1\n",
      "cloudpickle              2.2.1\n",
      "comm                     0.1.2\n",
      "contourpy                1.0.7\n",
      "cycler                   0.11.0\n",
      "debugpy                  1.6.6\n",
      "decorator                5.1.1\n",
      "defusedxml               0.7.1\n",
      "executing                1.2.0\n",
      "fastjsonschema           2.16.2\n",
      "fonttools                4.38.0\n",
      "fqdn                     1.5.1\n",
      "idna                     3.4\n",
      "importlib-metadata       6.0.0\n",
      "importlib-resources      5.12.0\n",
      "ipykernel                6.21.2\n",
      "ipython                  8.10.0\n",
      "ipython-genutils         0.2.0\n",
      "ipywidgets               8.0.4\n",
      "isoduration              20.11.0\n",
      "jedi                     0.18.2\n",
      "Jinja2                   3.1.2\n",
      "joblib                   1.2.0\n",
      "jsonpointer              2.3\n",
      "jsonschema               4.17.3\n",
      "jupyter                  1.0.0\n",
      "jupyter_client           8.0.3\n",
      "jupyter-console          6.6.1\n",
      "jupyter_core             5.2.0\n",
      "jupyter-events           0.6.3\n",
      "jupyter_server           2.3.0\n",
      "jupyter_server_terminals 0.4.4\n",
      "jupyterlab-pygments      0.2.2\n",
      "jupyterlab-widgets       3.0.5\n",
      "kiwisolver               1.4.4\n",
      "lightgbm                 3.3.5\n",
      "llvmlite                 0.39.1\n",
      "MarkupSafe               2.1.2\n",
      "matplotlib               3.7.0\n",
      "matplotlib-inline        0.1.6\n",
      "missingpy                0.2.0\n",
      "mistune                  2.0.5\n",
      "nbclassic                0.5.2\n",
      "nbclient                 0.7.2\n",
      "nbconvert                7.2.9\n",
      "nbformat                 5.7.3\n",
      "nest-asyncio             1.5.6\n",
      "notebook                 6.5.2\n",
      "notebook_shim            0.2.2\n",
      "numba                    0.56.4\n",
      "numpy                    1.23.5\n",
      "packaging                23.0\n",
      "pandas                   1.5.3\n",
      "pandocfilters            1.5.0\n",
      "parso                    0.8.3\n",
      "pexpect                  4.8.0\n",
      "pickleshare              0.7.5\n",
      "Pillow                   9.4.0\n",
      "pip                      21.3.1\n",
      "pkgutil_resolve_name     1.3.10\n",
      "platformdirs             3.0.0\n",
      "prometheus-client        0.16.0\n",
      "prompt-toolkit           3.0.37\n",
      "psutil                   5.9.4\n",
      "ptyprocess               0.7.0\n",
      "pure-eval                0.2.2\n",
      "pycparser                2.21\n",
      "Pygments                 2.14.0\n",
      "pyparsing                3.0.9\n",
      "pyrsistent               0.19.3\n",
      "python-dateutil          2.8.2\n",
      "python-json-logger       2.0.7\n",
      "pytz                     2022.7.1\n",
      "PyYAML                   6.0\n",
      "pyzmq                    25.0.0\n",
      "qtconsole                5.4.0\n",
      "QtPy                     2.3.0\n",
      "rfc3339-validator        0.1.4\n",
      "rfc3986-validator        0.1.1\n",
      "scikit-learn             1.2.1\n",
      "scipy                    1.10.1\n",
      "Send2Trash               1.8.0\n",
      "setuptools               60.2.0\n",
      "shap                     0.41.0\n",
      "six                      1.16.0\n",
      "slicer                   0.0.7\n",
      "sniffio                  1.3.0\n",
      "soupsieve                2.4\n",
      "stack-data               0.6.2\n",
      "terminado                0.17.1\n",
      "threadpoolctl            3.1.0\n",
      "tinycss2                 1.2.1\n",
      "tornado                  6.2\n",
      "tqdm                     4.64.1\n",
      "traitlets                5.9.0\n",
      "uri-template             1.2.0\n",
      "wcwidth                  0.2.6\n",
      "webcolors                1.12\n",
      "webencodings             0.5.1\n",
      "websocket-client         1.5.1\n",
      "wheel                    0.37.1\n",
      "widgetsnbextension       4.0.5\n",
      "xgboost                  1.7.4\n",
      "zipp                     3.14.0\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Users/valler/Python/OX_Thesis/OX_thesis/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have imported the data and it has 6385 rows and 139620 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "share_path= Path('/Users/valler/Python/OX_Thesis/OX_thesis/Data/SHARE')\n",
    "\n",
    "# import data\n",
    "with open(share_path/'harmonised/H_SHARE_f.pkl', \"rb\") as fh:\n",
    "    data = pd.read_pickle(fh)\n",
    "\n",
    "print('we have imported the data and it has {} rows and {} columns'.format(data.shape[1],data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_wave = '1'\n",
    "drink_wave=[2,4,5]\n",
    "financial_difficulties_wave=[3,7]\n",
    "today = datetime.now().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data recode record initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have recoded 41 vars so far, keep going on\n",
      "and the last variable is deathY\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "\n",
    "if os.path.exists(share_path/'recoded_data.pkl'):\n",
    "    df_recode_record=pd.read_csv(share_path/'recode_record.csv')\n",
    "    df = pd.read_pickle(share_path/'recoded_data.pkl')\n",
    "    print(f'we have recoded {len(df_recode_record)} vars so far, keep going on')\n",
    "    print(f\"and the last variable is {df_recode_record.loc[len(df_recode_record)-1,'varname']}\")\n",
    "    \n",
    "else:\n",
    "    columns = ['varname',\n",
    "               'conventional_name',\n",
    "               'varname_in_raw',\n",
    "               'domain',\n",
    "\n",
    "               'available_waves',  # 0:time invariant\n",
    "               'recode_type', # [historical, multi-response, direct]\n",
    "               'reverse_code', # Boolean\n",
    "               'maximum_missing_response', # If the variable \n",
    "               'replace_dict',\n",
    "               'standardise',\n",
    "\n",
    "               'notes',\n",
    "               'in_HRS',\n",
    "               'in_ELSA',\n",
    "               'recode_date']\n",
    "    \n",
    "    df_recode_record=pd.DataFrame(columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row_to_df_record(new_row,df_recode_record):\n",
    "    \"\"\"\n",
    "    add row to df_recode_record\n",
    "    if the row exists, rewrite it\n",
    "    \"\"\"\n",
    "    varname= new_row['varname']\n",
    "    replace_control = 1 # by deafualt, we update the dict\n",
    "    \n",
    "    if varname in list(df_recode_record['varname']):\n",
    "        exist_row=df_recode_record.loc[df_recode_record['varname']==varname,:]\n",
    "        \n",
    "        # for vars with replace_dict, ask whether to clean it \n",
    "        replace_dict=exist_row['replace_dict'].values[0]\n",
    "        if not pd.isnull(replace_dict) and isinstance(replace_dict,dict):\n",
    "            \n",
    "            \n",
    "            stay_control=True\n",
    "            while stay_control:\n",
    "                print('we have found the dict as follows')\n",
    "                for key in replace_dict.keys():\n",
    "                    print('{}->{}'.format(key,replace_dict[key]))\n",
    "                    \n",
    "                replace_control=input(\"do you want to update it? 1->yes 0->no\")\n",
    "                try:\n",
    "                    replace_control=int(replace_control)\n",
    "                    if replace_control in [1,0]:\n",
    "                        stay_control=False\n",
    "                    else:   \n",
    "                        print('please check your response and try again')\n",
    "                except:\n",
    "                    print('please check your response and try again')\n",
    "            \n",
    "            \n",
    "        \n",
    "        # only keep those rows that doesn't match the new varname\n",
    "        df_recode_record=df_recode_record.where(df_recode_record['varname']!=varname)\n",
    "        df_recode_record.dropna(how='all',inplace=True)\n",
    "    \n",
    "    if  replace_control==0:  # not update, keep the original one\n",
    "        print('we will keep the original replace_dict')\n",
    "        new_row['replace_dict']=replace_dict\n",
    "        \n",
    "    df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n",
    "    \n",
    "         \n",
    "    return df_recode_record\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data_across_waves(varname_w1,total_waves,data):\n",
    "    \"\"\"\n",
    "    generate the column names with the first column name\n",
    "    when we need to draw information from multiple waves\n",
    "    \"\"\"\n",
    "    var_names=[]\n",
    "    for i in range(1,total_waves+1):\n",
    "        var_names.append(varname_w1.replace('1',str(i)))\n",
    "    temp = data[var_names]\n",
    "    return temp\n",
    "\n",
    "def count_times(df_row,response_to_count):\n",
    "    \"\"\"\n",
    "    send the row and response to count, to count the times that the \n",
    "    response has appeared in ech row/ppl\n",
    "    e.g. df['rentperiod'] = temp.apply(count_times,axis=1,response_to_count='1.own home')\n",
    "    \"\"\"\n",
    "    count=0\n",
    "    for item in df_row:\n",
    "        if item==response_to_count:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "\n",
    "def average_response_by_row(df_row,maximum_missing_response):\n",
    "    \"\"\"\n",
    "    for vars that draw info from multiple variables, this\n",
    "    function help to average them with maximum_missing_response\n",
    "    # df_row should be sliced data\n",
    "    \"\"\"\n",
    "    \n",
    "    missing_count=sum(pd.isnull(df_row))\n",
    "    if missing_count>=maximum_missing_response:\n",
    "        return None\n",
    "    else:\n",
    "        df_row=[x for x in df_row if not pd.isnull(x)]\n",
    "        # average among avaliable responses\n",
    "        return sum(df_row)/len(df_row)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple response functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def multiresponse_average(varname,df_recode_record,data,df,print_missing_count_control):\n",
    "    \"\"\"\n",
    "    automation of average to multiple response\n",
    "    \"\"\"\n",
    "    \n",
    "    sliced_row = df_recode_record.loc[df_recode_record['varname']==varname,]\n",
    "    varset=sliced_row['var_set'].values[0]\n",
    "    maximum_missing_response=sliced_row['maximum_missing_response'].values[0]\n",
    "    reverse_control=sliced_row['reverse_code'].values[0]\n",
    "    \n",
    "    sliced_data = data[varset].copy()\n",
    "    \n",
    "    # print_missing counts info\n",
    "    if print_missing_count_control:\n",
    "        missing_count(sliced_data)\n",
    "    \n",
    "    print(f'1. maximum_missing_response {maximum_missing_response}\\n2. reverse_control {reverse_control}')\n",
    "    \n",
    "    # replace string to number \n",
    "    replace_dict=replace_response_with_value(sliced_data)\n",
    "    print(\"3. the replace dict is {}\".format(replace_dict))\n",
    "    sliced_data.replace(replace_dict,inplace=True)\n",
    "    \n",
    "    # reverse control\n",
    "    if reverse_control:\n",
    "        \n",
    "        unique_vals = get_unique_valaues(sliced_data)\n",
    "        print(\"4. unique_vals are {}\".format(unique_vals))\n",
    "        replace_dict = generate_value_replace_dict(unique_vals)\n",
    "        print(\"5. dict is {}\".format(replace_dict))\n",
    "        sliced_data.replace(replace_dict,inplace=True)\n",
    "    \n",
    "    # if there is only one variable, set it to the df directly rather than averaging them \n",
    "    if len(varset)==1:\n",
    "        df[varname]=sliced_data[varset[0]]\n",
    "    else:    \n",
    "        df[varname]=sliced_data.apply(average_response_by_row,axis=1,maximum_missing_response=maximum_missing_response)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_value_replace_dict(res_lst):\n",
    "    \"\"\"\n",
    "    return the replace dict for reverse coding \n",
    "    \"\"\"\n",
    "    replace_dict={}\n",
    "    max_val=max(res_lst)\n",
    "    res_lst.sort()\n",
    "    res_len=len(res_lst)\n",
    "    \n",
    "    for index in range(res_len):\n",
    "        reverse_ind = res_len-index-1\n",
    "        replace_dict[res_lst[index]]=res_lst[reverse_ind]\n",
    "    return replace_dict  \n",
    "\n",
    "def get_unique_valaues(sliced_data):\n",
    "    \"\"\"\n",
    "    if we need to treat values from all columns as a whole,\n",
    "    this function help to get the unique value list\n",
    "    \"\"\"\n",
    "    unique_list=[]\n",
    "    for column in sliced_data.columns:\n",
    "        unique_list+=list(sliced_data[column].unique())\n",
    "    \n",
    "    # delete repeat value\n",
    "    unique_list=list(set(unique_list))\n",
    "    \n",
    "    # get rid of nans\n",
    "    unique_list= [x for x in unique_list if not pd.isnull(x)]\n",
    "    return unique_list\n",
    "\n",
    "\n",
    "def replace_response_with_value(sliced_data):\n",
    "    \"\"\"\n",
    "    replace the string response with numbers \n",
    "    # here by default we assume all the values are format of '#. explain'\n",
    "    # e.g. '1.hardly ever or never'\n",
    "    \"\"\"\n",
    "    replace_dict={}\n",
    "    response_list = get_unique_valaues(sliced_data)\n",
    "    \n",
    "    # generate the dict\n",
    "    for res in response_list:\n",
    "        if isinstance(res,str):\n",
    "            number=res.split('.')[0]\n",
    "            replace_dict[res]=int(number)\n",
    "        elif isinstance(res,float) or isinstance(res,int):\n",
    "            number=res\n",
    "            replace_dict[res]=int(number)\n",
    "        else:\n",
    "            print('the response is incorrect, {}, type{}'.format(res,type(res)))\n",
    "        \n",
    "        \n",
    "    return replace_dict\n",
    "\n",
    "def missing_count(sliced_data):\n",
    "    \"\"\"\n",
    "    print the missing counts in each row, account for all columns in var_set\n",
    "    \"\"\"\n",
    "    \n",
    "    def return_sum_of_null(row):\n",
    "        missing_count=sum(pd.isnull(row))\n",
    "        return missing_count\n",
    "    sliced_data['missing_count']=sliced_data.apply(return_sum_of_null,axis=1)\n",
    "    print(\"0. missing information -------- start\")\n",
    "    print(sliced_data['missing_count'].value_counts())\n",
    "    sliced_data.drop(columns=['missing_count'],inplace=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### historical response functions \n",
    "\n",
    "- historical response : mainly for yes or no type variable\n",
    "- once `yes` lable appears, it will be counted as `yes`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def historical_response_recorder(varname,df_recode_record,data,df):\n",
    "    \"\"\"\n",
    "    check whether there is any affimative response to the question, if exists (doesn't matter how many times) ->1\n",
    "    \"\"\"\n",
    "    \n",
    "    sliced_row = df_recode_record.loc[df_recode_record['varname']==varname,]\n",
    "    varset = sliced_row['var_set'].values[0]\n",
    "    sliced_data = data[varset].copy()\n",
    "\n",
    "    # get the replace_dict by inputting or from df_recode_record\n",
    "        \n",
    "    replace_dict=generate_replace_dict_for_historical_response(sliced_row,sliced_data)\n",
    "    replace_dict['nan']=None\n",
    "    # record the replace_dict\n",
    "    \n",
    "    df_recode_record.loc[df_recode_record['varname']==varname,'replace_dict']=[replace_dict]\n",
    "    \n",
    "    # here all the values will be changed to 1/-1 value\n",
    "    # first convert all columns to str (could be categorical)\n",
    "    # for col in sliced_data.columns:\n",
    "        # sliced_data[col].replace(replace_dict,inplace=True)\n",
    "        # sliced_data[col]=sliced_data[col].astype('str')\n",
    "        \n",
    "    # print(f'unique values are {get_unique_valaues(sliced_data)}')\n",
    "    # print(sliced_data.value_counts())\n",
    "    print(f'\\n1.the replace dict is \\n{replace_dict}')\n",
    "    \n",
    "    sliced_data.replace(replace_dict,inplace=True)\n",
    "    \n",
    "    \n",
    "    # if there is only one variable being sent -> set the sliced_data to df directly\n",
    "    if len(varset)==1:\n",
    "        \n",
    "        df[varname]=sliced_data[varset[0]]\n",
    "    else:\n",
    "        # mark response \n",
    "        df[varname]=sliced_data.apply(mark_positive_response,axis=1)\n",
    "        \n",
    "    return df,df_recode_record\n",
    "\n",
    "\n",
    "def generate_replace_dict_for_historical_response(sliced_row,sliced_data):\n",
    "    \"\"\"\n",
    "    generate the replace_dict if there is nothing in sliced_row['replace_dict']/returned object is not dict\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        replace_dict=sliced_row['replace_dict'].values[0]\n",
    "    except:\n",
    "        replace_dict=None\n",
    "    # if we had done it, we shouldn't do it again..\n",
    "    if pd.isnull(replace_dict) or not isinstance(replace_dict,dict):\n",
    "        replace_dict={}\n",
    "        response_list = get_unique_valaues(sliced_data)\n",
    "        print(f'all responses are: {response_list}')\n",
    "        for response in response_list:\n",
    "            Pass_control=True\n",
    "            while Pass_control:\n",
    "                replace_val=input(f'replace response [{response}] with int .. (999 -> none)')\n",
    "                try:\n",
    "                    replace_val=int(replace_val)\n",
    "                    Pass_control=False\n",
    "                except:\n",
    "                    print('error in the response, please try again')\n",
    "                    \n",
    "            replace_dict[response]= None if replace_val==999 else replace_val \n",
    "            \n",
    "    return replace_dict\n",
    "    \n",
    "def mark_positive_response(df_row):\n",
    "    \"\"\"\n",
    "    if 1 exists in df_row, mark it as 1 else -1\n",
    "    \"\"\"\n",
    "    if 1 in list(df_row):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace only function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_only_recorder(varname,df_recode_record,data,df):\n",
    "    \n",
    "    # get the records \n",
    "    sliced_row = df_recode_record.loc[df_recode_record['varname']==varname,]\n",
    "    varset=sliced_row['var_set'].values[0]\n",
    "    reverse_control = sliced_row['reverse_code'].values[0]\n",
    "    sliced_data = data[varset].copy()\n",
    "    \n",
    "\n",
    "    # get the replace_dict by inputting or from df_recode_record\n",
    "    replace_dict=generate_replace_dict_for_historical_response(sliced_row,sliced_data)\n",
    "    replace_dict['nan']=None\n",
    "    # record the replace_dict\n",
    "    \n",
    "    \n",
    "    df_recode_record.loc[df_recode_record['varname']==varname,'replace_dict'] = [replace_dict]\n",
    "    print(f'\\n1.the replace dict is \\n{replace_dict}')\n",
    "    \n",
    "    df[varname] = sliced_data.replace(replace_dict)\n",
    "    \n",
    "    # we reverse code lastly to avoid crashing the previous replacing action\n",
    "    if reverse_control:\n",
    "        response_list = list(replace_dict.values())\n",
    "        while None in response_list: response_list.remove(None)\n",
    "        reverse_replace_dict = generate_value_replace_dict(response_list)\n",
    "        df[varname].replace(reverse_replace_dict, inplace=True)\n",
    "    \n",
    "    return df,df_recode_record\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recode Processor \n",
    "\n",
    "after reading the new_row dict, decide which function we should use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_processor(varname,df_recode_record,df):\n",
    "    var_dict=df_recode_record.loc[df_recode_record['varname']==varname,:].to_dict('records')[0]\n",
    "\n",
    "    if var_dict['recode_type']=='direct_use':\n",
    "        df[varname]=data[var_dict['var_set']]\n",
    "        print(df[varname].describe())\n",
    "    elif var_dict['recode_type']=='replace_only':\n",
    "        df,df_recode_record = replace_only_recorder(varname,df_recode_record,data,df)\n",
    "        print(f'\\n2. the updated var_dict is\\n{var_dict}')\n",
    "        print(f'\\n3. statistics\\n{df[varname].value_counts()}')\n",
    "    elif var_dict['recode_type']=='historical':\n",
    "        df,df_recode_record=historical_response_recorder(varname,df_recode_record,data,df)\n",
    "        print(df[varname].value_counts())\n",
    "    elif var_dict['recode_type'] == 'multi_response':\n",
    "        print_missing_count_control=True if input('want to check the missings ? 1/0 ')=='1' else False\n",
    "        df=multiresponse_average(varname,df_recode_record,data,df,print_missing_count_control)\n",
    "    return df,df_recode_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Var Recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_dict={\"1\":\"Demographic\", \"2\": \"Childhood Adversity\",\n",
    "             \"3\": \"Adulthood Socioeconomic\",\"4\":\"Adulthood Health Behaviors\",\n",
    "             \"5\":\"Adulthood Social Connections\",\"6\":\"Adulthood Psychological\",\n",
    "             \"7\":\"Adulthood Adverse Experiences\",\"8\":'Others'}\n",
    "\n",
    "recode_type_dict={\"1\":'historical',\"2\":'multi_response',\"3\":'replace_only',\"4\":'direct_use',\"5\":'row_manual'}\n",
    "\n",
    "wave_controller_dict={\"1\":'latest_wave',\"2\":\"single_wave\",'3':\"drink_wave\",'4':'financial_difficulties_wave',\"5\":\"manual\"}\n",
    "\n",
    "def new_var_record_input(varname,var_set,available_waves,replace_dict,notes):\n",
    "    new_row={}\n",
    "    \n",
    "    new_row['varname']=varname\n",
    "    new_row['var_set']=var_set\n",
    "    new_row['available_waves'] = available_waves\n",
    "    new_row['replace_dict'] =replace_dict\n",
    "    new_row['notes'] = notes\n",
    "\n",
    "    new_row['conventional_name']=input(\"what's the conventional name? \")\n",
    "    \n",
    "    for key,value in domain_dict.items():\n",
    "        print(f'\\n{key}:{value}')\n",
    "    domain_key=input(\"what's the domain? (select the number) \")\n",
    "    new_row['domain']=domain_dict[domain_key]\n",
    "        \n",
    "    for key,value in recode_type_dict.items():\n",
    "        print(f'\\n{key}:{value}')\n",
    "    recode_type_key=input(\"what's the recode_type? \")\n",
    "    new_row['recode_type']=recode_type_dict[recode_type_key]\n",
    "    \n",
    "    for key,value in wave_controller_dict.items():\n",
    "        print(f'\\n{key}:{value}')\n",
    "    wave_controller_key=input(\"what's the recode_type? \")\n",
    "    new_row['wave_controller']=wave_controller_dict[wave_controller_key]\n",
    "    \n",
    "    reverse_code_control = input('do this var need to be reverse_coded? 1/0 ')\n",
    "    new_row['reverse_code']=True if reverse_code_control=='1' else False\n",
    "\n",
    "    \n",
    "    new_row['maximum_missing_response']=int(input(\"what's the maximum_missing_response? \")) if recode_type_key=='2' else None\n",
    "    \n",
    "    standardise_control = input('do this var need to be standardised? 1/0 ')\n",
    "    new_row['standardise']=True if standardise_control=='1' else False\n",
    "    \n",
    "    HRS_control= input('Is this var in HRS? 1/0 ')\n",
    "    new_row['in_HRS']=True if HRS_control=='1' else False\n",
    "    \n",
    "    ELSA_control= input('Is this var in ELSA? 1/0 ')\n",
    "    new_row['in_ELSA']=True if ELSA_control=='1' else False\n",
    "    \n",
    "    new_row['recode_date']=today\n",
    "    \n",
    "    return new_row\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDs and Death Info "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df[['hhid','pn','mergeid','isocountry']]=data[['hhid','pn','mergeid','isocountry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Death Year `deathY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_5964/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "varname='deathY'\n",
    "var_set=['radyear']\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Death Year',\n",
    " 'domain': 'Others',\n",
    " 'recode_type': 'direct_use',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': False,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='deathY'\n",
    "var_set=['radyear']\n",
    "available_waves= [0]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    18349.000000\n",
      "mean      2014.411630\n",
      "std          4.017226\n",
      "min       2004.000000\n",
      "25%       2012.000000\n",
      "50%       2015.000000\n",
      "75%       2018.000000\n",
      "max       2021.000000\n",
      "Name: deathY, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "varname='deathY'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1KklEQVR4nO3df3RU9Z3/8VcSkiEBhp8mE5YQU1mByE9BYKpShJCIKZXKH7UqUIuy0EAX0gVMFyFAKYqlSBWhLUjcFlq1K64CQgYwUCSIZEn55XKE4sEuTLJHheHnMCT3+0e+mTASIBNmMvmE5+OcOXLv/cznfu57PjPz8s6dTJRlWZYAAAAMEh3pAQAAAASLAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAME6zSA8gXCorK3Xy5Em1atVKUVFRkR4OAACoA8uydPbsWXXs2FHR0dc/z9JkA8zJkyeVkpIS6WEAAIB6+OKLL9SpU6frbm+yAaZVq1aSqgpgt9sjPJr68fl8KiwsVGZmpmJjYyM9nIihDjWoRRXqUIU6VKEONZpCLTwej1JSUvzv49fTZANM9cdGdrvd6ACTkJAgu91u7EQMBepQg1pUoQ5VqEMV6lCjKdXiZpd/cBEvAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIwTVIBZvny5evXq5f99IafTqQ8++MC/fciQIYqKigq4TZw4MaCPEydOKDs7WwkJCUpMTNT06dN15cqVgDZFRUW69957ZbPZ1KVLFxUUFNT/CAEAQJMT1I85durUSS+88IL++Z//WZZl6Y033tCjjz6qffv26Z577pEkPfvss5o3b57/PgkJCf5/V1RUKDs7Ww6HQ7t27dKpU6c0duxYxcbG6pe//KUk6fjx48rOztbEiRO1Zs0abd26Vc8884ySk5OVlZUVimMGAACGCyrAjBw5MmB5wYIFWr58uXbv3u0PMAkJCXI4HLXev7CwUIcPH9aWLVuUlJSkPn36aP78+Zo5c6by8/MVFxenFStWKC0tTYsXL5Ykde/eXTt37tSSJUsIMAAAQFKQAeZqFRUVevvtt3X+/Hk5nU7/+jVr1uiPf/yjHA6HRo4cqeeff95/Fqa4uFg9e/ZUUlKSv31WVpYmTZqkQ4cOqW/fviouLlZGRkbAvrKysjR16tQbjsfr9crr9fqXPR6PpKqfFvf5fPU9zIiqHrep4w8V6lCDWlShDlUaog498jeHre9QsUVbmt9f6jdvk7yVUTqYf/v+z25TeG7UdexBB5gDBw7I6XTq0qVLatmypdatW6f09HRJ0hNPPKHU1FR17NhR+/fv18yZM3XkyBG98847kiS32x0QXiT5l91u9w3beDweXbx4UfHx8bWOa+HChZo7d+416wsLCwM+xjKRy+WK9BAaBepQg1pUoQ5VwlmHRQPC1nXIze9fKUnauHFjhEcSeSY/Ny5cuFCndkEHmK5du6q0tFRnzpzRX/7yF40bN07bt29Xenq6JkyY4G/Xs2dPJScna9iwYTp27JjuuuuuYHcVlLy8POXm5vqXPR6PUlJSlJmZKbvdHtZ9h4vP55PL5dLw4cMVGxsb6eFEDHWoQS2qUIcqDVEHc87AVOr5vdGcgWkCz43qT1BuJugAExcXpy5dukiS+vXrp08++URLly7Vb3/722vaDhw4UJJ09OhR3XXXXXI4HNqzZ09Am7KyMknyXzfjcDj8665uY7fbr3v2RZJsNptsNts162NjY419EKs1hWMIBepQg1pUoQ5VwlkHb0VUWPoNB29llLwVUcwJmf3cqOu4b/nvwFRWVgZce3K10tJSSVJycrIkyel06sCBAyovL/e3cblcstvt/o+hnE6ntm7dGtCPy+UKuM4GAADc3oI6A5OXl6cRI0aoc+fOOnv2rNauXauioiJt3rxZx44d09q1a/XII4+offv22r9/v6ZNm6bBgwerV69ekqTMzEylp6drzJgxWrRokdxut2bNmqWcnBz/2ZOJEyfq1Vdf1YwZM/TjH/9Y27Zt01tvvaUNGzaE/ugBAICRggow5eXlGjt2rE6dOqXWrVurV69e2rx5s4YPH64vvvhCW7Zs0csvv6zz588rJSVFo0eP1qxZs/z3j4mJ0fr16zVp0iQ5nU61aNFC48aNC/i7MWlpadqwYYOmTZumpUuXqlOnTlq5ciVfoQYAAH5BBZhVq1Zdd1tKSoq2b99+0z5SU1NveoX4kCFDtG/fvmCGBgAAbiP8FhIAADAOAQYAABiHAAMAAIxDgAEAAMap928hAQDQGN35nHl/duPzF7IjPQTjcAYGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIwTVIBZvny5evXqJbvdLrvdLqfTqQ8++MC//dKlS8rJyVH79u3VsmVLjR49WmVlZQF9nDhxQtnZ2UpISFBiYqKmT5+uK1euBLQpKirSvffeK5vNpi5duqigoKD+RwgAAJqcoAJMp06d9MILL6ikpER79+7V0KFD9eijj+rQoUOSpGnTpun999/X22+/re3bt+vkyZN67LHH/PevqKhQdna2Ll++rF27dumNN95QQUGBZs+e7W9z/PhxZWdn66GHHlJpaammTp2qZ555Rps3bw7RIQMAANM1C6bxyJEjA5YXLFig5cuXa/fu3erUqZNWrVqltWvXaujQoZKk1atXq3v37tq9e7cGDRqkwsJCHT58WFu2bFFSUpL69Omj+fPna+bMmcrPz1dcXJxWrFihtLQ0LV68WJLUvXt37dy5U0uWLFFWVlaIDhsAAJgsqABztYqKCr399ts6f/68nE6nSkpK5PP5lJGR4W/TrVs3de7cWcXFxRo0aJCKi4vVs2dPJSUl+dtkZWVp0qRJOnTokPr27avi4uKAPqrbTJ069Ybj8Xq98nq9/mWPxyNJ8vl88vl89T3MiKoet6njDxXqUINaVKEOVRqiDrYYK2x9h4ot2gr4r4lC9Rg2hedGXccedIA5cOCAnE6nLl26pJYtW2rdunVKT09XaWmp4uLi1KZNm4D2SUlJcrvdkiS32x0QXqq3V2+7URuPx6OLFy8qPj6+1nEtXLhQc+fOvWZ9YWGhEhISgj3MRsXlckV6CI0CdahBLapQhyrhrMOiAWHrOuTm96+M9BDqbePGjSHtz+TnxoULF+rULugA07VrV5WWlurMmTP6y1/+onHjxmn79u1BDzDU8vLylJub61/2eDxKSUlRZmam7HZ7BEdWfz6fTy6XS8OHD1dsbGykhxMx1KEGtahCHao0RB165Df+6w9t0Zbm96/U83uj5a2MivRw6uVgfmgukWgKz43qT1BuJugAExcXpy5dukiS+vXrp08++URLly7VD37wA12+fFmnT58OOAtTVlYmh8MhSXI4HNqzZ09Af9XfUrq6zTe/uVRWVia73X7dsy+SZLPZZLPZrlkfGxtr7INYrSkcQyhQhxrUokrfBdvkrTDnDevzF7LD0m8454NJ9fVWRhk13quF+vEz+TWiruO+5b8DU1lZKa/Xq379+ik2NlZbt271bzty5IhOnDghp9MpSXI6nTpw4IDKy8v9bVwul+x2u9LT0/1tru6juk11HwAAAEGdgcnLy9OIESPUuXNnnT17VmvXrlVRUZE2b96s1q1ba/z48crNzVW7du1kt9s1ZcoUOZ1ODRo0SJKUmZmp9PR0jRkzRosWLZLb7dasWbOUk5PjP3syceJEvfrqq5oxY4Z+/OMfa9u2bXrrrbe0YcOG0B89AAAwUlABpry8XGPHjtWpU6fUunVr9erVS5s3b9bw4cMlSUuWLFF0dLRGjx4tr9errKwsvfbaa/77x8TEaP369Zo0aZKcTqdatGihcePGad68ef42aWlp2rBhg6ZNm6alS5eqU6dOWrlyJV+hBgAAfkEFmFWrVt1we/PmzbVs2TItW7bsum1SU1NverX1kCFDtG/fvmCGBgAAbiP8FhIAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOEEFmIULF+q+++5Tq1atlJiYqFGjRunIkSMBbYYMGaKoqKiA28SJEwPanDhxQtnZ2UpISFBiYqKmT5+uK1euBLQpKirSvffeK5vNpi5duqigoKB+RwgAAJqcoALM9u3blZOTo927d8vlcsnn8ykzM1Pnz58PaPfss8/q1KlT/tuiRYv82yoqKpSdna3Lly9r165deuONN1RQUKDZs2f72xw/flzZ2dl66KGHVFpaqqlTp+qZZ57R5s2bb/FwAQBAU9AsmMabNm0KWC4oKFBiYqJKSko0ePBg//qEhAQ5HI5a+ygsLNThw4e1ZcsWJSUlqU+fPpo/f75mzpyp/Px8xcXFacWKFUpLS9PixYslSd27d9fOnTu1ZMkSZWVlBXuMAACgiQkqwHzTmTNnJEnt2rULWL9mzRr98Y9/lMPh0MiRI/X8888rISFBklRcXKyePXsqKSnJ3z4rK0uTJk3SoUOH1LdvXxUXFysjIyOgz6ysLE2dOvW6Y/F6vfJ6vf5lj8cjSfL5fPL5fLdymBFTPW5Txx8q1KEGtahSffy2aCvCIwlOqB+3hpgPtpjGX+PqeWDafLhaqB7DpvAaUdex1zvAVFZWaurUqbr//vvVo0cP//onnnhCqamp6tixo/bv36+ZM2fqyJEjeueddyRJbrc7ILxI8i+73e4btvF4PLp48aLi4+OvGc/ChQs1d+7ca9YXFhb6w5OpXC5XpIfQKFCHGtSiyvz+lZEeQlA2btwYln7DOR8WDQhb1yFn2ny4WqjnhsmvERcuXKhTu3oHmJycHB08eFA7d+4MWD9hwgT/v3v27Knk5GQNGzZMx44d01133VXf3d1UXl6ecnNz/csej0cpKSnKzMyU3W4P237DyefzyeVyafjw4YqNjY30cCKGOtSgFlWq6/D83mh5K6MiPZw6O5gf2o/AG2I+9Mhv/Nce2qItze9fadx8uFqo5kZTeI2o/gTlZuoVYCZPnqz169drx44d6tSp0w3bDhw4UJJ09OhR3XXXXXI4HNqzZ09Am7KyMknyXzfjcDj8665uY7fbaz37Ikk2m002m+2a9bGxscY+iNWawjGEAnWoQS2qeCuj5K0w5w0rXI9ZOOeDSfU1bT5cLdSPn8mvEXUdd1DfQrIsS5MnT9a6deu0bds2paWl3fQ+paWlkqTk5GRJktPp1IEDB1ReXu5v43K5ZLfblZ6e7m+zdevWgH5cLpecTmcwwwUAAE1UUAEmJydHf/zjH7V27Vq1atVKbrdbbrdbFy9elCQdO3ZM8+fPV0lJiT7//HO99957Gjt2rAYPHqxevXpJkjIzM5Wenq4xY8bob3/7mzZv3qxZs2YpJyfHfwZl4sSJ+vvf/64ZM2bof/7nf/Taa6/prbfe0rRp00J8+AAAwERBBZjly5frzJkzGjJkiJKTk/23N998U5IUFxenLVu2KDMzU926ddPPfvYzjR49Wu+//76/j5iYGK1fv14xMTFyOp166qmnNHbsWM2bN8/fJi0tTRs2bJDL5VLv3r21ePFirVy5kq9QAwAASUFeA2NZN/6KWkpKirZv337TflJTU296xfWQIUO0b9++YIYHAABuE/wWEgAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABinWaQHACDy7nxuQ6SHEBRbjKVFAyI9CgCRxBkYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjBNUgFm4cKHuu+8+tWrVSomJiRo1apSOHDkS0ObSpUvKyclR+/bt1bJlS40ePVplZWUBbU6cOKHs7GwlJCQoMTFR06dP15UrVwLaFBUV6d5775XNZlOXLl1UUFBQvyMEAABNTlABZvv27crJydHu3bvlcrnk8/mUmZmp8+fP+9tMmzZN77//vt5++21t375dJ0+e1GOPPebfXlFRoezsbF2+fFm7du3SG2+8oYKCAs2ePdvf5vjx48rOztZDDz2k0tJSTZ06Vc8884w2b94cgkMGAACmaxZM402bNgUsFxQUKDExUSUlJRo8eLDOnDmjVatWae3atRo6dKgkafXq1erevbt2796tQYMGqbCwUIcPH9aWLVuUlJSkPn36aP78+Zo5c6by8/MVFxenFStWKC0tTYsXL5Ykde/eXTt37tSSJUuUlZUVokMHAACmuqVrYM6cOSNJateunSSppKREPp9PGRkZ/jbdunVT586dVVxcLEkqLi5Wz549lZSU5G+TlZUlj8ejQ4cO+dtc3Ud1m+o+AADA7S2oMzBXq6ys1NSpU3X//ferR48ekiS32624uDi1adMmoG1SUpLcbre/zdXhpXp79bYbtfF4PLp48aLi4+OvGY/X65XX6/UvezweSZLP55PP56vvYUZU9bhNHX+oUIca4aqFLcYKaX/hZou2Av5rilA/bg3x3DBhbpg6H64WqsewKbxe1nXs9Q4wOTk5OnjwoHbu3FnfLkJq4cKFmjt37jXrCwsLlZCQEIERhY7L5Yr0EBoF6lAj1LVYNCCk3TWY+f0rIz2EoGzcuDEs/YbzuWHS3DBtPlwt1HPD5NfLCxcu1KldvQLM5MmTtX79eu3YsUOdOnXyr3c4HLp8+bJOnz4dcBamrKxMDofD32bPnj0B/VV/S+nqNt/85lJZWZnsdnutZ18kKS8vT7m5uf5lj8ejlJQUZWZmym631+cwI87n88nlcmn48OGKjY2N9HAihjrUCFcteuSbdYG8LdrS/P6Ven5vtLyVUZEeTp0dzA/tNXwN8dwwYW6YOh+uFqq50RReL6s/QbmZoAKMZVmaMmWK1q1bp6KiIqWlpQVs79evn2JjY7V161aNHj1aknTkyBGdOHFCTqdTkuR0OrVgwQKVl5crMTFRUlVStNvtSk9P97f5Zhp1uVz+Pmpjs9lks9muWR8bG2vsg1itKRxDKFCHGqGuhbfCzBd9b2WUUWMP1/wN53PDpPqaNh+uFurHz+TXy7qOO6gAk5OTo7Vr1+q//uu/1KpVK/81K61bt1Z8fLxat26t8ePHKzc3V+3atZPdbteUKVPkdDo1aNAgSVJmZqbS09M1ZswYLVq0SG63W7NmzVJOTo4/gEycOFGvvvqqZsyYoR//+Mfatm2b3nrrLW3YsCGY4QIAgCYqqG8hLV++XGfOnNGQIUOUnJzsv7355pv+NkuWLNF3v/tdjR49WoMHD5bD4dA777zj3x4TE6P169crJiZGTqdTTz31lMaOHat58+b526SlpWnDhg1yuVzq3bu3Fi9erJUrV/IVagAAIKkeHyHdTPPmzbVs2TItW7bsum1SU1NvesHSkCFDtG/fvmCGBwAAbhP8FhIAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgnGbB3mHHjh166aWXVFJSolOnTmndunUaNWqUf/uPfvQjvfHGGwH3ycrK0qZNm/zLX331laZMmaL3339f0dHRGj16tJYuXaqWLVv62+zfv185OTn65JNPdMcdd2jKlCmaMWNGPQ4RABqHO5/bENL+bDGWFg2QeuRvlrciKqR9A41d0Gdgzp8/r969e2vZsmXXbfPwww/r1KlT/tuf/vSngO1PPvmkDh06JJfLpfXr12vHjh2aMGGCf7vH41FmZqZSU1NVUlKil156Sfn5+frd734X7HABAEATFPQZmBEjRmjEiBE3bGOz2eRwOGrd9umnn2rTpk365JNP1L9/f0nSK6+8okceeUS/+tWv1LFjR61Zs0aXL1/W66+/rri4ON1zzz0qLS3Vr3/964CgAwAAbk9BB5i6KCoqUmJiotq2bauhQ4fqF7/4hdq3by9JKi4uVps2bfzhRZIyMjIUHR2tjz/+WN///vdVXFyswYMHKy4uzt8mKytLL774or7++mu1bdv2mn16vV55vV7/ssfjkST5fD75fL5wHGbYVY/b1PGHCnWoEa5a2GKskPYXbrZoK+C/tyvqUKUp1CFUz+mm8HpZ17GHPMA8/PDDeuyxx5SWlqZjx47p5z//uUaMGKHi4mLFxMTI7XYrMTExcBDNmqldu3Zyu92SJLfbrbS0tIA2SUlJ/m21BZiFCxdq7ty516wvLCxUQkJCqA4vIlwuV6SH0ChQhxqhrsWiASHtrsHM718Z6SE0CtShisl12LhxY0j7M/n18sKFC3VqF/IA8/jjj/v/3bNnT/Xq1Ut33XWXioqKNGzYsFDvzi8vL0+5ubn+ZY/Ho5SUFGVmZsput4dtv+Hk8/nkcrk0fPhwxcbGRno4EUMdaoSrFj3yN4esr4Zgi7Y0v3+lnt8bLW/l7XvxKnWo0hTqcDA/KyT9NIXXy+pPUG4mLB8hXe1b3/qWOnTooKNHj2rYsGFyOBwqLy8PaHPlyhV99dVX/utmHA6HysrKAtpUL1/v2hqbzSabzXbN+tjYWGMfxGpN4RhCgTrUCHUtTP0Gi7cyytixhxJ1qGJyHUL92mby62Vdxx32vwPzj3/8Q19++aWSk5MlSU6nU6dPn1ZJSYm/zbZt21RZWamBAwf62+zYsSPgczCXy6WuXbvW+vERAAC4vQQdYM6dO6fS0lKVlpZKko4fP67S0lKdOHFC586d0/Tp07V79259/vnn2rp1qx599FF16dJFWVlVp8e6d++uhx9+WM8++6z27Nmjjz76SJMnT9bjjz+ujh07SpKeeOIJxcXFafz48Tp06JDefPNNLV26NOAjIgAAcPsKOsDs3btXffv2Vd++fSVJubm56tu3r2bPnq2YmBjt379f3/ve93T33Xdr/Pjx6tevn/76178GfLyzZs0adevWTcOGDdMjjzyiBx54IOBvvLRu3VqFhYU6fvy4+vXrp5/97GeaPXs2X6EGAACS6nENzJAhQ2RZ1/+q2ubNN78YsF27dlq7du0N2/Tq1Ut//etfgx0eAADGCdVfaW7Iv878+QvZYe3/ZvgtJAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGCfrXqIGGdOdzGxr011VDIdK/0AoAtwPOwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMEHWB27NihkSNHqmPHjoqKitK7774bsN2yLM2ePVvJycmKj49XRkaGPvvss4A2X331lZ588knZ7Xa1adNG48eP17lz5wLa7N+/Xw8++KCaN2+ulJQULVq0KPijAwAATVLQAeb8+fPq3bu3li1bVuv2RYsW6Te/+Y1WrFihjz/+WC1atFBWVpYuXbrkb/Pkk0/q0KFDcrlcWr9+vXbs2KEJEyb4t3s8HmVmZio1NVUlJSV66aWXlJ+fr9/97nf1OEQAANDUNAv2DiNGjNCIESNq3WZZll5++WXNmjVLjz76qCTpP/7jP5SUlKR3331Xjz/+uD799FNt2rRJn3zyifr37y9JeuWVV/TII4/oV7/6lTp27Kg1a9bo8uXLev311xUXF6d77rlHpaWl+vWvfx0QdAAAwO0p6ABzI8ePH5fb7VZGRoZ/XevWrTVw4EAVFxfr8ccfV3Fxsdq0aeMPL5KUkZGh6Ohoffzxx/r+97+v4uJiDR48WHFxcf42WVlZevHFF/X111+rbdu21+zb6/XK6/X6lz0ejyTJ5/PJ5/OF8jAbTPW4TR1/KNhiLNmirap/////NnbhfLzCNSdsMWbUtpppcyJcqEMV6lCjIWsRrte6uvYb0gDjdrslSUlJSQHrk5KS/NvcbrcSExMDB9Gsmdq1axfQJi0t7Zo+qrfVFmAWLlyouXPnXrO+sLBQCQkJ9TyixsHlckV6CBGzaEDNv+f3r4zcQIKwcePGsO8j1HPi6jqbxJQ5EW7UoQp1qNEQtQjXa92FCxfq1C6kASaS8vLylJub61/2eDxKSUlRZmam7HZ7BEdWfz6fTy6XS8OHD1dsbGykhxMRPfI3yxZtaX7/Sj2/N1reyqhID+mmDuZnha3vcM2JHvmbQ9ZXQzBtToQLdahCHWo0ZC3C9VpX/QnKzYQ0wDgcDklSWVmZkpOT/evLysrUp08ff5vy8vKA+125ckVfffWV//4Oh0NlZWUBbaqXq9t8k81mk81mu2Z9bGys8W/+TeEY6stbUfME9FZGBSw3Vg3xWIV6TphQ19qYMifCjTpUoQ41GqIW4Xqtq2u/IQ0waWlpcjgc2rp1qz+weDweffzxx5o0aZIkyel06vTp0yopKVG/fv0kSdu2bVNlZaUGDhzob/Pv//7v8vl8/gNxuVzq2rVrrR8f4ebufG5DpIcAAEDIBP016nPnzqm0tFSlpaWSqi7cLS0t1YkTJxQVFaWpU6fqF7/4hd577z0dOHBAY8eOVceOHTVq1ChJUvfu3fXwww/r2Wef1Z49e/TRRx9p8uTJevzxx9WxY0dJ0hNPPKG4uDiNHz9ehw4d0ptvvqmlS5cGfEQEAABuX0Gfgdm7d68eeugh/3J1qBg3bpwKCgo0Y8YMnT9/XhMmTNDp06f1wAMPaNOmTWrevLn/PmvWrNHkyZM1bNgwRUdHa/To0frNb37j3966dWsVFhYqJydH/fr1U4cOHTR79my+Qg0AACTVI8AMGTJElnX9r2dFRUVp3rx5mjdv3nXbtGvXTmvXrr3hfnr16qW//vWvwQ4PAADcBvgtJAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxmkW6QEATc2dz20IW9+2GEuLBkg98jfLWxEVtv0AQGPHGRgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYJyQB5j8/HxFRUUF3Lp16+bffunSJeXk5Kh9+/Zq2bKlRo8erbKysoA+Tpw4oezsbCUkJCgxMVHTp0/XlStXQj1UAABgqLD8lMA999yjLVu21OykWc1upk2bpg0bNujtt99W69atNXnyZD322GP66KOPJEkVFRXKzs6Ww+HQrl27dOrUKY0dO1axsbH65S9/GY7hAgAAw4QlwDRr1kwOh+Oa9WfOnNGqVau0du1aDR06VJK0evVqde/eXbt379agQYNUWFiow4cPa8uWLUpKSlKfPn00f/58zZw5U/n5+YqLiwvHkAEAgEHCEmA+++wzdezYUc2bN5fT6dTChQvVuXNnlZSUyOfzKSMjw9+2W7du6ty5s4qLizVo0CAVFxerZ8+eSkpK8rfJysrSpEmTdOjQIfXt27fWfXq9Xnm9Xv+yx+ORJPl8Pvl8vnAcZthVjzsU47fFWLfcR6TYoq2A/97OqEUV6lCFOlShDjUashbhem+ta78hDzADBw5UQUGBunbtqlOnTmnu3Ll68MEHdfDgQbndbsXFxalNmzYB90lKSpLb7ZYkud3ugPBSvb162/UsXLhQc+fOvWZ9YWGhEhISbvGoIsvlct1yH4sGhGAgETa/f2Wkh9BoUIsq1KEKdahCHWo0RC02btwYln4vXLhQp3YhDzAjRozw/7tXr14aOHCgUlNT9dZbbyk+Pj7Uu/PLy8tTbm6uf9nj8SglJUWZmZmy2+1h2284+Xw+uVwuDR8+XLGxsbfUV4/8zSEaVcOzRVua379Sz++NlrcyKtLDiShqUYU6VKEOVahDjYasxcH8rLD0W/0Jys2E5SOkq7Vp00Z33323jh49quHDh+vy5cs6ffp0wFmYsrIy/zUzDodDe/bsCeij+ltKtV1XU81ms8lms12zPjY29pbf/CMtFMfgrTD/Se2tjGoSxxEK1KIKdahCHapQhxoNUYtwvbfWtd+w/x2Yc+fO6dixY0pOTla/fv0UGxurrVu3+rcfOXJEJ06ckNPplCQ5nU4dOHBA5eXl/jYul0t2u13p6enhHi4AADBAyM/A/Nu//ZtGjhyp1NRUnTx5UnPmzFFMTIx++MMfqnXr1ho/frxyc3PVrl072e12TZkyRU6nU4MGDZIkZWZmKj09XWPGjNGiRYvkdrs1a9Ys5eTk1HqGBQAA3H5CHmD+8Y9/6Ic//KG+/PJL3XHHHXrggQe0e/du3XHHHZKkJUuWKDo6WqNHj5bX61VWVpZee+01//1jYmK0fv16TZo0SU6nUy1atNC4ceM0b968UA8VAAAYKuQB5s9//vMNtzdv3lzLli3TsmXLrtsmNTU1bFc3AwAA8/FbSAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOGH/Neqm6M7nNjTIfmwxlhYNkHrkb+YXVgEAuApnYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGKdRB5hly5bpzjvvVPPmzTVw4EDt2bMn0kMCAACNQKMNMG+++aZyc3M1Z84c/fd//7d69+6trKwslZeXR3poAAAgwhptgPn1r3+tZ599Vk8//bTS09O1YsUKJSQk6PXXX4/00AAAQIQ1i/QAanP58mWVlJQoLy/Pvy46OloZGRkqLi6u9T5er1der9e/fObMGUnSV199JZ/PF9LxNbtyPqT9XXc/lZYuXKhUM1+0KiqjGmSfjRF1qEEtqlCHKtShCnWo0ZC1+PLLL8PS79mzZyVJlmXduKHVCP3v//6vJcnatWtXwPrp06dbAwYMqPU+c+bMsSRx48aNGzdu3JrA7YsvvrhhVmiUZ2DqIy8vT7m5uf7lyspKffXVV2rfvr2iosxM5B6PRykpKfriiy9kt9sjPZyIoQ41qEUV6lCFOlShDjWaQi0sy9LZs2fVsWPHG7ZrlAGmQ4cOiomJUVlZWcD6srIyORyOWu9js9lks9kC1rVp0yZcQ2xQdrvd2IkYStShBrWoQh2qUIcq1KGG6bVo3br1Tds0yot44+Li1K9fP23dutW/rrKyUlu3bpXT6YzgyAAAQGPQKM/ASFJubq7GjRun/v37a8CAAXr55Zd1/vx5Pf3005EeGgAAiLBGG2B+8IMf6P/+7/80e/Zsud1u9enTR5s2bVJSUlKkh9ZgbDab5syZc81HY7cb6lCDWlShDlWoQxXqUON2qkWUZd3se0oAAACNS6O8BgYAAOBGCDAAAMA4BBgAAGAcAgwAADAOASYEFi5cqPvuu0+tWrVSYmKiRo0apSNHjgS0uXTpknJyctS+fXu1bNlSo0ePvuYP9Z04cULZ2dlKSEhQYmKipk+fritXrvi3FxUVKSoq6pqb2+2+4fj279+vBx98UM2bN1dKSooWLVoUuoO/SkPV4Uc/+lGtdbjnnnuuO7bPP/+81vvs3r07tEVQ6Orw05/+VP369ZPNZlOfPn1q3Vd9Htub1TeUGqoWRUVFevTRR5WcnKwWLVqoT58+WrNmzU3HV9uc+POf/3xLx1ybhqpDfed5Q82JhqpDfn5+rXVo0aLFDcfXUPNBCk0t/va3v+mHP/yhUlJSFB8fr+7du2vp0qXX7KuoqEj33nuvbDabunTpooKCgpuOr6HeN25JaH696PaWlZVlrV692jp48KBVWlpqPfLII1bnzp2tc+fO+dtMnDjRSklJsbZu3Wrt3bvXGjRokPXtb3/bv/3KlStWjx49rIyMDGvfvn3Wxo0brQ4dOlh5eXn+Nh9++KElyTpy5Ih16tQp/62iouK6Yztz5oyVlJRkPfnkk9bBgwetP/3pT1Z8fLz129/+1tg6nD59OuD4v/jiC6tdu3bWnDlzrju248ePW5KsLVu2BNz38uXLjbIOlmVZU6ZMsV599VVrzJgxVu/eva/ZT30e27rUN5QaqhYLFiywZs2aZX300UfW0aNHrZdfftmKjo623n///RuOT5K1evXqgDlx8eLFkBz71RqqDvWZ5w05JxqqDmfPng04/lOnTlnp6enWuHHjbji+hpoPlhWaWqxatcr66U9/ahUVFVnHjh2z/vCHP1jx8fHWK6+84m/z97//3UpISLByc3Otw4cPW6+88ooVExNjbdq06bpja8j3jVtBgAmD8vJyS5K1fft2y7Kq3nBjY2Ott99+29/m008/tSRZxcXFlmVZ1saNG63o6GjL7Xb72yxfvtyy2+2W1+u1LKsmwHz99dd1Hstrr71mtW3b1t+HZVnWzJkzra5du97KIdZJuOrwTevWrbOioqKszz///LpjqX5h37dvXwiOLDj1qcPV5syZU+uLdH0e2/rUN5TCVYvaPPLII9bTTz99wzaSrHXr1tV5/KESrjrUZ55Hck401HwoLS21JFk7duy4YbtIzQfLuvVaVPvJT35iPfTQQ/7lGTNmWPfcc09Amx/84AdWVlbWdfuI5PtGMPgIKQzOnDkjSWrXrp0kqaSkRD6fTxkZGf423bp1U+fOnVVcXCxJKi4uVs+ePQP+UF9WVpY8Ho8OHToU0H+fPn2UnJys4cOH66OPPrrhWIqLizV48GDFxcUF9HvkyBF9/fXXt3agNxHuOlRbtWqVMjIylJqaetMxfe9731NiYqIeeOABvffee/U+tmDUpw51UZ/Htj71DaVw1eJ6+6rez43k5OSoQ4cOGjBggF5//XVZDfCnscJdh2DmeSTnREPNh5UrV+ruu+/Wgw8+eNO2kZgPUuhq8c15X1xcHNCHVPX43qiPSL5vBKPR/iVeU1VWVmrq1Km6//771aNHD0mS2+1WXFzcNT8umZSU5L9+xe12X/NXhquXq9skJydrxYoV6t+/v7xer1auXKkhQ4bo448/1r333lvreNxut9LS0q7bb9u2bW/tgK8jnHW42smTJ/XBBx9o7dq1NxxPy5YttXjxYt1///2Kjo7Wf/7nf2rUqFF699139b3vfa++h3lT9a1DXdTnsQ22vqEUzlp801tvvaVPPvlEv/3tb2/Ybt68eRo6dKgSEhJUWFion/zkJzp37px++tOf1nvfNxPOOtRnnkdqTjTUfLh06ZLWrFmj55577qZtIzEfpNDVYteuXXrzzTe1YcMG/7rrPb4ej0cXL15UfHz8Nf1E6n0jWASYEMvJydHBgwe1c+fOkPfdtWtXde3a1b/87W9/W8eOHdOSJUv0hz/8IeT7uxXhrMPV3njjDbVp00ajRo26YbsOHTooNzfXv3zffffp5MmTeumll8IaYBqqDiZoqFp8+OGHevrpp/X73//+hhd2S9Lzzz/v/3ffvn11/vx5vfTSS2F9wwpnHSI1z+ujoebDunXrdPbsWY0bN+6mbSMxH6TQ1OLgwYN69NFHNWfOHGVmZoZwdI0XHyGF0OTJk7V+/Xp9+OGH6tSpk3+9w+HQ5cuXdfr06YD2ZWVlcjgc/jbfvNK+erm6TW0GDBigo0ePXnd7ffu9FQ1VB8uy9Prrr2vMmDEBpzrrauDAgTes3a26lTrURX0e20jMByn8tai2fft2jRw5UkuWLNHYsWODvv/AgQP1j3/8Q16vN+j71kVD1eFqN5vnpr1GBGvlypX67ne/W6/f0Qv3fJBCU4vDhw9r2LBhmjBhgmbNmhWw7XqPr91ur/Xsy43uU72tsSDAhIBlWZo8ebLWrVunbdu2XXPqrV+/foqNjdXWrVv9644cOaITJ07I6XRKkpxOpw4cOKDy8nJ/G5fLJbvdrvT09Ovuu7S0VMnJydfd7nQ6tWPHDvl8voB+u3btGvLTgA1dh+3bt+vo0aMaP358vcZ7s9rVVyjqUBf1eWzrO8/qq6FqIVV9VTQ7O1svvviiJkyYUK/xlpaWqm3btiH/IbyGrMM31eU1oqHmREPX4fjx4/rwww9v6TUiHPNBCl0tDh06pIceekjjxo3TggULrtmP0+kM6EOqenxvVM+GfN+4JZG6ergpmTRpktW6dWurqKgo4Ot3Fy5c8LeZOHGi1blzZ2vbtm3W3r17LafTaTmdTv/26q8yZmZmWqWlpdamTZusO+64I+CrjEuWLLHeffdd67PPPrMOHDhg/eu//qsVHR1tbdmyxd/mlVdesYYOHepfPn36tJWUlGSNGTPGOnjwoPXnP//ZSkhICMvX4RqqDtWeeuopa+DAgbWO5Zt1KCgosNauXWt9+umn1qeffmotWLDAio6Otl5//fUQVqBKKOpgWZb12WefWfv27bP+5V/+xbr77rutffv2Wfv27fN/M6Auj+0777wT8M2BYOprUi22bdtmJSQkWHl5eQH7+fLLL69bi/fee8/6/e9/bx04cMD67LPPrNdee81KSEiwZs+ebWwd6jLPIzknGqoO1WbNmmV17NjRunLlyjVjieR8sKzQ1OLAgQPWHXfcYT311FMBfZSXl/vbVH+Nevr06dann35qLVu27JqvUUfyfeNWEGBCQFKtt9WrV/vbXLx40frJT35itW3b1kpISLC+//3vW6dOnQro5/PPP7dGjBhhxcfHWx06dLB+9rOfWT6fz7/9xRdftO666y6refPmVrt27awhQ4ZY27ZtC+hjzpw5VmpqasC6v/3tb9YDDzxg2Ww265/+6Z+sF154IeQ1sKyGq4NlVT3B4uPjrd/97ne1juWbdSgoKLC6d+9uJSQkWHa73RowYEDA1xNDKVR1+M53vlNrP8ePH/e3udlju3r1auub/59Sl/qGSkPVYty4cbVu/853vnPdWnzwwQdWnz59rJYtW1otWrSwevfuba1YseKGf1epsdehLvM8knOiIZ8bFRUVVqdOnayf//zntY4lkvPBskJTizlz5tTaxzffAz788EOrT58+VlxcnPWtb30rYB/V/UTqfeNWRFlWA31HDAAAIES4BgYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4/w/3jeTcIK3gRUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['deathY'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016.0    1910\n",
       "2018.0    1718\n",
       "2019.0    1668\n",
       "2017.0    1597\n",
       "2014.0    1586\n",
       "2015.0    1538\n",
       "2013.0    1391\n",
       "2012.0    1357\n",
       "2020.0     922\n",
       "2011.0     901\n",
       "2008.0     723\n",
       "2010.0     644\n",
       "2009.0     571\n",
       "2007.0     527\n",
       "2021.0     512\n",
       "2006.0     446\n",
       "2005.0     290\n",
       "2004.0      48\n",
       "Name: deathY, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['deathY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139620"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18349"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['deathY'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age at Interview `age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='age'\n",
    "var_set=['r8agey'.replace('8',latest_wave)]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Age at Interview',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'domain': 'Demographic',\n",
    " 'recode_type': 'direct_use',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='age'\n",
    "var_set=['r8agey'.replace('8',latest_wave)]\n",
    "available_waves= list(range(1,9))\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    46733.000000\n",
       "mean        70.270815\n",
       "std          9.472927\n",
       "min         31.000000\n",
       "25%         63.000000\n",
       "50%         70.000000\n",
       "75%         77.000000\n",
       "max        103.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)\n",
    "df[varname].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Male `maleYN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "1.man->1\n",
      "2.woman->-1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>conventional_name</th>\n",
       "      <th>varname_in_raw</th>\n",
       "      <th>domain</th>\n",
       "      <th>available_waves</th>\n",
       "      <th>recode_type</th>\n",
       "      <th>reverse_code</th>\n",
       "      <th>maximum_missing_response</th>\n",
       "      <th>replace_dict</th>\n",
       "      <th>standardise</th>\n",
       "      <th>notes</th>\n",
       "      <th>recode_date</th>\n",
       "      <th>var_set</th>\n",
       "      <th>in_ELSA</th>\n",
       "      <th>in_HRS</th>\n",
       "      <th>wave_controller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deathY</td>\n",
       "      <td>Death Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Others</td>\n",
       "      <td>[0]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[radyear]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>Age at Interview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8agey]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>everunemployed</td>\n",
       "      <td>History of Unemployment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lencurmarridge</td>\n",
       "      <td>length of current marriage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1mcurln]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>currentpaternered</td>\n",
       "      <td>Current Marital Status: With Partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8mstat]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zeduccat</td>\n",
       "      <td>Lower Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.Primary education': 1, '3.Upper secondary ...</td>\n",
       "      <td>True</td>\n",
       "      <td>not same as HRS, we use the ISCED 2 code for e...</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[raedisced]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rural</td>\n",
       "      <td>Residence in Rurual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.rural': 1, '0.urban': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>1:rural;-1:urban</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[h8rural]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>citizenship</td>\n",
       "      <td>Citizenship Status</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>whether citizen at baseline interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[racitizen]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>migrantYN</td>\n",
       "      <td>Foreign Born</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.in country': -1, '0.out of country': 1, 'n...</td>\n",
       "      <td>True</td>\n",
       "      <td>Born in Country of Interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[rabcountry]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>maleYN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.man': 1, '2.woman': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[ragender]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             varname                         conventional_name  \\\n",
       "0             deathY                                Death Year   \n",
       "1                age                          Age at Interview   \n",
       "2     everunemployed                   History of Unemployment   \n",
       "3     lencurmarridge                length of current marriage   \n",
       "4  currentpaternered  Current Marital Status: With Partnership   \n",
       "5           Zeduccat                           Lower Education   \n",
       "6              rural                       Residence in Rurual   \n",
       "7        citizenship                        Citizenship Status   \n",
       "8          migrantYN                              Foreign Born   \n",
       "9             maleYN                                      Male   \n",
       "\n",
       "   varname_in_raw                   domain           available_waves  \\\n",
       "0             NaN                   Others                       [0]   \n",
       "1             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "2             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "3             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "4             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "5             NaN  Adulthood Socioeconomic                       [0]   \n",
       "6             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "7             NaN              Demographic                       [0]   \n",
       "8             NaN              Demographic                       [0]   \n",
       "9             NaN              Demographic                       [0]   \n",
       "\n",
       "    recode_type reverse_code maximum_missing_response  \\\n",
       "0    direct_use        False                     None   \n",
       "1    direct_use        False                     None   \n",
       "2    historical        False                     None   \n",
       "3    direct_use        False                     None   \n",
       "4  replace_only        False                     None   \n",
       "5  replace_only         True                     None   \n",
       "6  replace_only        False                     None   \n",
       "7  replace_only        False                     None   \n",
       "8  replace_only        False                     None   \n",
       "9  replace_only        False                     None   \n",
       "\n",
       "                                        replace_dict standardise  \\\n",
       "0                                               None       False   \n",
       "1                                               None        True   \n",
       "2                                               None        True   \n",
       "3                                               None        True   \n",
       "4                                               None        True   \n",
       "5  {'1.Primary education': 1, '3.Upper secondary ...        True   \n",
       "6         {'1.rural': 1, '0.urban': -1, 'nan': None}        True   \n",
       "7              {'0.No': -1, '1.Yes': 1, 'nan': None}        True   \n",
       "8  {'1.in country': -1, '0.out of country': 1, 'n...        True   \n",
       "9           {'1.man': 1, '2.woman': -1, 'nan': None}        True   \n",
       "\n",
       "                                               notes recode_date  \\\n",
       "0                                               None  2023-01-10   \n",
       "1                                               None  2023-01-10   \n",
       "2                                               None  2023-01-10   \n",
       "3                                               None  2023-01-10   \n",
       "4                                               None  2023-01-10   \n",
       "5  not same as HRS, we use the ISCED 2 code for e...  2023-01-10   \n",
       "6                                   1:rural;-1:urban  2023-01-10   \n",
       "7              whether citizen at baseline interview  2023-01-10   \n",
       "8                       Born in Country of Interview  2023-01-10   \n",
       "9                                               None  2023-01-10   \n",
       "\n",
       "                                             var_set in_ELSA in_HRS  \\\n",
       "0                                          [radyear]    True   True   \n",
       "1                                           [r8agey]    True   True   \n",
       "2  [r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...    True   True   \n",
       "3                                         [r1mcurln]   False  False   \n",
       "4                                          [r8mstat]    True  False   \n",
       "5                                        [raedisced]    True   True   \n",
       "6                                          [h8rural]   False  False   \n",
       "7                                        [racitizen]   False  False   \n",
       "8                                       [rabcountry]    True   True   \n",
       "9                                         [ragender]    True   True   \n",
       "\n",
       "  wave_controller  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2     latest_wave  \n",
       "3     latest_wave  \n",
       "4     latest_wave  \n",
       "5     latest_wave  \n",
       "6     latest_wave  \n",
       "7     single_wave  \n",
       "8     single_wave  \n",
       "9     single_wave  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname='maleYN'\n",
    "var_set=['ragender']\n",
    "\n",
    "new_row={'varname':varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': {'1.man': 1, '2.woman': -1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Male',\n",
    " 'domain': 'Demographic',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'in_HRS':True,\n",
    " 'in_ELSA': True,\n",
    " 'standardise': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='maleYN'\n",
    "var_set=['ragender']\n",
    "available_waves= [0]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.the replace dict is \n",
      "{'1.man': 1, '2.woman': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      " {'varname': 'maleYN', 'conventional_name': 'Male', 'varname_in_raw': nan, 'domain': 'Demographic', 'available_waves': [0], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': {'1.man': 1, '2.woman': -1, 'nan': None}, 'standardise': True, 'notes': None, 'recode_date': '2023-01-10', 'var_set': ['ragender']}\n",
      "\n",
      "3. statistics\n",
      " -1    77707\n",
      " 1    61913\n",
      "Name: maleYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='maleYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foreign Born `migrantYN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "1.in country->-1\n",
      "0.out of country->1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>conventional_name</th>\n",
       "      <th>varname_in_raw</th>\n",
       "      <th>domain</th>\n",
       "      <th>available_waves</th>\n",
       "      <th>recode_type</th>\n",
       "      <th>reverse_code</th>\n",
       "      <th>maximum_missing_response</th>\n",
       "      <th>replace_dict</th>\n",
       "      <th>standardise</th>\n",
       "      <th>notes</th>\n",
       "      <th>recode_date</th>\n",
       "      <th>var_set</th>\n",
       "      <th>in_ELSA</th>\n",
       "      <th>in_HRS</th>\n",
       "      <th>wave_controller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deathY</td>\n",
       "      <td>Death Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Others</td>\n",
       "      <td>[0]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[radyear]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>Age at Interview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8agey]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maleYN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.man': 1, '2.woman': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[ragender]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>everunemployed</td>\n",
       "      <td>History of Unemployment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lencurmarridge</td>\n",
       "      <td>length of current marriage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1mcurln]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>currentpaternered</td>\n",
       "      <td>Current Marital Status: With Partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8mstat]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zeduccat</td>\n",
       "      <td>Lower Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.Primary education': 1, '3.Upper secondary ...</td>\n",
       "      <td>True</td>\n",
       "      <td>not same as HRS, we use the ISCED 2 code for e...</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[raedisced]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rural</td>\n",
       "      <td>Residence in Rurual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.rural': 1, '0.urban': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>1:rural;-1:urban</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[h8rural]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>citizenship</td>\n",
       "      <td>Citizenship Status</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>whether citizen at baseline interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[racitizen]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>migrantYN</td>\n",
       "      <td>Foreign Born</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.in country': -1, '0.out of country': 1, 'n...</td>\n",
       "      <td>True</td>\n",
       "      <td>Born in Country of Interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[rabcountry]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             varname                         conventional_name  \\\n",
       "0             deathY                                Death Year   \n",
       "1                age                          Age at Interview   \n",
       "2             maleYN                                      Male   \n",
       "3     everunemployed                   History of Unemployment   \n",
       "4     lencurmarridge                length of current marriage   \n",
       "5  currentpaternered  Current Marital Status: With Partnership   \n",
       "6           Zeduccat                           Lower Education   \n",
       "7              rural                       Residence in Rurual   \n",
       "8        citizenship                        Citizenship Status   \n",
       "9          migrantYN                              Foreign Born   \n",
       "\n",
       "   varname_in_raw                   domain           available_waves  \\\n",
       "0             NaN                   Others                       [0]   \n",
       "1             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "2             NaN              Demographic                       [0]   \n",
       "3             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "4             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "5             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "6             NaN  Adulthood Socioeconomic                       [0]   \n",
       "7             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "8             NaN              Demographic                       [0]   \n",
       "9             NaN              Demographic                       [0]   \n",
       "\n",
       "    recode_type reverse_code maximum_missing_response  \\\n",
       "0    direct_use        False                     None   \n",
       "1    direct_use        False                     None   \n",
       "2  replace_only        False                     None   \n",
       "3    historical        False                     None   \n",
       "4    direct_use        False                     None   \n",
       "5  replace_only        False                     None   \n",
       "6  replace_only         True                     None   \n",
       "7  replace_only        False                     None   \n",
       "8  replace_only        False                     None   \n",
       "9  replace_only        False                     None   \n",
       "\n",
       "                                        replace_dict standardise  \\\n",
       "0                                               None       False   \n",
       "1                                               None        True   \n",
       "2           {'1.man': 1, '2.woman': -1, 'nan': None}        True   \n",
       "3                                               None        True   \n",
       "4                                               None        True   \n",
       "5                                               None        True   \n",
       "6  {'1.Primary education': 1, '3.Upper secondary ...        True   \n",
       "7         {'1.rural': 1, '0.urban': -1, 'nan': None}        True   \n",
       "8              {'0.No': -1, '1.Yes': 1, 'nan': None}        True   \n",
       "9  {'1.in country': -1, '0.out of country': 1, 'n...        True   \n",
       "\n",
       "                                               notes recode_date  \\\n",
       "0                                               None  2023-01-10   \n",
       "1                                               None  2023-01-10   \n",
       "2                                               None  2023-01-10   \n",
       "3                                               None  2023-01-10   \n",
       "4                                               None  2023-01-10   \n",
       "5                                               None  2023-01-10   \n",
       "6  not same as HRS, we use the ISCED 2 code for e...  2023-01-10   \n",
       "7                                   1:rural;-1:urban  2023-01-10   \n",
       "8              whether citizen at baseline interview  2023-01-10   \n",
       "9                       Born in Country of Interview  2023-01-10   \n",
       "\n",
       "                                             var_set in_ELSA in_HRS  \\\n",
       "0                                          [radyear]    True   True   \n",
       "1                                           [r8agey]    True   True   \n",
       "2                                         [ragender]    True   True   \n",
       "3  [r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...    True   True   \n",
       "4                                         [r1mcurln]   False  False   \n",
       "5                                          [r8mstat]    True  False   \n",
       "6                                        [raedisced]    True   True   \n",
       "7                                          [h8rural]   False  False   \n",
       "8                                        [racitizen]   False  False   \n",
       "9                                       [rabcountry]    True   True   \n",
       "\n",
       "  wave_controller  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3     latest_wave  \n",
       "4     latest_wave  \n",
       "5     latest_wave  \n",
       "6     latest_wave  \n",
       "7     latest_wave  \n",
       "8     single_wave  \n",
       "9     single_wave  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname='migrantYN'\n",
    "var_set=['rabcountry']\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': {'1.in country': -1, \n",
    "                  '0.out of country': 1, \n",
    "                  'nan': None},\n",
    " 'notes': 'Born in Country of Interview',\n",
    " 'conventional_name': 'Foreign Born',\n",
    " 'domain': 'Demographic',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'recode_type': 'replace_only',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='migrantYN'\n",
    "var_set=['rabcountry']\n",
    "available_waves= [0]\n",
    "replace_dict=  None\n",
    "notes='Born in Country of Interview' \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [1.in country] with int .. (999 -> none)-1\n",
      "replace response [0.out of country] with int .. (999 -> none)1\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.in country': -1, '0.out of country': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'migrantYN', 'conventional_name': 'Foreign Born', 'varname_in_raw': nan, 'domain': 'Demographic', 'available_waves': [0], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': 'Born in Country of Interview', 'recode_date': '2023-01-10', 'var_set': ['rabcountry'], 'in_ELSA': True, 'in_HRS': True}\n",
      "\n",
      "3. statistics\n",
      "-1.0    124238\n",
      " 1.0     14485\n",
      "Name: migrantYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='migrantYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citizenship Status `citizenship`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "0.No->-1\n",
      "1.Yes->1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>conventional_name</th>\n",
       "      <th>varname_in_raw</th>\n",
       "      <th>domain</th>\n",
       "      <th>available_waves</th>\n",
       "      <th>recode_type</th>\n",
       "      <th>reverse_code</th>\n",
       "      <th>maximum_missing_response</th>\n",
       "      <th>replace_dict</th>\n",
       "      <th>standardise</th>\n",
       "      <th>notes</th>\n",
       "      <th>recode_date</th>\n",
       "      <th>var_set</th>\n",
       "      <th>in_ELSA</th>\n",
       "      <th>in_HRS</th>\n",
       "      <th>wave_controller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deathY</td>\n",
       "      <td>Death Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Others</td>\n",
       "      <td>[0]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[radyear]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>Age at Interview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8agey]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maleYN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.man': 1, '2.woman': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[ragender]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>migrantYN</td>\n",
       "      <td>Foreign Born</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.in country': -1, '0.out of country': 1, 'n...</td>\n",
       "      <td>True</td>\n",
       "      <td>Born in Country of Interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[rabcountry]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>everunemployed</td>\n",
       "      <td>History of Unemployment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lencurmarridge</td>\n",
       "      <td>length of current marriage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1mcurln]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>currentpaternered</td>\n",
       "      <td>Current Marital Status: With Partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8mstat]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zeduccat</td>\n",
       "      <td>Lower Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.Primary education': 1, '3.Upper secondary ...</td>\n",
       "      <td>True</td>\n",
       "      <td>not same as HRS, we use the ISCED 2 code for e...</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[raedisced]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rural</td>\n",
       "      <td>Residence in Rurual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.rural': 1, '0.urban': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>1:rural;-1:urban</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[h8rural]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>citizenship</td>\n",
       "      <td>Citizenship Status</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>whether citizen at baseline interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[racitizen]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             varname                         conventional_name  \\\n",
       "0             deathY                                Death Year   \n",
       "1                age                          Age at Interview   \n",
       "2             maleYN                                      Male   \n",
       "3          migrantYN                              Foreign Born   \n",
       "4     everunemployed                   History of Unemployment   \n",
       "5     lencurmarridge                length of current marriage   \n",
       "6  currentpaternered  Current Marital Status: With Partnership   \n",
       "7           Zeduccat                           Lower Education   \n",
       "8              rural                       Residence in Rurual   \n",
       "9        citizenship                        Citizenship Status   \n",
       "\n",
       "   varname_in_raw                   domain           available_waves  \\\n",
       "0             NaN                   Others                       [0]   \n",
       "1             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "2             NaN              Demographic                       [0]   \n",
       "3             NaN              Demographic                       [0]   \n",
       "4             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "5             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "6             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "7             NaN  Adulthood Socioeconomic                       [0]   \n",
       "8             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "9             NaN              Demographic                       [0]   \n",
       "\n",
       "    recode_type reverse_code maximum_missing_response  \\\n",
       "0    direct_use        False                     None   \n",
       "1    direct_use        False                     None   \n",
       "2  replace_only        False                     None   \n",
       "3  replace_only        False                     None   \n",
       "4    historical        False                     None   \n",
       "5    direct_use        False                     None   \n",
       "6  replace_only        False                     None   \n",
       "7  replace_only         True                     None   \n",
       "8  replace_only        False                     None   \n",
       "9  replace_only        False                     None   \n",
       "\n",
       "                                        replace_dict standardise  \\\n",
       "0                                               None       False   \n",
       "1                                               None        True   \n",
       "2           {'1.man': 1, '2.woman': -1, 'nan': None}        True   \n",
       "3  {'1.in country': -1, '0.out of country': 1, 'n...        True   \n",
       "4                                               None        True   \n",
       "5                                               None        True   \n",
       "6                                               None        True   \n",
       "7  {'1.Primary education': 1, '3.Upper secondary ...        True   \n",
       "8         {'1.rural': 1, '0.urban': -1, 'nan': None}        True   \n",
       "9              {'0.No': -1, '1.Yes': 1, 'nan': None}        True   \n",
       "\n",
       "                                               notes recode_date  \\\n",
       "0                                               None  2023-01-10   \n",
       "1                                               None  2023-01-10   \n",
       "2                                               None  2023-01-10   \n",
       "3                       Born in Country of Interview  2023-01-10   \n",
       "4                                               None  2023-01-10   \n",
       "5                                               None  2023-01-10   \n",
       "6                                               None  2023-01-10   \n",
       "7  not same as HRS, we use the ISCED 2 code for e...  2023-01-10   \n",
       "8                                   1:rural;-1:urban  2023-01-10   \n",
       "9              whether citizen at baseline interview  2023-01-10   \n",
       "\n",
       "                                             var_set in_ELSA in_HRS  \\\n",
       "0                                          [radyear]    True   True   \n",
       "1                                           [r8agey]    True   True   \n",
       "2                                         [ragender]    True   True   \n",
       "3                                       [rabcountry]    True   True   \n",
       "4  [r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...    True   True   \n",
       "5                                         [r1mcurln]   False  False   \n",
       "6                                          [r8mstat]    True  False   \n",
       "7                                        [raedisced]    True   True   \n",
       "8                                          [h8rural]   False  False   \n",
       "9                                        [racitizen]   False  False   \n",
       "\n",
       "  wave_controller  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4     latest_wave  \n",
       "5     latest_wave  \n",
       "6     latest_wave  \n",
       "7     latest_wave  \n",
       "8     latest_wave  \n",
       "9     single_wave  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname='citizenship'\n",
    "var_set=['racitizen']\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': {'0.No': -1, '1.Yes': 1, 'nan': None},\n",
    " 'notes': 'whether citizen at baseline interview',\n",
    " 'conventional_name': 'Citizenship Status',\n",
    " 'domain': 'Demographic',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'recode_type': 'replace_only',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': False,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='citizenship'\n",
    "var_set=['racitizen']\n",
    "available_waves= [0]\n",
    "replace_dict=  None\n",
    "notes='whether citizen at baseline interview' \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [0.No] with int .. (999 -> none)-1\n",
      "replace response [1.Yes] with int .. (999 -> none)1\n",
      "\n",
      "1.the replace dict is \n",
      "{'0.No': -1, '1.Yes': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'citizenship', 'conventional_name': 'Citizenship Status', 'varname_in_raw': nan, 'domain': 'Demographic', 'available_waves': [0], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': 'whether citizen at baseline interview', 'recode_date': '2023-01-10', 'var_set': ['racitizen'], 'in_ELSA': False, 'in_HRS': False}\n",
      "\n",
      "3. statistics\n",
      " 1.0    133671\n",
      "-1.0      4994\n",
      "Name: citizenship, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname = 'citizenship'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region of Residence `rural`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "1.rural->1\n",
      "0.urban->-1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>conventional_name</th>\n",
       "      <th>varname_in_raw</th>\n",
       "      <th>domain</th>\n",
       "      <th>available_waves</th>\n",
       "      <th>recode_type</th>\n",
       "      <th>reverse_code</th>\n",
       "      <th>maximum_missing_response</th>\n",
       "      <th>replace_dict</th>\n",
       "      <th>standardise</th>\n",
       "      <th>notes</th>\n",
       "      <th>recode_date</th>\n",
       "      <th>var_set</th>\n",
       "      <th>in_ELSA</th>\n",
       "      <th>in_HRS</th>\n",
       "      <th>wave_controller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deathY</td>\n",
       "      <td>Death Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Others</td>\n",
       "      <td>[0]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[radyear]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>Age at Interview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8agey]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maleYN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.man': 1, '2.woman': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[ragender]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>migrantYN</td>\n",
       "      <td>Foreign Born</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.in country': -1, '0.out of country': 1, 'n...</td>\n",
       "      <td>True</td>\n",
       "      <td>Born in Country of Interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[rabcountry]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>citizenship</td>\n",
       "      <td>Citizenship Status</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>whether citizen at baseline interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[racitizen]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>everunemployed</td>\n",
       "      <td>History of Unemployment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lencurmarridge</td>\n",
       "      <td>length of current marriage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r1mcurln]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>currentpaternered</td>\n",
       "      <td>Current Marital Status: With Partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[r8mstat]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zeduccat</td>\n",
       "      <td>Lower Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.Primary education': 1, '3.Upper secondary ...</td>\n",
       "      <td>True</td>\n",
       "      <td>not same as HRS, we use the ISCED 2 code for e...</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[raedisced]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rural</td>\n",
       "      <td>Residence in Rurual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'1.rural': 1, '0.urban': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>1:rural;-1:urban</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>[h8rural]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             varname                         conventional_name  \\\n",
       "0             deathY                                Death Year   \n",
       "1                age                          Age at Interview   \n",
       "2             maleYN                                      Male   \n",
       "3          migrantYN                              Foreign Born   \n",
       "4        citizenship                        Citizenship Status   \n",
       "5     everunemployed                   History of Unemployment   \n",
       "6     lencurmarridge                length of current marriage   \n",
       "7  currentpaternered  Current Marital Status: With Partnership   \n",
       "8           Zeduccat                           Lower Education   \n",
       "9              rural                       Residence in Rurual   \n",
       "\n",
       "   varname_in_raw                   domain           available_waves  \\\n",
       "0             NaN                   Others                       [0]   \n",
       "1             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "2             NaN              Demographic                       [0]   \n",
       "3             NaN              Demographic                       [0]   \n",
       "4             NaN              Demographic                       [0]   \n",
       "5             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "6             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "7             NaN  Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "8             NaN  Adulthood Socioeconomic                       [0]   \n",
       "9             NaN              Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "\n",
       "    recode_type reverse_code maximum_missing_response  \\\n",
       "0    direct_use        False                     None   \n",
       "1    direct_use        False                     None   \n",
       "2  replace_only        False                     None   \n",
       "3  replace_only        False                     None   \n",
       "4  replace_only        False                     None   \n",
       "5    historical        False                     None   \n",
       "6    direct_use        False                     None   \n",
       "7  replace_only        False                     None   \n",
       "8  replace_only         True                     None   \n",
       "9  replace_only        False                     None   \n",
       "\n",
       "                                        replace_dict standardise  \\\n",
       "0                                               None       False   \n",
       "1                                               None        True   \n",
       "2           {'1.man': 1, '2.woman': -1, 'nan': None}        True   \n",
       "3  {'1.in country': -1, '0.out of country': 1, 'n...        True   \n",
       "4              {'0.No': -1, '1.Yes': 1, 'nan': None}        True   \n",
       "5                                               None        True   \n",
       "6                                               None        True   \n",
       "7                                               None        True   \n",
       "8  {'1.Primary education': 1, '3.Upper secondary ...        True   \n",
       "9         {'1.rural': 1, '0.urban': -1, 'nan': None}        True   \n",
       "\n",
       "                                               notes recode_date  \\\n",
       "0                                               None  2023-01-10   \n",
       "1                                               None  2023-01-10   \n",
       "2                                               None  2023-01-10   \n",
       "3                       Born in Country of Interview  2023-01-10   \n",
       "4              whether citizen at baseline interview  2023-01-10   \n",
       "5                                               None  2023-01-10   \n",
       "6                                               None  2023-01-10   \n",
       "7                                               None  2023-01-10   \n",
       "8  not same as HRS, we use the ISCED 2 code for e...  2023-01-10   \n",
       "9                                   1:rural;-1:urban  2023-01-10   \n",
       "\n",
       "                                             var_set in_ELSA in_HRS  \\\n",
       "0                                          [radyear]    True   True   \n",
       "1                                           [r8agey]    True   True   \n",
       "2                                         [ragender]    True   True   \n",
       "3                                       [rabcountry]    True   True   \n",
       "4                                        [racitizen]   False  False   \n",
       "5  [r1unemp, r2unemp, r3unemp, r4unemp, r5unemp, ...    True   True   \n",
       "6                                         [r1mcurln]   False  False   \n",
       "7                                          [r8mstat]    True  False   \n",
       "8                                        [raedisced]    True   True   \n",
       "9                                          [h8rural]   False  False   \n",
       "\n",
       "  wave_controller  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "5     latest_wave  \n",
       "6     latest_wave  \n",
       "7     latest_wave  \n",
       "8     latest_wave  \n",
       "9     latest_wave  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname='rural'\n",
    "var_set=['h1rural'.replace('1',latest_wave)]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'1.rural': 1, '0.urban': -1, 'nan': None},\n",
    " 'notes': '1:rural;-1:urban',\n",
    " 'conventional_name': 'Residence in Rurual',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'domain': 'Demographic',\n",
    " 'recode_type': 'replace_only',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': False,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-10'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "varname='rural'\n",
    "var_set=['h1rural'.replace('1',latest_wave)]\n",
    "available_waves= list(range(1,9))\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [1.rural] with int .. (999 -> none)1\n",
      "replace response [0.urban] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.rural': 1, '0.urban': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'rural', 'conventional_name': 'Residence in Rurual', 'varname_in_raw': nan, 'domain': 'Demographic', 'available_waves': [1, 2, 3, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': None, 'recode_date': '2023-01-10', 'var_set': ['h8rural'], 'in_ELSA': False, 'in_HRS': False}\n",
      "\n",
      "3. statistics\n",
      "-1.0    29359\n",
      " 1.0    15198\n",
      "Name: rural, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname = 'rural'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adulthood Socioeconomic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wealth `ZwealthT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='ZwealthT'\n",
    "var_set=['h1atotb'.replace('1',latest_wave)]\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Wealth',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'direct_use',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-12'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='ZwealthT'\n",
    "var_set=['h1atotb'.replace('1',latest_wave)]\n",
    "available_waves= list(range(1,9))\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4.659400e+04\n",
      "mean     3.061818e+05\n",
      "std      1.481495e+06\n",
      "min     -1.138827e+06\n",
      "25%      3.700000e+04\n",
      "50%      1.230000e+05\n",
      "75%      3.270000e+05\n",
      "max      2.067499e+08\n",
      "Name: ZwealthT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "varname='ZwealthT'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income `ZincomeT`\n",
    "\n",
    "special recoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='ZincomeT'\n",
    "var_set=['r1itearn','r1itsemp', 'r1itpena', 'r1itpubpen', 'r1itgxfr', 'r1itothr']\n",
    "var_set=[x.replace('1',latest_wave) for x in var_set]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [ 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': '(after tax) adding together Individual Earnings, Employer Capital Income, Pension or Annuity,Public Pensions,Other Government Transfers,Other Individual Income',\n",
    " 'conventional_name': 'Total Income',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'special_code',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-12'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='ZincomeT'\n",
    "var_set=['r1iearn, r1ipena, r1ipubpen, r1igxfr, r1iothr']\n",
    "var_set=[x.replace('1',latest_wave) for x in var_set]\n",
    "available_waves= list(range(1,9))\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.396200e+05\n",
       "mean     5.082528e+03\n",
       "std      2.184080e+04\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      0.000000e+00\n",
       "75%      4.236578e+03\n",
       "max      5.889591e+06\n",
       "Name: ZincomeT, dtype: float64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname='ZincomeT'\n",
    "var_dict=df_recode_record.loc[df_recode_record['varname']==varname,:].to_dict('records')[0]\n",
    "\n",
    "var_set=var_dict['var_set']\n",
    "temp = data[var_set].fillna(0)\n",
    "df[varname]=temp.apply(sum,axis=1)\n",
    "df[varname].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Household Income (Respondent & Spouse) `HIncome`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='HIncome'\n",
    "var_set=['h2ittot'.replace('2',latest_wave)]\n",
    "\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Total Household Income',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'direct_use',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': False,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-12'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='HIncome'\n",
    "var_set=['h2ittot'.replace('2',latest_wave)]\n",
    "\n",
    "available_waves= [2,4,5,6,7,8]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4.285400e+04\n",
      "mean     2.509210e+04\n",
      "std      4.551648e+04\n",
      "min      0.000000e+00\n",
      "25%      7.131789e+03\n",
      "50%      1.467293e+04\n",
      "75%      3.056559e+04\n",
      "max      5.889635e+06\n",
      "Name: HIncome, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "varname='HIncome'\n",
    "df,df_recode_record = recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education `Zeduccat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "1.Primary education->1\n",
      "3.Upper secondary education->3\n",
      "2.Lower secondary education->2\n",
      "5.First stage of tertiary education->5\n",
      "0.None->None\n",
      "6.Second stage of tertiary education->6\n",
      "4.Post-secondary non tertiary education->4\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    }
   ],
   "source": [
    "varname='Zeduccat'\n",
    "var_set=['raedisced']\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': {'1.Primary education': 1, \n",
    "                  '3.Upper secondary education': 3, \n",
    "                  '2.Lower secondary education': 2, \n",
    "                  '5.First stage of tertiary education': 5, \n",
    "                  '0.None': None, \n",
    "                  '6.Second stage of tertiary education': 6, \n",
    "                  '4.Post-secondary non tertiary education': 4, \n",
    "                  'nan': None},\n",
    " 'notes': \"not same as HRS, we use the ISCED 2 code for education category\",\n",
    " 'conventional_name': 'Lower Education',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'recode_type': 'replace_only',\n",
    " 'reverse_code': True,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS':True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.the replace dict is \n",
      "{'1.Primary education': 1, '3.Upper secondary education': 3, '2.Lower secondary education': 2, '5.First stage of tertiary education': 5, '0.None': None, '6.Second stage of tertiary education': 6, '4.Post-secondary non tertiary education': 4, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'Zeduccat', 'conventional_name': 'Lower Education', 'varname_in_raw': nan, 'domain': 'Adulthood Socioeconomic', 'available_waves': [0], 'recode_type': 'replace_only', 'reverse_code': True, 'maximum_missing_response': None, 'replace_dict': {'1.Primary education': 1, '3.Upper secondary education': 3, '2.Lower secondary education': 2, '5.First stage of tertiary education': 5, '0.None': None, '6.Second stage of tertiary education': 6, '4.Post-secondary non tertiary education': 4, 'nan': None}, 'standardise': True, 'notes': 'not same as HRS, we use the ISCED 2 code for education category', 'recode_date': '2023-01-10', 'var_set': ['raedisced']}\n",
      "\n",
      "3. statistics\n",
      "4.0    46941\n",
      "2.0    27578\n",
      "5.0    25455\n",
      "6.0    25082\n",
      "3.0     6080\n",
      "1.0      980\n",
      "Name: Zeduccat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='Zeduccat'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Marital Status: With Partnership `currentpaternered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='currentpaternered'\n",
    "var_set=['r1mstat'.replace('1',latest_wave)]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Current Marital Status: With Partnership',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'recode_type': 'replace_only',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': False,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='currentpaternered'\n",
    "var_set=['r1mstat'.replace('1',latest_wave)]\n",
    "available_waves= list(range(1,9))\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [5.divorced] with int .. (999 -> none)-1\n",
      "replace response [4.separated] with int .. (999 -> none)-1\n",
      "replace response [1.married] with int .. (999 -> none)1\n",
      "replace response [3.partnered] with int .. (999 -> none)1\n",
      "replace response [7.widowed] with int .. (999 -> none)-1\n",
      "replace response [8.never married] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'5.divorced': -1, '4.separated': -1, '1.married': 1, '3.partnered': 1, '7.widowed': -1, '8.never married': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'currentpaternered', 'conventional_name': 'Current Marital Status: With Partnership', 'varname_in_raw': nan, 'domain': 'Adulthood Socioeconomic', 'available_waves': [1, 2, 3, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': None, 'recode_date': '2023-01-10', 'var_set': ['r8mstat'], 'in_ELSA': True, 'in_HRS': False}\n",
      "\n",
      "3. statistics\n",
      " 1.0    33426\n",
      "-1.0    13274\n",
      "Name: currentpaternered, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='currentpaternered'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## length of current marriage `lencurmarridge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='lencurmarridge'\n",
    "var_set=['r1mcurln'.replace('8',latest_wave)]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'length of current marriage',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'recode_type': 'direct_use',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': False,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='lencurmarridge'\n",
    "var_set=['r1mcurln'.replace('8',latest_wave)]\n",
    "available_waves= list(range(1,9))\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    21710.000000\n",
      "mean        35.903685\n",
      "std         11.649478\n",
      "min          0.000000\n",
      "25%         29.000000\n",
      "50%         36.000000\n",
      "75%         44.000000\n",
      "max         85.000000\n",
      "Name: lencurmarridge, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "varname='lencurmarridge'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History of Unemployment `everunemployed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='everunemployed'\n",
    "var_set=['r{}unemp'.format(str(x)) for x in [1, 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'0.No': -1, '1.Yes': 1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'History of Unemployment',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'historical',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='everunemployed'\n",
    "var_set=['r{}unemp'.format(str(x)) for x in range(1,int(latest_wave)+1)]\n",
    "available_waves= list(range(1,9))\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.the replace dict is \n",
      "{'0.No': -1, '1.Yes': 1, 'nan': None}\n",
      "-1    132195\n",
      " 1      7425\n",
      "Name: everunemployed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='everunemployed'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History of Renting  `everrent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='everrent'\n",
    "var_set=['r{}hownrnt'.format(str(x)) for x in  [1, 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'3.other arrangements': -1, '2.rents home': 1, '1.owns home': -1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'History Of Renting',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'historical',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='everrent'\n",
    "var_set=['r{}hownrnt'.format(str(x)) for x in  [1, 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "available_waves=  [1, 2, 4, 5, 6, 7, 8]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [3.other arrangements] with int .. (999 -> none)-1\n",
      "replace response [2.rents home] with int .. (999 -> none)1\n",
      "replace response [1.owns home] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'3.other arrangements': -1, '2.rents home': 1, '1.owns home': -1, 'nan': None}\n",
      "-1    120718\n",
      " 1     18902\n",
      "Name: everrent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='everrent'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History of Financial Difficulties `everfindiff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "1.yes->1\n",
      "0.no->-1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    }
   ],
   "source": [
    "varname='everfindiff' \n",
    "var_set=['r{}sfnhe'.format(str(x)) for x in [3,7]]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [3, 7],\n",
    " 'replace_dict': {'1.yes': 1, '0.no': -1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'History of Financial Difficulties',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'historical',\n",
    " 'wave_controller': 'financial_difficulties_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-11'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='everfindiff' \n",
    "var_set=['r{}sfnhe'.format(str(x)) for x in [3,7]]\n",
    "\n",
    "available_waves= [3,7] \n",
    "replace_dict= None \n",
    "notes=None\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes) \n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record) \n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [1.yes] with int .. (999 -> none)1\n",
      "replace response [0.no] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.yes': 1, '0.no': -1, 'nan': None}\n",
      "-1    111889\n",
      " 1     27731\n",
      "Name: everfindiff, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='everfindiff'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History of Divorce `everdivorced`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "varname='everdivorced' \n",
    "var_set=['r{}mstat'.format(str(x)) for x in [1, 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'7.widowed': -1, '1.married': -1, '8.never married': -1, '3.partnered': -1, '5.divorced': 1, '4.separated': 1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'History Of Divorce',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'historical',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-11'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "varname='everdivorced' \n",
    "var_set=['r{}mstat'.format(str(x)) for x in [1, 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "available_waves= [1, 2, 4, 5, 6, 7, 8]\n",
    "replace_dict= None \n",
    "notes=None\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes) \n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record) \n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [7.widowed] with int .. (999 -> none)-1\n",
      "replace response [1.married] with int .. (999 -> none)-1\n",
      "replace response [8.never married] with int .. (999 -> none)-1\n",
      "replace response [3.partnered] with int .. (999 -> none)-1\n",
      "replace response [5.divorced] with int .. (999 -> none)1\n",
      "replace response [4.separated] with int .. (999 -> none)1\n",
      "\n",
      "1.the replace dict is \n",
      "{'7.widowed': -1, '1.married': -1, '8.never married': -1, '3.partnered': -1, '5.divorced': 1, '4.separated': 1, 'nan': None}\n",
      "-1    129122\n",
      " 1     10498\n",
      "Name: everdivorced, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='everdivorced'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Never Married `nevermarried`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='nevermarried' \n",
    "var_set=['r{}mstat'.format(latest_wave)]\n",
    "\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'7.widowed': -1, '1.married': -1, '8.never married': 1, '3.partnered': -1, '5.divorced': -1, '4.separated': -1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Never Married',\n",
    " 'domain': 'Adulthood Socioeconomic',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-11'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='nevermarried' \n",
    "var_set=['r{}mstat'.format(latest_wave)]\n",
    "\n",
    "available_waves= [1, 2, 4, 5, 6, 7, 8]\n",
    "replace_dict= None \n",
    "notes=None\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes) \n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record) \n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [7.widowed] with int .. (999 -> none)-1\n",
      "replace response [1.married] with int .. (999 -> none)-1\n",
      "replace response [8.never married] with int .. (999 -> none)1\n",
      "replace response [3.partnered] with int .. (999 -> none)-1\n",
      "replace response [5.divorced] with int .. (999 -> none)-1\n",
      "replace response [4.separated] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'7.widowed': -1, '1.married': -1, '8.never married': 1, '3.partnered': -1, '5.divorced': -1, '4.separated': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'nevermarried', 'conventional_name': 'Never Married', 'varname_in_raw': nan, 'domain': 'Adulthood Socioeconomic', 'available_waves': [1, 2, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': None, 'recode_date': '2023-01-11', 'var_set': ['r8mstat'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1.0    44889\n",
      " 1.0     1811\n",
      "Name: nevermarried, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='nevermarried'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adulthood Health Behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low/No Vigorous Activity `vigactivityYN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "3.1 per week->-1\n",
      "4.1-3 per mon->1\n",
      "2.> 1 per week->-1\n",
      "5.hardly ever or never->1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    }
   ],
   "source": [
    "varname='vigactivityYN'\n",
    "var_set=['r{}vgactx'.format(latest_wave)]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None},\n",
    " 'notes': '>=1 times/week, -1',\n",
    " 'conventional_name': 'Low/No Vigorous Activity',\n",
    " 'domain': 'Adulthood Health Behaviors',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='vigactivityYN'\n",
    "var_set=['r{}vgactx'.format(str(x)) for x in  [1, 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "available_waves=  [1, 2, 4, 5, 6, 7, 8]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [3.1 per week] with int .. (999 -> none)-1\n",
      "replace response [4.1-3 per mon] with int .. (999 -> none)1\n",
      "replace response [2.> 1 per week] with int .. (999 -> none)-1\n",
      "replace response [5.hardly ever or never] with int .. (999 -> none)1\n",
      "\n",
      "1.the replace dict is \n",
      "{'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'vigactivityYN', 'conventional_name': 'Low/No Vigorous Activity', 'varname_in_raw': nan, 'domain': 'Adulthood Health Behaviors', 'available_waves': [1, 2, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': None, 'recode_date': '2023-01-10', 'var_set': ['r8vgactx'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      " 1.0    25620\n",
      "-1.0    20965\n",
      "Name: vigactivityYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='vigactivityYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low/No Moderate Activity `modactivityYN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='modactivityYN'\n",
    "var_set=['r{}mdactx'.format(latest_wave)]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None},\n",
    " 'notes': '>=1 times/week, -1',\n",
    " 'conventional_name': 'Low/No Moderate Activity',\n",
    " 'domain': 'Adulthood Health Behaviors',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.the replace dict is \n",
      "{'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'modactivityYN', 'conventional_name': 'Low/No Moderate Activity', 'varname_in_raw': nan, 'domain': 'Adulthood Health Behaviors', 'available_waves': [1, 2, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': {'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None}, 'standardise': True, 'notes': '>=1 times/week, -1', 'recode_date': '2023-01-10', 'var_set': ['r8mdactx'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1.0    36372\n",
      " 1.0    10230\n",
      "Name: modactivityYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='modactivityYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alcohol Abuse `alcoholYN`\n",
    "\n",
    "Share also have vars indicating the binge drunk frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='alcoholYN'\n",
    "var_set=['r{}drinkb'.format(latest_wave)]\n",
    "\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Directly using the definition of binge drunk from SHARE',\n",
    " 'conventional_name': 'Alcohol Abuse',\n",
    " 'domain': 'Adulthood Health Behaviors',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='alcoholYN'\n",
    "var_set=['r{}drinkb'.format(latest_wave)]\n",
    "\n",
    "available_waves=  [ 2, 4, 5, 6, 7, 8]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [1.yes] with int .. (999 -> none)1\n",
      "replace response [0.no] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.yes': 1, '0.no': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'alcoholYN', 'conventional_name': 'Alcohol Abuse', 'varname_in_raw': nan, 'domain': 'Adulthood Health Behaviors', 'available_waves': [2, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': 'Directly using the definition of binge drunk from SHARE', 'recode_date': '2023-01-10', 'var_set': ['r8drinkb'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1.0    37046\n",
      " 1.0     9514\n",
      "Name: alcoholYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='alcoholYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History of drink `everalcoholYN`\n",
    "\n",
    "they also have var `r1drinkxw`:w1 R drinks alcohol weekly which has information from all waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "varname = 'everalcoholYN'\n",
    "var_set = ['r{}drinkev'.format(str(x)) for x in drink_wave]\n",
    "\n",
    "new_row = {'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [2, 4, 5],\n",
    " 'replace_dict': {'1.yes': 1, '0.no': -1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'History of drink',\n",
    " 'domain': 'Adulthood Health Behaviors',\n",
    " 'recode_type': 'historical',\n",
    " 'wave_controller': 'drink_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': False,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'everalcoholYN'\n",
    "var_set = ['r{}drinkev'.format(str(x)) for x in [2,4,5]]\n",
    "\n",
    "available_waves =  [2,4,5]\n",
    "replace_dict =  None\n",
    "notes = None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [1.yes] with int .. (999 -> none)1\n",
      "replace response [0.no] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.yes': 1, '0.no': -1, 'nan': None}\n",
      " 1    84616\n",
      "-1    55004\n",
      "Name: everalcoholYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='everalcoholYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History of Smoking  `eversmokeYN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='eversmokeYN'\n",
    "var_set=['r{}smokev'.format(str(x)) for x in [1 , 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'History of Smoking',\n",
    " 'domain': 'Adulthood Health Behaviors',\n",
    " 'recode_type': 'historical',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'eversmokeYN'\n",
    "var_set = ['r{}smokev'.format(str(x)) for x in [1 , 2, 4, 5, 6, 7, 8]]\n",
    "\n",
    "available_waves =  [1,2,4,5,6,7,8]\n",
    "replace_dict =  None\n",
    "notes = None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [0.No] with int .. (999 -> none)-1\n",
      "replace response [1.Yes] with int .. (999 -> none)1\n",
      "\n",
      "1.the replace dict is \n",
      "{'0.No': -1, '1.Yes': 1, 'nan': None}\n",
      "-1    77943\n",
      " 1    61677\n",
      "Name: eversmokeYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='eversmokeYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Smoker `currsmokeYN`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "0.No->-1\n",
      "1.Yes->1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    }
   ],
   "source": [
    "varname='currsmokeYN'\n",
    "var_set=['r{}smokev'.format(latest_wave)]\n",
    "\n",
    "new_row={'varname': 'currsmokeYN',\n",
    " 'var_set': ['r8smokev'],\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'0.No': -1, '1.Yes': 1, 'nan': None},\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Current Smoker',\n",
    " 'domain': 'Adulthood Health Behaviors',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-10'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='currsmokeYN'\n",
    "var_set=['r{}smokev'.format(latest_wave)]\n",
    "\n",
    "\n",
    "available_waves=  [1, 2, 4, 5, 6, 7, 8]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [0.No] with int .. (999 -> none)-1\n",
      "replace response [1.Yes] with int .. (999 -> none)1\n",
      "\n",
      "1.the replace dict is \n",
      "{'0.No': -1, '1.Yes': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'currsmokeYN', 'conventional_name': 'Current Smoker', 'varname_in_raw': nan, 'domain': 'Adulthood Health Behaviors', 'available_waves': [1, 2, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': None, 'recode_date': '2023-01-10', 'var_set': ['r8smokev'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1.0    27553\n",
      " 1.0    19152\n",
      "Name: currsmokeYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='currsmokeYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sleep Problems `sleepYN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latest_wave' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_9313/2060109570.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvarname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sleepYN'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvar_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r{}sleep'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest_wave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m new_row={'varname': varname,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'latest_wave' is not defined"
     ]
    }
   ],
   "source": [
    "varname='sleepYN'\n",
    "var_set=['r{}sleep'.format(latest_wave)]\n",
    "\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': {'1.yes': 1, '0.no': -1, 'nan': None},\n",
    " 'notes': \"r been asked have you have trouble recently in sleeping\",\n",
    " 'conventional_name': 'Sleep Problems',\n",
    " 'domain': 'Adulthood Health Behaviors',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-11'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "available_waves=  [1, 2, 4, 5, 6, 7, 8]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [1.yes] with int .. (999 -> none)1\n",
      "replace response [0.no] with int .. (999 -> none)-1\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.yes': 1, '0.no': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'sleepYN', 'conventional_name': 'Sleep Problems', 'varname_in_raw': nan, 'domain': 'Adulthood Health Behaviors', 'available_waves': [1, 2, 4, 5, 6, 7, 8], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': 'r been asked have you have trouble recently in sleeping', 'recode_date': '2023-01-11', 'var_set': ['r8sleep'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1.0    28982\n",
      " 1.0    16786\n",
      "Name: sleepYN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='sleepYN'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Childhood Adversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# racsevent_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Childhood stressful events  `chilstrevents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='chilstrevents'\n",
    "var_set=['racsevent_s']\n",
    "\n",
    "new_row={'varname':varname,\n",
    " 'var_set':var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': None,\n",
    " 'notes': None,\n",
    " 'conventional_name': 'Sum of Childhood Stressful Events',\n",
    " 'domain': 'Childhood Adversity',\n",
    " 'recode_type': 'direct_use',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': False,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-11'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='chilstrevents'\n",
    "var_set=['racsevent_s']\n",
    "\n",
    "\n",
    "available_waves=  [0]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='chilstrevents'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maternal Education `Zmotherseduc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "6.Second stage of tertiary education->6\n",
      "2.Lower secondary education->2\n",
      "1.Primary education->1\n",
      "3.Upper secondary education->3\n",
      "0.None->None\n",
      "5.First stage of tertiary education->5\n",
      "4.Post-secondary non tertiary education->4\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    }
   ],
   "source": [
    "varname='Zmotherseduc'\n",
    "var_set=['ramomedisced']\n",
    "\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': {'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None},\n",
    " 'notes': 'isced standard',\n",
    " 'conventional_name': 'Lower Maternal Education',\n",
    " 'domain': 'Childhood Adversity',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'reverse_code': True,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-11'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='Zmotherseduc'\n",
    "var_set=['ramomedisced']\n",
    "\n",
    "\n",
    "available_waves=  [0]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [6.Second stage of tertiary education] with int .. (999 -> none)6\n",
      "replace response [2.Lower secondary education] with int .. (999 -> none)2\n",
      "replace response [1.Primary education] with int .. (999 -> none)1\n",
      "replace response [3.Upper secondary education] with int .. (999 -> none)3\n",
      "replace response [0.None] with int .. (999 -> none)999\n",
      "replace response [5.First stage of tertiary education] with int .. (999 -> none)5\n",
      "replace response [4.Post-secondary non tertiary education] with int .. (999 -> none)4\n",
      "\n",
      "1.the replace dict is \n",
      "{'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'Zmotherseduc', 'conventional_name': 'Maternal Education', 'varname_in_raw': nan, 'domain': 'Childhood Adversity', 'available_waves': [0], 'recode_type': 'replace_only', 'reverse_code': True, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': 'isced standard', 'recode_date': '2023-01-11', 'var_set': ['ramomedisced'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'single_wave'}\n",
      "\n",
      "3. statistics\n",
      "6.0    28811\n",
      "5.0    19041\n",
      "4.0    12686\n",
      "2.0     3460\n",
      "3.0      867\n",
      "1.0       74\n",
      "Name: Zmotherseduc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='Zmotherseduc'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paternal Education `Zfatherseduc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "6.Second stage of tertiary education->6\n",
      "2.Lower secondary education->2\n",
      "1.Primary education->1\n",
      "3.Upper secondary education->3\n",
      "0.None->None\n",
      "5.First stage of tertiary education->5\n",
      "4.Post-secondary non tertiary education->4\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no0\n",
      "we will keep the original replace_dict\n"
     ]
    }
   ],
   "source": [
    "\n",
    "varname='Zfatherseduc'\n",
    "var_set=['radadedisced']\n",
    "\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': {'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None},\n",
    " 'notes': 'isced standard',\n",
    " 'conventional_name': 'Lower Paternal Education',\n",
    " 'domain': 'Childhood Adversity',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'reverse_code': True,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-11'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='Zfatherseduc'\n",
    "var_set=['radadedisced']\n",
    "\n",
    "\n",
    "available_waves =  [0]\n",
    "replace_dict =  None\n",
    "notes=None \n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [6.Second stage of tertiary education] with int .. (999 -> none)6\n",
      "replace response [2.Lower secondary education] with int .. (999 -> none)2\n",
      "replace response [1.Primary education] with int .. (999 -> none)1\n",
      "replace response [3.Upper secondary education] with int .. (999 -> none)3\n",
      "replace response [0.None] with int .. (999 -> none)999\n",
      "replace response [5.First stage of tertiary education] with int .. (999 -> none)5\n",
      "replace response [4.Post-secondary non tertiary education] with int .. (999 -> none)4\n",
      "\n",
      "1.the replace dict is \n",
      "{'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'Zfatherseduc', 'conventional_name': 'Lower Paternal Education', 'varname_in_raw': nan, 'domain': 'Childhood Adversity', 'available_waves': [0], 'recode_type': 'replace_only', 'reverse_code': True, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': 'isced code', 'recode_date': '2023-01-11', 'var_set': ['radadedisced'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'single_wave'}\n",
      "\n",
      "3. statistics\n",
      "6.0    24435\n",
      "4.0    19622\n",
      "5.0    13075\n",
      "2.0     7116\n",
      "3.0     1285\n",
      "1.0      504\n",
      "Name: Zfatherseduc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='Zfatherseduc'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Father Occupational Status  `fathersocc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "7.Craft or related trades worker->5\n",
      "6.Skilled agricultural or fishery worker->5\n",
      "11.Spontaneous only: there was no main breadwinner->None\n",
      "2.Professional->2\n",
      "9.Elementary occupation->6\n",
      "10.Armed forces->4\n",
      "4.Clerk->3\n",
      "8.Plant/machine operator or assembler->6\n",
      "5.Service, shop or market sales worker->3\n",
      "3.Technician or associate professional->2\n",
      "1.Legislator, senior official or manager->1\n",
      "nan->None\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    }
   ],
   "source": [
    "varname='fathersocc'\n",
    "var_set=['ramaoccup']\n",
    "\n",
    "new_row = {'varname': varname,\n",
    " 'var_set': var_set,\n",
    " 'available_waves': [0],\n",
    " 'replace_dict': {'7.Craft or related trades worker': 5, '6.Skilled agricultural or fishery worker': 5, '11.Spontaneous only: there was no main breadwinner': None, '2.Professional': 2, '9.Elementary occupation': 6, '10.Armed forces': 4, '4.Clerk': 3, '8.Plant/machine operator or assembler': 6, '5.Service, shop or market sales worker': 3, '3.Technician or associate professional': 2, '1.Legislator, senior official or manager': 1, 'nan': None},\n",
    " 'notes': 'not just for father, but the main carer',\n",
    " 'conventional_name': 'Lower Main Carer Occupational Status',\n",
    " 'domain': 'Childhood Adversity',\n",
    " 'recode_type': 'replace_only',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-11'}\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname='fathersocc'\n",
    "var_set=['radadoccup']\n",
    "\n",
    "\n",
    "available_waves=  [0]\n",
    "replace_dict=  None\n",
    "notes=None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace response [7.Craft or related trades worker] with int .. (999 -> none)5\n",
      "replace response [6.Skilled agricultural or fishery worker] with int .. (999 -> none)5\n",
      "replace response [11.Spontaneous only: there was no main breadwinner] with int .. (999 -> none)999\n",
      "replace response [2.Professional] with int .. (999 -> none)2\n",
      "replace response [9.Elementary occupation] with int .. (999 -> none)6\n",
      "replace response [10.Armed forces] with int .. (999 -> none)4\n",
      "replace response [4.Clerk] with int .. (999 -> none)3\n",
      "replace response [8.Plant/machine operator or assembler] with int .. (999 -> none)6\n",
      "replace response [5.Service, shop or market sales worker] with int .. (999 -> none)3\n",
      "replace response [3.Technician or associate professional] with int .. (999 -> none)2\n",
      "replace response [1.Legislator, senior official or manager] with int .. (999 -> none)1\n",
      "\n",
      "1.the replace dict is \n",
      "{'7.Craft or related trades worker': 5, '6.Skilled agricultural or fishery worker': 5, '11.Spontaneous only: there was no main breadwinner': None, '2.Professional': 2, '9.Elementary occupation': 6, '10.Armed forces': 4, '4.Clerk': 3, '8.Plant/machine operator or assembler': 6, '5.Service, shop or market sales worker': 3, '3.Technician or associate professional': 2, '1.Legislator, senior official or manager': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'fathersocc', 'conventional_name': 'Lower Main Carer Occupational Status', 'varname_in_raw': nan, 'domain': 'Childhood Adversity', 'available_waves': [0], 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': None, 'replace_dict': None, 'standardise': True, 'notes': 'not just for father, but the main carer', 'recode_date': '2023-01-11', 'var_set': ['ramaoccup'], 'in_ELSA': False, 'in_HRS': True, 'wave_controller': 'single_wave'}\n",
      "\n",
      "3. statistics\n",
      "5.0    35257\n",
      "6.0    15415\n",
      "2.0    10414\n",
      "3.0     9521\n",
      "1.0     4053\n",
      "4.0      435\n",
      "Name: fathersocc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varname='fathersocc'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adulthood Psychological "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loneliness `Zloneliness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname= 'Zloneliness'\n",
    "varset=['r4leftoutt', \n",
    "         'r4complac',\n",
    "         'r4leftout'] \n",
    "varset=[x.replace('4',latest_wave) for x in varset]\n",
    "\n",
    "\n",
    "new_row={'varname': varname,\n",
    " 'var_set': varset,\n",
    " 'available_waves': [4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'leftout has data from wave 1',\n",
    " 'conventional_name': 'Loneliness',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'multi_response',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': 2,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-11'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname= 'Zloneliness'\n",
    "varset=['r4leftoutt', \n",
    "         'r4complac',\n",
    "         'r4leftout'] \n",
    "varset=[x.replace('4',latest_wave) for x in varset]\n",
    "\n",
    "\n",
    "\n",
    "available_waves=  [4,5,6,7,8]\n",
    "replace_dict=  None\n",
    "notes = None \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "want to check the missings ? 1/0 1\n",
      "0. missing information -------- start\n",
      "3    93858\n",
      "0    45347\n",
      "1      316\n",
      "2       99\n",
      "Name: missing_count, dtype: int64\n",
      "1. maximum_missing_response 2\n",
      "2. reverse_control False\n",
      "3. the replace dict is {'1.hardly ever or never': 1, '3.often': 3, '2.some of the time': 2}\n"
     ]
    }
   ],
   "source": [
    "varname= 'Zloneliness'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Life Satisfaction `Zlifesatis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname= 'Zlifesatis'\n",
    "varset=['r{}satlifez'.format(latest_wave)]\n",
    "\n",
    "\n",
    "new_row={'varname':varname,\n",
    " 'var_set': varset,\n",
    " 'available_waves': [2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'This is an one-question Z-score, different to the HRS definition',\n",
    " 'conventional_name': 'Life Satisfaction',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'direct_use',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': True,\n",
    " 'recode_date': '2023-01-11'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname= 'Zlifesatis'\n",
    "varset=['r{}satlifez'.format(latest_wave)]\n",
    "\n",
    "\n",
    "available_waves=  [2,4,5,6,7,8]\n",
    "replace_dict=  None\n",
    "notes = \"This is a Z-score, different to the HRS definition\" \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4.543600e+04\n",
      "mean     1.386655e-15\n",
      "std      1.000000e+00\n",
      "min     -4.601587e+00\n",
      "25%     -4.799497e-01\n",
      "50%      1.088556e-01\n",
      "75%      6.976609e-01\n",
      "max      1.286466e+00\n",
      "Name: Zlifesatis, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "varname= 'Zlifesatis'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Affect `Znegaffect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname= 'Znegaffect'\n",
    "varset=['r{}eurod'.format(latest_wave)]\n",
    "\n",
    "\n",
    "new_row={'varname':varname,\n",
    " 'var_set': varset,\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Different to HRS, this is a depression indicative sum score',\n",
    " 'conventional_name': 'Depression Score',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'direct_use',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-01-11'}\n",
    "\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname= 'Znegaffect'\n",
    "varset=['r{}eurod'.format(latest_wave)]\n",
    "\n",
    "\n",
    "available_waves=  [1,2,4,5,6,7,8]\n",
    "replace_dict=  None\n",
    "notes = \"Different to HRS, this is a depression indicative sum score\" \n",
    "\n",
    "\n",
    "new_row=new_var_record_input(varname,var_set,available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    46733.000000\n",
      "mean         2.448420\n",
      "std          2.263815\n",
      "min          0.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          4.000000\n",
      "max         12.000000\n",
      "Name: Znegaffect, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "varname= 'Znegaffect'\n",
    "df,df_recode_record=recode_processor(varname,df_recode_record,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data Recode Zone\n",
    "\n",
    "we try to:\n",
    "\n",
    "1. put all recoded raw data in the df_raw_recoded, identified by the merged_id \n",
    "2. all infomations about recoding still stored in the df_recode_record \n",
    "3. column names are formatted as 'varname_wave'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_raw_recoded = pd.DataFrame()\n",
    "df_raw_recoded['mergeid']=df_temp['mergeid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',None)\n",
    "\n",
    "df_raw_recoded=pd.read_csv(share_path/'raw_recoded_data.csv')\n",
    "df_vars_found_in_raw=pd.read_csv(Path.cwd()/'vars_found_in_raw'/'SHARE.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def return_var_set_lst(record):\n",
    "    var_set_dict = {}\n",
    "    for index,row in record.iterrows():\n",
    "        var_set_dict[int(row['wave'])] = {row['file_name']:ast.literal_eval( row['var_set'])}\n",
    "    \n",
    "    return var_set_dict,list(var_set_dict.keys())\n",
    "\n",
    "def folder_name(latest_wave):\n",
    "    return f'sharew{latest_wave}_rel8-0-0_ALL_datasets_stata'\n",
    "\n",
    "def get_raw_info(row,latest_wave):\n",
    "    \"\"\"\n",
    "    return var_set and file_name from row and latest wave\n",
    "    \"\"\"\n",
    "    temp_lst = list(row['var_set'][0][latest_wave].items())[0]\n",
    "    var_set, file_name = temp_lst[1], temp_lst[0]\n",
    "    return var_set, file_name\n",
    "\n",
    "### replace functions ---------------------------\n",
    "def replace_procedure(sliced_data,file_name,latest_wave,row):\n",
    "    print('Replace Procedures start..\\n')\n",
    "    response_list = get_unique_valaues(sliced_data)\n",
    "    print(f'all responses are: {response_list}')\n",
    "\n",
    "    # check whether we have define it before \n",
    "    try:\n",
    "        replace_dict=row['replace_dict'][file_name]\n",
    "        print(f'we have found the dict for wave {latest_wave}:')\n",
    "        print(replace_dict)\n",
    "    except:\n",
    "        print(f'no replace_dict been found for wave {latest_wave}')\n",
    "    \n",
    "    if row['replace_dict']:\n",
    "        print(row['replace_dict'])\n",
    "        using_original_dict_control = input(f'here are the available dicts, do you wish to use? 1->yes 0->no')\n",
    "        if using_original_dict_control == '1':\n",
    "            key=input('type key of it')\n",
    "            row['replace_dict'][file_name] = row['replace_dict'][key]\n",
    "    \n",
    "    #new dict?\n",
    "    replace_control=input(f'do you wish to generate/re-define a replace_dict for wave {latest_wave}? 1->yes others->no')\n",
    "    if replace_control=='1':\n",
    "        row =raw_replace(row,file_name)\n",
    "    \n",
    "    #replace\n",
    "    replace_=input(f'do you wish to replace data in {latest_wave}? 1->yes others->no')\n",
    "    if replace_ =='1':\n",
    "        sliced_data = sliced_data.replace(row['replace_dict'][file_name])\n",
    "    print('Replace Procedures end..\\n')\n",
    "    return row,sliced_data\n",
    "\n",
    "def generate_replace_dict_for_historical_response_raw(sliced_row,sliced_data):\n",
    "    \"\"\"\n",
    "    for raw: generate the replace_dict if there is nothing in sliced_row['replace_dict']/returned object is not dict\n",
    "    difference with the original: we move the existence detection out the function\n",
    "    \"\"\"\n",
    " \n",
    "    replace_dict={}\n",
    "    response_list = get_unique_valaues(sliced_data)\n",
    "    for response in response_list:\n",
    "        Pass_control=True\n",
    "        while Pass_control:\n",
    "            replace_val=input(f'replace response [{response}] with int .. (999 -> none)')\n",
    "            try:\n",
    "                replace_val=int(replace_val)\n",
    "                Pass_control=False\n",
    "            except:\n",
    "                print('error in the response, please try again')\n",
    "\n",
    "        replace_dict[response]= None if replace_val==999 else replace_val \n",
    "\n",
    "    return replace_dict\n",
    "\n",
    "def raw_replace(row,file_name):\n",
    "    \"\"\"\n",
    "    replace the data using the row['replace_dict']\n",
    "    \"\"\"\n",
    "    # get the replace_dict by inputting or from df_recode_record\n",
    "    replace_dict=generate_replace_dict_for_historical_response_raw(row,sliced_data)\n",
    "    replace_dict['nan']=None\n",
    "    \n",
    "    if not row['replace_dict']:\n",
    "        row['replace_dict']={}\n",
    "    \n",
    "    row['replace_dict'][file_name]=replace_dict\n",
    "\n",
    "    return row\n",
    "\n",
    "### replace functions --------------------------- end\n",
    "\n",
    "def mark_df_vars_found_in_raw(varname_in_raw_recoder,latest_wave):\n",
    "    \"\"\"\n",
    "    mark the df_vars_found_in_raw for the 'recoded' column\n",
    "    \"\"\"\n",
    "    c1 = df_vars_found_in_raw['varname']==varname_in_raw_recoder\n",
    "    c2 = df_vars_found_in_raw['wave']==latest_wave\n",
    "    df_vars_found_in_raw.loc[c1 & c2,'recoded']=True\n",
    "    df_vars_found_in_raw.to_csv(Path.cwd()/'vars_found_in_raw'/'SHARE.csv',index=False)\n",
    "    \n",
    "def raw_save_each_var():\n",
    "    mark_df_vars_found_in_raw(varname_in_raw_recoder,latest_wave)\n",
    "    df_recode_record=add_row_to_df_record(row,df_recode_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceived Mastery `Zperceivedmastery`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Perceived Mastery</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['eg_G13']</td>\n",
       "      <td>{'eg_G13': 'Keeping under control'}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              varname  wave                     file_name     var_set  \\\n",
       "15  Perceived Mastery     8  sharew8_rel8-0-0_dropoff.dta  ['eg_G13']   \n",
       "\n",
       "                                  Notes  recoded  \n",
       "15  {'eg_G13': 'Keeping under control'}     True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 raw record\n",
    "varname_in_raw_recoder= 'Perceived Mastery'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 new record\n",
    "varname = 'Zperceivedmastery'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_8512/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "row={'varname': 'Zperceivedmastery',\n",
    " 'var_set': [{8: {'sharew8_rel8-0-0_dropoff.dta': ['eg_G13']}}],\n",
    " 'available_waves': [8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Lower Sense of Mastery',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'single_wave',\n",
    " 'reverse_code': True,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}\n",
    "df_recode_record=add_row_to_df_record(row,df_recode_record) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rarely or never    359\n",
       "6.0                153\n",
       "5.0                 54\n",
       "4.0                 30\n",
       "3.0                 22\n",
       "Very often          17\n",
       "2.0                 13\n",
       "Name: eg_G13, dtype: int64"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_wave = 8\n",
    "#0. retreive data\n",
    "varname = row['varname']\n",
    "var_set, file_name = get_raw_info(row,latest_wave)\n",
    "df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "sliced_data = df_temp[var_set]\n",
    "df_temp = df_temp[['mergeid']]\n",
    "sliced_data[var_set[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#1. replace\n",
    "row,sliced_data = replace_procedure(sliced_data,file_name,latest_wave,row)\n",
    "\n",
    "#2. deal with maximum missing response\n",
    "if len(var_set)>1:\n",
    "    missing_count(sliced_data)\n",
    "    \n",
    "    if row['maximum_missing_response']:\n",
    "        print(f'the maximum missing response is {row[\"maximum_missing_response\"]}')\n",
    "    else:\n",
    "        missing_count_controller = int(input('please specify the missing count (999 is none)'))\n",
    "        row['maximum_missing_response']= missing_count_controller if not missing_count_controller==999 else None\n",
    "\n",
    "#3. deal with reverse_code\n",
    "print(f'the reverse code is {row[\"reverse_code\"]}')\n",
    "reverse_control = input('wish to redefine reverse_conde controller? 1->Change any.other->Not Change')\n",
    "row[\"reverse_code\"]= not row[\"reverse_code\"] if reverse_control=='1' else row[\"reverse_code\"]\n",
    "\n",
    "# reverse control\n",
    "if row[\"reverse_code\"]:\n",
    "    unique_vals = get_unique_valaues(sliced_data)\n",
    "    print(\"4. unique_vals are {}\".format(unique_vals))\n",
    "    replace_dict = generate_value_replace_dict(unique_vals)\n",
    "    print(\"5. dict is {}\".format(replace_dict))\n",
    "    sliced_data.replace(replace_dict,inplace=True)\n",
    "\n",
    "#categorical column pretreatment\n",
    "for column in sliced_data.columns:\n",
    "    if isinstance(sliced_data[column].dtype,pd.api.types.CategoricalDtype):\n",
    "        sliced_data[column]=np.asarray(sliced_data[column])\n",
    "# multiple response\n",
    "if len(var_set)==1:\n",
    "    df_temp[f'{varname}_{latest_wave}']=sliced_data[var_set[0]]\n",
    "else:    \n",
    "    df_temp[f'{varname}_{latest_wave}']=sliced_data.apply(average_response_by_row,axis=1,maximum_missing_response=row[\"maximum_missing_response\"])\n",
    "\n",
    "# savezone\n",
    "df_raw_recoded=pd.merge(left=df_raw_recoded,right=df_temp,on='mergeid',how='outer')\n",
    "mark_df_vars_found_in_raw(varname_in_raw_recoder,latest_wave)\n",
    "df_recode_record=add_row_to_df_record(row,df_recode_record)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0    359\n",
       "6.0    153\n",
       "5.0     54\n",
       "4.0     30\n",
       "3.0     22\n",
       "1.0     17\n",
       "2.0     13\n",
       "Name: Zperceivedmastery_8, dtype: int64"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_recoded[f'{varname}_{latest_wave}'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceived Constraints  `Zperceivedconstraints`\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>1</td>\n",
       "      <td>sharew1_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q2_b', 'q2_c']</td>\n",
       "      <td>{'q2_b': 'I feel that what happens to me is out of my control', 'q2_c': 'I feel left out of things'}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>2</td>\n",
       "      <td>sharew2_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac015_']</td>\n",
       "      <td>{'ac015_': 'Out of control'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>4</td>\n",
       "      <td>sharew4_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac015_']</td>\n",
       "      <td>{'ac015_': 'Out of control'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>5</td>\n",
       "      <td>sharew5_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac015_']</td>\n",
       "      <td>{'ac015_': 'Out of control'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>6</td>\n",
       "      <td>sharew6_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac015_']</td>\n",
       "      <td>{'ac015_': 'Out of control'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>7</td>\n",
       "      <td>sharew7_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac015_']</td>\n",
       "      <td>{'ac015_': 'Out of control'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac015_']</td>\n",
       "      <td>{'ac015_': 'Out of control'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  varname  wave                     file_name  \\\n",
       "8   Perceived Constraints     1  sharew1_rel8-0-0_dropoff.dta   \n",
       "9   Perceived Constraints     2       sharew2_rel8-0-0_ac.dta   \n",
       "10  Perceived Constraints     4       sharew4_rel8-0-0_ac.dta   \n",
       "11  Perceived Constraints     5       sharew5_rel8-0-0_ac.dta   \n",
       "12  Perceived Constraints     6       sharew6_rel8-0-0_ac.dta   \n",
       "13  Perceived Constraints     7       sharew7_rel8-0-0_ac.dta   \n",
       "14  Perceived Constraints     8       sharew8_rel8-0-0_ac.dta   \n",
       "\n",
       "             var_set  \\\n",
       "8   ['q2_b', 'q2_c']   \n",
       "9         ['ac015_']   \n",
       "10        ['ac015_']   \n",
       "11        ['ac015_']   \n",
       "12        ['ac015_']   \n",
       "13        ['ac015_']   \n",
       "14        ['ac015_']   \n",
       "\n",
       "                                                                                                   Notes  \\\n",
       "8   {'q2_b': 'I feel that what happens to me is out of my control', 'q2_c': 'I feel left out of things'}   \n",
       "9                                                                           {'ac015_': 'Out of control'}   \n",
       "10                                                                          {'ac015_': 'Out of control'}   \n",
       "11                                                                          {'ac015_': 'Out of control'}   \n",
       "12                                                                          {'ac015_': 'Out of control'}   \n",
       "13                                                                          {'ac015_': 'Out of control'}   \n",
       "14                                                                          {'ac015_': 'Out of control'}   \n",
       "\n",
       "    recoded  \n",
       "8      True  \n",
       "9     False  \n",
       "10    False  \n",
       "11    False  \n",
       "12    False  \n",
       "13    False  \n",
       "14    False  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conventional_name= 'Perceived Constraints'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==conventional_name,]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_dropoff.dta->{'Never': 1, 'Rarely': 2, 'Sometimes': 3, 'Often': 4, 'Not answered': None, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_8512/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "row={'varname': 'Zperceivedconstraints',\n",
    " 'var_set': [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q2_b', 'q2_c']},\n",
    " 2: {'sharew2_rel8-0-0_ac.dta': ['ac015_']},\n",
    " 4: {'sharew4_rel8-0-0_ac.dta': ['ac015_']},\n",
    " 5: {'sharew5_rel8-0-0_ac.dta': ['ac015_']},\n",
    " 6: {'sharew6_rel8-0-0_ac.dta': ['ac015_']},\n",
    " 7: {'sharew7_rel8-0-0_ac.dta': ['ac015_']},\n",
    " 8: {'sharew8_rel8-0-0_ac.dta': ['ac015_']}}],\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Perceived Constraints',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'latest_wave',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': False,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-18'}\n",
    "df_recode_record=add_row_to_df_record(row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Row Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wave 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_wave = 1\n",
    "\n",
    "varname = row['varname']\n",
    "var_set, file_name = get_raw_info(row,latest_wave)\n",
    "df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "\n",
    "df_temp = df_temp[['mergeid']]\n",
    "sliced_data = df_temp[var_set]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Never', 'Rarely', 'Sometimes', 'Often', 'Not answered']\n",
      "no replace_dict been found\n",
      "do you wish to generate/re-define a replace_dict for wave 1? 1->yes others->no1\n",
      "replace response [Never] with int .. (999 -> none)1\n",
      "replace response [Rarely] with int .. (999 -> none)2\n",
      "replace response [Sometimes] with int .. (999 -> none)3\n",
      "replace response [Often] with int .. (999 -> none)4\n",
      "replace response [Not answered] with int .. (999 -> none)999\n",
      "do you wish to replace data in 1? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    19388\n",
      "2      443\n",
      "1      361\n",
      "Name: missing_count, dtype: int64\n",
      "please specify the missing count (999 is none)2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_8512/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#1. replace\n",
    "row,sliced_data = replace_procedure(sliced_data,file_name,latest_wave,row)\n",
    "\n",
    "#2. deal with maximum missing response\n",
    "if len(var_set)>1:\n",
    "    missing_count(sliced_data)\n",
    "    \n",
    "    if row['maximum_missing_response']:\n",
    "        print(f'the maximum missing response is {row[\"maximum_missing_response\"]}')\n",
    "    else:\n",
    "        missing_count_controller = int(input('please specify the missing count (999 is none)'))\n",
    "        row['maximum_missing_response']= missing_count_controller if not missing_count_controller==999 else None\n",
    "\n",
    "#3. deal with reverse_code\n",
    "print(f'the reverse code is {row[\"reverse_code\"]}')\n",
    "reverse_control = input('wish to redefine reverse_conde controller? 1->Change any.other->Not Change')\n",
    "row[\"reverse_code\"]= not row[\"reverse_code\"] if reverse_control=='1' else row[\"reverse_code\"]\n",
    "\n",
    "# reverse control\n",
    "if row[\"reverse_code\"]:\n",
    "    unique_vals = get_unique_valaues(sliced_data)\n",
    "    print(\"4. unique_vals are {}\".format(unique_vals))\n",
    "    replace_dict = generate_value_replace_dict(unique_vals)\n",
    "    print(\"5. dict is {}\".format(replace_dict))\n",
    "    sliced_data.replace(replace_dict,inplace=True)\n",
    "\n",
    "# multiple response\n",
    "if len(varset)==1:\n",
    "    df_temp[f'{varname}_{latest_wave}']=sliced_data[varset[0]]\n",
    "else:    \n",
    "    df_temp[f'{varname}_{latest_wave}']=sliced_data.apply(average_response_by_row,axis=1,maximum_missing_response=row[\"maximum_missing_response\"])\n",
    "\n",
    "# savezone\n",
    "df_raw_recoded=pd.merge(left=df_raw_recoded,right=df_temp,on='mergeid',how='outer')\n",
    "mark_df_vars_found_in_raw(varname_in_raw_recoder,latest_wave)\n",
    "df_recode_record=add_row_to_df_record(row,df_recode_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trait Anxiety `Zanxiety`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Trait Anxiety</td>\n",
       "      <td>4</td>\n",
       "      <td>sharew4_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh023_', 'mh024_', 'mh025_', 'mh026_', 'mh027_']</td>\n",
       "      <td>{'mh023_': 'Fear of the worst happening', 'mh024_': 'Nervous', 'mh025_': 'Hands trembling', 'mh026_': 'Fear of dying', 'mh027_': 'Felt faint'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Trait Anxiety</td>\n",
       "      <td>5</td>\n",
       "      <td>sharew5_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh023_', 'mh024_', 'mh025_', 'mh026_', 'mh027_']</td>\n",
       "      <td>{'mh023_': 'Fear of the worst happening', 'mh024_': 'Nervous', 'mh025_': 'Hands trembling', 'mh026_': 'Fear of dying', 'mh027_': 'Felt faint'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          varname  wave                file_name  \\\n",
       "16  Trait Anxiety     4  sharew4_rel8-0-0_mh.dta   \n",
       "17  Trait Anxiety     5  sharew5_rel8-0-0_mh.dta   \n",
       "\n",
       "                                               var_set  \\\n",
       "16  ['mh023_', 'mh024_', 'mh025_', 'mh026_', 'mh027_']   \n",
       "17  ['mh023_', 'mh024_', 'mh025_', 'mh026_', 'mh027_']   \n",
       "\n",
       "                                                                                                                                             Notes  \\\n",
       "16  {'mh023_': 'Fear of the worst happening', 'mh024_': 'Nervous', 'mh025_': 'Hands trembling', 'mh026_': 'Fear of dying', 'mh027_': 'Felt faint'}   \n",
       "17  {'mh023_': 'Fear of the worst happening', 'mh024_': 'Nervous', 'mh025_': 'Hands trembling', 'mh026_': 'Fear of dying', 'mh027_': 'Felt faint'}   \n",
       "\n",
       "    recoded  \n",
       "16    False  \n",
       "17    False  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Trait Anxiety'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zanxiety'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "row = {'varname': 'Zanxiety',\n",
    " 'var_set': [{4: {'sharew4_rel8-0-0_mh.dta': ['mh023_',\n",
    "     'mh024_',\n",
    "     'mh025_',\n",
    "     'mh026_',\n",
    "     'mh027_']},\n",
    "   5: {'sharew5_rel8-0-0_mh.dta': ['mh023_',\n",
    "     'mh024_',\n",
    "     'mh025_',\n",
    "     'mh026_',\n",
    "     'mh027_']}}],\n",
    " 'available_waves': [4, 5],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Trait Anxiety',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}\n",
    "df_recode_record=add_row_to_df_record(row,df_recode_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest_wave = 4\n",
    "latest_wave = 5\n",
    "#0. retreive data\n",
    "varname = row['varname']\n",
    "var_set, file_name = get_raw_info(row,latest_wave)\n",
    "df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "sliced_data = df_temp[var_set]\n",
    "df_temp = df_temp[['mergeid']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for column in sliced_data.columns:\n",
    "    print(sliced_data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded):\n",
    "    #1. replace\n",
    "    row,sliced_data = replace_procedure(sliced_data,file_name,latest_wave,row)\n",
    "\n",
    "    #2. deal with maximum missing response\n",
    "    if len(var_set)>1:\n",
    "        missing_count(sliced_data)\n",
    "\n",
    "        if row['maximum_missing_response']:\n",
    "            print(f'the maximum missing response is {row[\"maximum_missing_response\"]}')\n",
    "        else:\n",
    "            missing_count_controller = int(input('please specify the missing count (999 is none)'))\n",
    "            row['maximum_missing_response']= missing_count_controller if not missing_count_controller==999 else None\n",
    "\n",
    "    #3. deal with reverse_code\n",
    "    print(f'the reverse code is {row[\"reverse_code\"]}')\n",
    "    reverse_control = input('wish to redefine reverse_conde controller? 1->Change any.other->Not Change')\n",
    "    row[\"reverse_code\"]= not row[\"reverse_code\"] if reverse_control=='1' else row[\"reverse_code\"]\n",
    "\n",
    "    # reverse control\n",
    "    if row[\"reverse_code\"]:\n",
    "        unique_vals = get_unique_valaues(sliced_data)\n",
    "        print(\"4. unique_vals are {}\".format(unique_vals))\n",
    "        replace_dict = generate_value_replace_dict(unique_vals)\n",
    "        print(\"5. dict is {}\".format(replace_dict))\n",
    "        sliced_data.replace(replace_dict,inplace=True)\n",
    "\n",
    "    # categorical column pretreatment\n",
    "    for column in sliced_data.columns:\n",
    "        if isinstance(sliced_data[column].dtype,pd.api.types.CategoricalDtype):\n",
    "            sliced_data[column]=np.asarray(sliced_data[column])\n",
    "    # multiple response\n",
    "    if len(var_set)==1:\n",
    "        df_temp[f'{varname}_{latest_wave}']=sliced_data[var_set[0]]\n",
    "    else:    \n",
    "        df_temp[f'{varname}_{latest_wave}']=sliced_data.apply(average_response_by_row,axis=1,maximum_missing_response=row[\"maximum_missing_response\"])\n",
    "\n",
    "    # savezone\n",
    "    df_raw_recoded=pd.merge(left=df_raw_recoded,right=df_temp,on='mergeid',how='outer')\n",
    "    mark_df_vars_found_in_raw(varname_in_raw_recoder,latest_wave)\n",
    "    df_recode_record=add_row_to_df_record(row,df_recode_record)\n",
    "    return df_recode_record,df_raw_recoded\n",
    "\n",
    "# raw_multi_response_procedure(sliced_data,file_name,latest_wave,row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hopelessness `Zhopelessness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>1</td>\n",
       "      <td>sharew1_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh003_']</td>\n",
       "      <td>{'mh003_': 'Hopes for the future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>2</td>\n",
       "      <td>sharew2_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh003_']</td>\n",
       "      <td>{'mh003_': 'Hopes for the future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>4</td>\n",
       "      <td>sharew4_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh003_']</td>\n",
       "      <td>{'mh003_': 'Hopes for the future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>5</td>\n",
       "      <td>sharew5_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh003_']</td>\n",
       "      <td>{'mh003_': 'Hopes for the future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>6</td>\n",
       "      <td>sharew6_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh003_']</td>\n",
       "      <td>{'mh003_': 'Hopes for the future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>7</td>\n",
       "      <td>sharew7_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh003_']</td>\n",
       "      <td>{'mh003_': 'Hopes for the future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh003_']</td>\n",
       "      <td>{'mh003_': 'Hopes for the future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         varname  wave                file_name     var_set  \\\n",
       "20  Hopelessness     1  sharew1_rel8-0-0_mh.dta  ['mh003_']   \n",
       "21  Hopelessness     2  sharew2_rel8-0-0_mh.dta  ['mh003_']   \n",
       "22  Hopelessness     4  sharew4_rel8-0-0_mh.dta  ['mh003_']   \n",
       "23  Hopelessness     5  sharew5_rel8-0-0_mh.dta  ['mh003_']   \n",
       "24  Hopelessness     6  sharew6_rel8-0-0_mh.dta  ['mh003_']   \n",
       "25  Hopelessness     7  sharew7_rel8-0-0_mh.dta  ['mh003_']   \n",
       "26  Hopelessness     8  sharew8_rel8-0-0_mh.dta  ['mh003_']   \n",
       "\n",
       "                                 Notes  recoded  \n",
       "20  {'mh003_': 'Hopes for the future'}    False  \n",
       "21  {'mh003_': 'Hopes for the future'}    False  \n",
       "22  {'mh003_': 'Hopes for the future'}    False  \n",
       "23  {'mh003_': 'Hopes for the future'}    False  \n",
       "24  {'mh003_': 'Hopes for the future'}    False  \n",
       "25  {'mh003_': 'Hopes for the future'}    False  \n",
       "26  {'mh003_': 'Hopes for the future'}    False  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Hopelessness'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zhopelessness'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Zhopelessness',\n",
    " 'var_set': [{1: {'sharew1_rel8-0-0_mh.dta': ['mh003_']},\n",
    "   2: {'sharew2_rel8-0-0_mh.dta': ['mh003_']},\n",
    "   4: {'sharew4_rel8-0-0_mh.dta': ['mh003_']},\n",
    "   5: {'sharew5_rel8-0-0_mh.dta': ['mh003_']},\n",
    "   6: {'sharew6_rel8-0-0_mh.dta': ['mh003_']},\n",
    "   7: {'sharew7_rel8-0-0_mh.dta': ['mh003_']},\n",
    "   8: {'sharew8_rel8-0-0_mh.dta': ['mh003_']}}],\n",
    " 'available_waves': [1, 2, 4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Hopelessness',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': True,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 2-------\n",
      "0         No hopes mentioned\n",
      "1        Any hopes mentioned\n",
      "2        Any hopes mentioned\n",
      "3         No hopes mentioned\n",
      "4        Any hopes mentioned\n",
      "                ...         \n",
      "37138    Any hopes mentioned\n",
      "37139    Any hopes mentioned\n",
      "37140    Any hopes mentioned\n",
      "37141    Any hopes mentioned\n",
      "37142    Any hopes mentioned\n",
      "Name: mh003_, Length: 37143, dtype: category\n",
      "Categories (4, object): ['Refusal' < 'Don't know' < 'Any hopes mentioned' < 'No hopes mentioned']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Refusal', \"Don't know\", 'No hopes mentioned', 'Any hopes mentioned']\n",
      "no replace_dict been found for wave 2\n",
      "{'sharew1_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew1_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 2? 1->yes others->no0\n",
      "do you wish to replace data in 2? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew2_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 4-------\n",
      "0        Any hopes mentioned\n",
      "1        Any hopes mentioned\n",
      "2        Any hopes mentioned\n",
      "3        Any hopes mentioned\n",
      "4        Any hopes mentioned\n",
      "                ...         \n",
      "57995     No hopes mentioned\n",
      "57996     No hopes mentioned\n",
      "57997    Any hopes mentioned\n",
      "57998    Any hopes mentioned\n",
      "57999    Any hopes mentioned\n",
      "Name: mh003_, Length: 58000, dtype: category\n",
      "Categories (4, object): ['Refusal' < 'Don't know' < 'Any hopes mentioned' < 'No hopes mentioned']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Refusal', \"Don't know\", 'No hopes mentioned', 'Any hopes mentioned']\n",
      "no replace_dict been found for wave 4\n",
      "{'sharew1_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew2_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew1_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 4? 1->yes others->no0\n",
      "do you wish to replace data in 4? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew2_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew4_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 5-------\n",
      "0        Any hopes mentioned\n",
      "1        Any hopes mentioned\n",
      "2        Any hopes mentioned\n",
      "3        Any hopes mentioned\n",
      "4        Any hopes mentioned\n",
      "                ...         \n",
      "66060    Any hopes mentioned\n",
      "66061    Any hopes mentioned\n",
      "66062    Any hopes mentioned\n",
      "66063    Any hopes mentioned\n",
      "66064     No hopes mentioned\n",
      "Name: mh003_, Length: 66065, dtype: category\n",
      "Categories (4, object): ['Refusal' < 'Don't know' < 'Any hopes mentioned' < 'No hopes mentioned']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Refusal', \"Don't know\", 'No hopes mentioned', 'Any hopes mentioned']\n",
      "no replace_dict been found for wave 5\n",
      "{'sharew1_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew2_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew4_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew1_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 5? 1->yes others->no0\n",
      "do you wish to replace data in 5? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew2_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew4_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 6-------\n",
      "0        Any hopes mentioned\n",
      "1        Any hopes mentioned\n",
      "2        Any hopes mentioned\n",
      "3        Any hopes mentioned\n",
      "4        Any hopes mentioned\n",
      "                ...         \n",
      "68080     No hopes mentioned\n",
      "68081    Any hopes mentioned\n",
      "68082    Any hopes mentioned\n",
      "68083     No hopes mentioned\n",
      "68084     No hopes mentioned\n",
      "Name: mh003_, Length: 68085, dtype: category\n",
      "Categories (4, object): ['Refusal' < 'Don't know' < 'Any hopes mentioned' < 'No hopes mentioned']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Refusal', \"Don't know\", 'No hopes mentioned', 'Any hopes mentioned']\n",
      "no replace_dict been found for wave 6\n",
      "{'sharew1_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew2_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew4_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew1_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 6? 1->yes others->no0\n",
      "do you wish to replace data in 6? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew2_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew4_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew6_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 7-------\n",
      "0        NaN\n",
      "1        NaN\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "        ... \n",
      "77197    NaN\n",
      "77198    NaN\n",
      "77199    NaN\n",
      "77200    NaN\n",
      "77201    NaN\n",
      "Name: mh003_, Length: 77202, dtype: category\n",
      "Categories (4, object): ['Refusal' < 'Don't know' < 'Any hopes mentioned' < 'No hopes mentioned']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Refusal', \"Don't know\", 'No hopes mentioned', 'Any hopes mentioned']\n",
      "no replace_dict been found for wave 7\n",
      "{'sharew1_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew2_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew4_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew6_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew1_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 7? 1->yes others->no0\n",
      "do you wish to replace data in 7? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew2_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew4_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew6_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew7_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 8-------\n",
      "0        Any hopes mentioned\n",
      "1        Any hopes mentioned\n",
      "2        Any hopes mentioned\n",
      "3                 Don't know\n",
      "4         No hopes mentioned\n",
      "                ...         \n",
      "46728    Any hopes mentioned\n",
      "46729     No hopes mentioned\n",
      "46730     No hopes mentioned\n",
      "46731    Any hopes mentioned\n",
      "46732     No hopes mentioned\n",
      "Name: mh003_, Length: 46733, dtype: category\n",
      "Categories (4, object): ['Refusal' < 'Don't know' < 'Any hopes mentioned' < 'No hopes mentioned']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Refusal', \"Don't know\", 'No hopes mentioned', 'Any hopes mentioned']\n",
      "no replace_dict been found for wave 8\n",
      "{'sharew1_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew2_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew4_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew6_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}, 'sharew7_rel8-0-0_mh.dta': {'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew1_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 8? 1->yes others->no0\n",
      "do you wish to replace data in 8? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew2_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew4_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew6_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew7_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "sharew8_rel8-0-0_mh.dta->{'Refusal': None, \"Don't know\": None, 'No hopes mentioned': 1, 'Any hopes mentioned': -1, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#for latest_wave in row['available_waves']:\n",
    "for latest_wave in [2, 4, 5, 6, 7, 8]:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loneliness  `Zloneliness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Loneliness</td>\n",
       "      <td>4</td>\n",
       "      <td>sharew4_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q5a', 'q5b', 'q5c', 'q5d']</td>\n",
       "      <td>{'q5a': 'How much of time: feel you lack companionship', 'q5b': 'How much of time: feel left out', 'q5c': 'How much of time: feel isolated from others', 'q5d': 'How much of time: feel lonely'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Loneliness</td>\n",
       "      <td>5</td>\n",
       "      <td>sharew5_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh034_', 'mh035_', 'mh036_', 'mh037_']</td>\n",
       "      <td>{'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Loneliness</td>\n",
       "      <td>6</td>\n",
       "      <td>sharew6_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh034_', 'mh035_', 'mh036_', 'mh037_']</td>\n",
       "      <td>{'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Loneliness</td>\n",
       "      <td>7</td>\n",
       "      <td>sharew7_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh034_', 'mh035_', 'mh036_', 'mh037_']</td>\n",
       "      <td>{'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Loneliness</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_mh.dta</td>\n",
       "      <td>['mh034_', 'mh035_', 'mh036_', 'mh037_']</td>\n",
       "      <td>{'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       varname  wave                     file_name  \\\n",
       "27  Loneliness     4  sharew4_rel8-0-0_dropoff.dta   \n",
       "28  Loneliness     5       sharew5_rel8-0-0_mh.dta   \n",
       "29  Loneliness     6       sharew6_rel8-0-0_mh.dta   \n",
       "30  Loneliness     7       sharew7_rel8-0-0_mh.dta   \n",
       "31  Loneliness     8       sharew8_rel8-0-0_mh.dta   \n",
       "\n",
       "                                     var_set  \\\n",
       "27              ['q5a', 'q5b', 'q5c', 'q5d']   \n",
       "28  ['mh034_', 'mh035_', 'mh036_', 'mh037_']   \n",
       "29  ['mh034_', 'mh035_', 'mh036_', 'mh037_']   \n",
       "30  ['mh034_', 'mh035_', 'mh036_', 'mh037_']   \n",
       "31  ['mh034_', 'mh035_', 'mh036_', 'mh037_']   \n",
       "\n",
       "                                                                                                                                                                                               Notes  \\\n",
       "27  {'q5a': 'How much of time: feel you lack companionship', 'q5b': 'How much of time: feel left out', 'q5c': 'How much of time: feel isolated from others', 'q5d': 'How much of time: feel lonely'}   \n",
       "28                                                           {'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}   \n",
       "29                                                           {'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}   \n",
       "30                                                           {'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}   \n",
       "31                                                           {'mh034_': 'Feels lack of companionship', 'mh035_': 'Feels left out', 'mh036_': 'Feels isolated from others', 'mh037_': 'Feels lonely'}   \n",
       "\n",
       "    recoded  \n",
       "27    False  \n",
       "28    False  \n",
       "29    False  \n",
       "30    False  \n",
       "31    False  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Loneliness'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zloneliness'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = {'varname': 'Zloneliness',\n",
    " 'var_set': [{4: {'sharew4_rel8-0-0_dropoff.dta': ['q5a',\n",
    "     'q5b',\n",
    "     'q5c',\n",
    "     'q5d']},\n",
    "   5: {'sharew5_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']},\n",
    "   6: {'sharew6_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']},\n",
    "   7: {'sharew7_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']},\n",
    "   8: {'sharew8_rel8-0-0_mh.dta': ['mh034_', 'mh035_', 'mh036_', 'mh037_']}}],\n",
    " 'available_waves': [4, 5, 6, 7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'loneliness',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': 4,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 5-------\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "66060        Some of the time\n",
      "66061    Hardly ever or never\n",
      "66062        Some of the time\n",
      "66063                   Often\n",
      "66064    Hardly ever or never\n",
      "Name: mh034_, Length: 66065, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "66060        Some of the time\n",
      "66061    Hardly ever or never\n",
      "66062    Hardly ever or never\n",
      "66063                   Often\n",
      "66064    Hardly ever or never\n",
      "Name: mh035_, Length: 66065, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "66060    Hardly ever or never\n",
      "66061    Hardly ever or never\n",
      "66062    Hardly ever or never\n",
      "66063        Some of the time\n",
      "66064    Hardly ever or never\n",
      "Name: mh036_, Length: 66065, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "66060    Hardly ever or never\n",
      "66061    Hardly ever or never\n",
      "66062        Some of the time\n",
      "66063        Some of the time\n",
      "66064    Hardly ever or never\n",
      "Name: mh037_, Length: 66065, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Hardly ever or never', 'Often', 'Refusal', \"Don't know\", 'Some of the time']\n",
      "no replace_dict been found for wave 5\n",
      "{'sharew4_rel8-0-0_dropoff.dta': {'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no0\n",
      "do you wish to generate/re-define a replace_dict for wave 5? 1->yes others->no1\n",
      "replace response [Hardly ever or never] with int .. (999 -> none)1\n",
      "replace response [Often] with int .. (999 -> none)3\n",
      "replace response [Refusal] with int .. (999 -> none)999\n",
      "replace response [Don't know] with int .. (999 -> none)999\n",
      "replace response [Some of the time] with int .. (999 -> none)2\n",
      "do you wish to replace data in 5? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    64364\n",
      "4     1373\n",
      "1      231\n",
      "2       52\n",
      "3       45\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 4\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew4_rel8-0-0_dropoff.dta->{'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 6-------\n",
      "0            Some of the time\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4            Some of the time\n",
      "                 ...         \n",
      "68080                   Often\n",
      "68081        Some of the time\n",
      "68082    Hardly ever or never\n",
      "68083    Hardly ever or never\n",
      "68084    Hardly ever or never\n",
      "Name: mh034_, Length: 68085, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0            Some of the time\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "68080        Some of the time\n",
      "68081    Hardly ever or never\n",
      "68082    Hardly ever or never\n",
      "68083    Hardly ever or never\n",
      "68084    Hardly ever or never\n",
      "Name: mh035_, Length: 68085, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "68080        Some of the time\n",
      "68081    Hardly ever or never\n",
      "68082    Hardly ever or never\n",
      "68083    Hardly ever or never\n",
      "68084    Hardly ever or never\n",
      "Name: mh036_, Length: 68085, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0            Some of the time\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3        Hardly ever or never\n",
      "4            Some of the time\n",
      "                 ...         \n",
      "68080                   Often\n",
      "68081    Hardly ever or never\n",
      "68082    Hardly ever or never\n",
      "68083    Hardly ever or never\n",
      "68084    Hardly ever or never\n",
      "Name: mh037_, Length: 68085, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Hardly ever or never', 'Often', 'Refusal', \"Don't know\", 'Some of the time']\n",
      "no replace_dict been found for wave 6\n",
      "{'sharew4_rel8-0-0_dropoff.dta': {'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew5_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 6? 1->yes others->no0\n",
      "do you wish to replace data in 6? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    64864\n",
      "4     3059\n",
      "1      130\n",
      "2       22\n",
      "3       10\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 4\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew4_rel8-0-0_dropoff.dta->{'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "sharew6_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 7-------\n",
      "0        NaN\n",
      "1        NaN\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "        ... \n",
      "77197    NaN\n",
      "77198    NaN\n",
      "77199    NaN\n",
      "77200    NaN\n",
      "77201    NaN\n",
      "Name: mh034_, Length: 77202, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        NaN\n",
      "1        NaN\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "        ... \n",
      "77197    NaN\n",
      "77198    NaN\n",
      "77199    NaN\n",
      "77200    NaN\n",
      "77201    NaN\n",
      "Name: mh035_, Length: 77202, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        NaN\n",
      "1        NaN\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "        ... \n",
      "77197    NaN\n",
      "77198    NaN\n",
      "77199    NaN\n",
      "77200    NaN\n",
      "77201    NaN\n",
      "Name: mh036_, Length: 77202, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        NaN\n",
      "1        NaN\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "        ... \n",
      "77197    NaN\n",
      "77198    NaN\n",
      "77199    NaN\n",
      "77200    NaN\n",
      "77201    NaN\n",
      "Name: mh037_, Length: 77202, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Hardly ever or never', 'Often', 'Refusal', \"Don't know\", 'Some of the time']\n",
      "no replace_dict been found for wave 7\n",
      "{'sharew4_rel8-0-0_dropoff.dta': {'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}, 'sharew6_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew5_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 7? 1->yes others->no0\n",
      "do you wish to replace data in 7? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "4    63574\n",
      "0    13568\n",
      "1       38\n",
      "3       13\n",
      "2        9\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 4\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew4_rel8-0-0_dropoff.dta->{'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "sharew6_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "sharew7_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 8-------\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3                  Don't know\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "46728    Hardly ever or never\n",
      "46729        Some of the time\n",
      "46730                   Often\n",
      "46731    Hardly ever or never\n",
      "46732        Some of the time\n",
      "Name: mh034_, Length: 46733, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3                  Don't know\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "46728    Hardly ever or never\n",
      "46729        Some of the time\n",
      "46730        Some of the time\n",
      "46731    Hardly ever or never\n",
      "46732                   Often\n",
      "Name: mh035_, Length: 46733, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3                  Don't know\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "46728    Hardly ever or never\n",
      "46729        Some of the time\n",
      "46730                   Often\n",
      "46731        Some of the time\n",
      "46732    Hardly ever or never\n",
      "Name: mh036_, Length: 46733, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "0        Hardly ever or never\n",
      "1        Hardly ever or never\n",
      "2        Hardly ever or never\n",
      "3                  Don't know\n",
      "4        Hardly ever or never\n",
      "                 ...         \n",
      "46728    Hardly ever or never\n",
      "46729        Some of the time\n",
      "46730                   Often\n",
      "46731        Some of the time\n",
      "46732                   Often\n",
      "Name: mh037_, Length: 46733, dtype: category\n",
      "Categories (5, object): ['Refusal' < 'Don't know' < 'Often' < 'Some of the time' < 'Hardly ever or never']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Hardly ever or never', 'Often', 'Refusal', \"Don't know\", 'Some of the time']\n",
      "no replace_dict been found for wave 8\n",
      "{'sharew4_rel8-0-0_dropoff.dta': {'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}, 'sharew5_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}, 'sharew6_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}, 'sharew7_rel8-0-0_mh.dta': {'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew5_rel8-0-0_mh.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 8? 1->yes others->no0\n",
      "do you wish to replace data in 8? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    45525\n",
      "4     1009\n",
      "1      150\n",
      "2       32\n",
      "3       17\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 4\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew4_rel8-0-0_dropoff.dta->{'Hardly ever or never': 3, 'Often': 1, 'Not answered': None, 'Some of the time': 2, 'nan': None}\n",
      "sharew5_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "sharew6_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "sharew7_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "sharew8_rel8-0-0_mh.dta->{'Hardly ever or never': 1, 'Often': 3, 'Refusal': None, \"Don't know\": None, 'Some of the time': 2, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "for latest_wave in [5,6,7,8]:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreeableness  `Zagreeableness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>7</td>\n",
       "      <td>sharew7_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac702_', 'ac711_']</td>\n",
       "      <td>{'ac702_': 'general trusting', 'ac711_': 'considerate and kind to almost everyone'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac702_', 'ac711_']</td>\n",
       "      <td>{'ac702_': 'general trusting', 'ac711_': 'considerate and kind to almost everyone'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          varname  wave                file_name               var_set  \\\n",
       "32  Agreeableness     7  sharew7_rel8-0-0_ac.dta  ['ac702_', 'ac711_']   \n",
       "33  Agreeableness     8  sharew8_rel8-0-0_ac.dta  ['ac702_', 'ac711_']   \n",
       "\n",
       "                                                                                  Notes  \\\n",
       "32  {'ac702_': 'general trusting', 'ac711_': 'considerate and kind to almost everyone'}   \n",
       "33  {'ac702_': 'general trusting', 'ac711_': 'considerate and kind to almost everyone'}   \n",
       "\n",
       "    recoded  \n",
       "32    False  \n",
       "33    False  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Agreeableness'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zagreeableness'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Zagreeableness',\n",
    " 'var_set': [{7: {'sharew7_rel8-0-0_ac.dta': ['ac702_', 'ac711_']},\n",
    "   8: {'sharew8_rel8-0-0_ac.dta': ['ac702_', 'ac711_']}}],\n",
    " 'available_waves': [7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Agreeableness',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 7-------\n",
      "0                    Agree a little\n",
      "1        Neither agree nor disagree\n",
      "2                    Agree strongly\n",
      "3                    Agree a little\n",
      "4                    Agree a little\n",
      "                    ...            \n",
      "77197                Agree strongly\n",
      "77198    Neither agree nor disagree\n",
      "77199    Neither agree nor disagree\n",
      "77200    Neither agree nor disagree\n",
      "77201             Disagree a little\n",
      "Name: ac702_, Length: 77202, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "0                    Agree a little\n",
      "1                    Agree strongly\n",
      "2                    Agree strongly\n",
      "3                    Agree a little\n",
      "4                    Agree a little\n",
      "                    ...            \n",
      "77197                Agree strongly\n",
      "77198    Neither agree nor disagree\n",
      "77199                Agree strongly\n",
      "77200    Neither agree nor disagree\n",
      "77201                Agree strongly\n",
      "Name: ac711_, Length: 77202, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Disagree a little', 'Agree a little', 'Refusal', 'Neither agree nor disagree', 'Agree strongly', 'Disagree strongly', \"Don't know\"]\n",
      "no replace_dict been found for wave 7\n",
      "do you wish to generate/re-define a replace_dict for wave 7? 1->yes others->no1\n",
      "replace response [Disagree a little] with int .. (999 -> none)4\n",
      "replace response [Agree a little] with int .. (999 -> none)2\n",
      "replace response [Refusal] with int .. (999 -> none)999\n",
      "replace response [Neither agree nor disagree] with int .. (999 -> none)3\n",
      "replace response [Agree strongly] with int .. (999 -> none)1\n",
      "replace response [Disagree strongly] with int .. (999 -> none)5\n",
      "replace response [Don't know] with int .. (999 -> none)999\n",
      "do you wish to replace data in 7? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    74773\n",
      "2     2242\n",
      "1      187\n",
      "Name: missing_count, dtype: int64\n",
      "please specify the missing count (999 is none)2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 8-------\n",
      "0                               NaN\n",
      "1                               NaN\n",
      "2                               NaN\n",
      "3                               NaN\n",
      "4                               NaN\n",
      "                    ...            \n",
      "46728                Agree a little\n",
      "46729                Agree a little\n",
      "46730                Agree strongly\n",
      "46731             Disagree a little\n",
      "46732    Neither agree nor disagree\n",
      "Name: ac702_, Length: 46733, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "0                               NaN\n",
      "1                               NaN\n",
      "2                               NaN\n",
      "3                               NaN\n",
      "4                               NaN\n",
      "                    ...            \n",
      "46728    Neither agree nor disagree\n",
      "46729                Agree a little\n",
      "46730                Agree strongly\n",
      "46731                Agree a little\n",
      "46732                Agree strongly\n",
      "Name: ac711_, Length: 46733, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Disagree a little', 'Agree a little', 'Refusal', 'Neither agree nor disagree', 'Agree strongly', 'Disagree strongly', \"Don't know\"]\n",
      "no replace_dict been found for wave 8\n",
      "{'sharew7_rel8-0-0_ac.dta': {'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, \"Don't know\": None, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew7_rel8-0-0_ac.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 8? 1->yes others->no0\n",
      "do you wish to replace data in 8? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "2    36814\n",
      "0     9894\n",
      "1       25\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew7_rel8-0-0_ac.dta->{'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, \"Don't know\": None, 'nan': None}\n",
      "sharew8_rel8-0-0_ac.dta->{'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, \"Don't know\": None, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count            46733\n",
      "unique           46733\n",
      "top       AT-001215-01\n",
      "freq                 1\n",
      "Name: mergeid, dtype: object\n",
      "count    9919.000000\n",
      "mean        2.141446\n",
      "std         0.800002\n",
      "min         1.000000\n",
      "25%         1.500000\n",
      "50%         2.000000\n",
      "75%         2.500000\n",
      "max         5.000000\n",
      "Name: Zagreeableness_8, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for column in df_temp.columns:\n",
    "    print(df_temp[column].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extroversion  `Zextroversion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Extroversion</td>\n",
       "      <td>7</td>\n",
       "      <td>sharew7_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac706_', 'ac711_']</td>\n",
       "      <td>{'ac706_': 'outgoing, sociable', 'ac711_': 'considerate and kind to almost everyone'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Extroversion</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac706_', 'ac711_']</td>\n",
       "      <td>{'ac706_': 'outgoing, sociable', 'ac711_': 'considerate and kind to almost everyone'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         varname  wave                file_name               var_set  \\\n",
       "34  Extroversion     7  sharew7_rel8-0-0_ac.dta  ['ac706_', 'ac711_']   \n",
       "35  Extroversion     8  sharew8_rel8-0-0_ac.dta  ['ac706_', 'ac711_']   \n",
       "\n",
       "                                                                                    Notes  \\\n",
       "34  {'ac706_': 'outgoing, sociable', 'ac711_': 'considerate and kind to almost everyone'}   \n",
       "35  {'ac706_': 'outgoing, sociable', 'ac711_': 'considerate and kind to almost everyone'}   \n",
       "\n",
       "    recoded  \n",
       "34    False  \n",
       "35    False  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Extroversion'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zextroversion'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Zextroversion',\n",
    " 'var_set': [{7: {'sharew7_rel8-0-0_ac.dta': ['ac706_', 'ac711_']},\n",
    "   8: {'sharew8_rel8-0-0_ac.dta': ['ac706_', 'ac711_']}}],\n",
    " 'available_waves': [7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Extroversion',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 7-------\n",
      "0        Neither agree nor disagree\n",
      "1                    Agree strongly\n",
      "2        Neither agree nor disagree\n",
      "3                    Agree a little\n",
      "4                    Agree a little\n",
      "                    ...            \n",
      "77197                Agree strongly\n",
      "77198             Disagree a little\n",
      "77199                Agree strongly\n",
      "77200    Neither agree nor disagree\n",
      "77201                Agree a little\n",
      "Name: ac706_, Length: 77202, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "0                    Agree a little\n",
      "1                    Agree strongly\n",
      "2                    Agree strongly\n",
      "3                    Agree a little\n",
      "4                    Agree a little\n",
      "                    ...            \n",
      "77197                Agree strongly\n",
      "77198    Neither agree nor disagree\n",
      "77199                Agree strongly\n",
      "77200    Neither agree nor disagree\n",
      "77201                Agree strongly\n",
      "Name: ac711_, Length: 77202, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Disagree a little', 'Agree a little', 'Refusal', 'Neither agree nor disagree', 'Agree strongly', 'Disagree strongly', \"Don't know\"]\n",
      "no replace_dict been found for wave 7\n",
      "do you wish to generate/re-define a replace_dict for wave 7? 1->yes others->no1\n",
      "replace response [Disagree a little] with int .. (999 -> none)4\n",
      "replace response [Agree a little] with int .. (999 -> none)2\n",
      "replace response [Refusal] with int .. (999 -> none)999\n",
      "replace response [Neither agree nor disagree] with int .. (999 -> none)3\n",
      "replace response [Agree strongly] with int .. (999 -> none)1\n",
      "replace response [Disagree strongly] with int .. (999 -> none)5\n",
      "replace response [Don't know] with int .. (999 -> none)999\n",
      "do you wish to replace data in 7? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    74800\n",
      "2     2253\n",
      "1      149\n",
      "Name: missing_count, dtype: int64\n",
      "please specify the missing count (999 is none)2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 8-------\n",
      "0                               NaN\n",
      "1                               NaN\n",
      "2                               NaN\n",
      "3                               NaN\n",
      "4                               NaN\n",
      "                    ...            \n",
      "46728                Agree a little\n",
      "46729                Agree a little\n",
      "46730    Neither agree nor disagree\n",
      "46731                Agree a little\n",
      "46732                Agree strongly\n",
      "Name: ac706_, Length: 46733, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "0                               NaN\n",
      "1                               NaN\n",
      "2                               NaN\n",
      "3                               NaN\n",
      "4                               NaN\n",
      "                    ...            \n",
      "46728    Neither agree nor disagree\n",
      "46729                Agree a little\n",
      "46730                Agree strongly\n",
      "46731                Agree a little\n",
      "46732                Agree strongly\n",
      "Name: ac711_, Length: 46733, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Disagree a little', 'Agree a little', 'Refusal', 'Neither agree nor disagree', 'Agree strongly', 'Disagree strongly', \"Don't know\"]\n",
      "no replace_dict been found for wave 8\n",
      "{'sharew7_rel8-0-0_ac.dta': {'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, \"Don't know\": None, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no1\n",
      "type key of itsharew7_rel8-0-0_ac.dta\n",
      "do you wish to generate/re-define a replace_dict for wave 8? 1->yes others->no0\n",
      "do you wish to replace data in 8? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "2    36814\n",
      "0     9898\n",
      "1       21\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew7_rel8-0-0_ac.dta->{'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, \"Don't know\": None, 'nan': None}\n",
      "sharew8_rel8-0-0_ac.dta->{'Disagree a little': 4, 'Agree a little': 2, 'Refusal': None, 'Neither agree nor disagree': 3, 'Agree strongly': 1, 'Disagree strongly': 5, \"Don't know\": None, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuroticism  `Zneuroticism`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>7</td>\n",
       "      <td>sharew7_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac709_', 'ac704_']</td>\n",
       "      <td>{'ac709_': 'gets nervous easily', 'ac704_': 'relaxed, handles stress well (reverse code)'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac709_', 'ac704_']</td>\n",
       "      <td>{'ac709_': 'gets nervous easily', 'ac704_': 'relaxed, handles stress well (reverse code)'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        varname  wave                file_name               var_set  \\\n",
       "36  Neuroticism     7  sharew7_rel8-0-0_ac.dta  ['ac709_', 'ac704_']   \n",
       "37  Neuroticism     8  sharew8_rel8-0-0_ac.dta  ['ac709_', 'ac704_']   \n",
       "\n",
       "                                                                                         Notes  \\\n",
       "36  {'ac709_': 'gets nervous easily', 'ac704_': 'relaxed, handles stress well (reverse code)'}   \n",
       "37  {'ac709_': 'gets nervous easily', 'ac704_': 'relaxed, handles stress well (reverse code)'}   \n",
       "\n",
       "    recoded  \n",
       "36    False  \n",
       "37    False  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Neuroticism'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zneuroticism'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Zneuroticism',\n",
    " 'var_set': [{7: {'sharew7_rel8-0-0_ac.dta': ['ac709_', 'ac704_']},\n",
    "   8: {'sharew8_rel8-0-0_ac.dta': ['ac709_', 'ac704_']}}],\n",
    " 'available_waves': [7, 8],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Neuroticism',\n",
    " 'domain': 'Adulthood Adverse Experiences',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 7-------\n",
      "0                 Disagree a little\n",
      "1                    Agree a little\n",
      "2                 Disagree strongly\n",
      "3                    Agree a little\n",
      "4                 Disagree a little\n",
      "                    ...            \n",
      "77197             Disagree strongly\n",
      "77198             Disagree strongly\n",
      "77199             Disagree strongly\n",
      "77200    Neither agree nor disagree\n",
      "77201             Disagree a little\n",
      "Name: ac709_, Length: 77202, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "0        Neither agree nor disagree\n",
      "1                 Disagree strongly\n",
      "2                    Agree strongly\n",
      "3                    Agree a little\n",
      "4                    Agree a little\n",
      "                    ...            \n",
      "77197                Agree a little\n",
      "77198    Neither agree nor disagree\n",
      "77199                Agree strongly\n",
      "77200    Neither agree nor disagree\n",
      "77201                Agree strongly\n",
      "Name: ac704_, Length: 77202, dtype: category\n",
      "Categories (7, object): ['Refusal' < 'Don't know' < 'Disagree strongly' < 'Disagree a little' < 'Neither agree nor disagree' < 'Agree a little' < 'Agree strongly']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Disagree a little', 'Agree a little', 'Refusal', 'Disagree strongly', 'Neither agree nor disagree', 'Agree strongly', \"Don't know\"]\n",
      "no replace_dict been found for wave 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m sliced_data\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sliced_data[column])\n\u001b[0;32m---> 12\u001b[0m df_recode_record,df_raw_recoded\u001b[38;5;241m=\u001b[39m\u001b[43mraw_multi_response_procedure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msliced_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlatest_wave\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf_recode_record\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf_raw_recoded\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 3\u001b[0m, in \u001b[0;36mraw_multi_response_procedure\u001b[0;34m(sliced_data, file_name, latest_wave, row, df_recode_record, df_raw_recoded)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraw_multi_response_procedure\u001b[39m(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#1. replace\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     row,sliced_data \u001b[38;5;241m=\u001b[39m \u001b[43mreplace_procedure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msliced_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlatest_wave\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#2. deal with maximum missing response\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(var_set)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "Cell \u001b[0;32mIn[54], line 43\u001b[0m, in \u001b[0;36mreplace_procedure\u001b[0;34m(sliced_data, file_name, latest_wave, row)\u001b[0m\n\u001b[1;32m     40\u001b[0m         row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace_dict\u001b[39m\u001b[38;5;124m'\u001b[39m][file_name] \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace_dict\u001b[39m\u001b[38;5;124m'\u001b[39m][key]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#new dict?\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m replace_control\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo you wish to generate/re-define a replace_dict for wave \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlatest_wave\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m? 1->yes others->no\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m replace_control\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     45\u001b[0m     row \u001b[38;5;241m=\u001b[39mraw_replace(row,file_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/OX_thesis/lib/python3.8/site-packages/ipykernel/kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1174\u001b[0m     )\n\u001b[0;32m-> 1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/OX_thesis/lib/python3.8/site-packages/ipykernel/kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sliced_data.columns:\n",
    "    print(sliced_data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_multi_response_procedure(sliced_data,file_name,latest_wave,row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Openness  `Zopenness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Openness</td>\n",
       "      <td>8</td>\n",
       "      <td>sharew8_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac710_', 'ac705_']</td>\n",
       "      <td>{'ac710_': 'active imagination', 'ac705_': 'few artistic interests (reverse code)'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Openness</td>\n",
       "      <td>7</td>\n",
       "      <td>sharew7_rel8-0-0_ac.dta</td>\n",
       "      <td>['ac710_', 'ac705_']</td>\n",
       "      <td>{'ac710_': 'active imagination', 'ac705_': 'few artistic interests (reverse code)'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     varname  wave                file_name               var_set  \\\n",
       "38  Openness     8  sharew8_rel8-0-0_ac.dta  ['ac710_', 'ac705_']   \n",
       "39  Openness     7  sharew7_rel8-0-0_ac.dta  ['ac710_', 'ac705_']   \n",
       "\n",
       "                                                                                  Notes  \\\n",
       "38  {'ac710_': 'active imagination', 'ac705_': 'few artistic interests (reverse code)'}   \n",
       "39  {'ac710_': 'active imagination', 'ac705_': 'few artistic interests (reverse code)'}   \n",
       "\n",
       "    recoded  \n",
       "38    False  \n",
       "39    False  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Openness'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = 'Zopenness'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sliced_data.columns:\n",
    "    print(sliced_data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_multi_response_procedure(sliced_data,file_name,latest_wave,row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conscientiousness  `Zneuroticism`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname_in_raw_recoder= ''\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = ''\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sliced_data.columns:\n",
    "    print(sliced_data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_multi_response_procedure(sliced_data,file_name,latest_wave,row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pessimism  `Zpessimism`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Pessimism</td>\n",
       "      <td>1</td>\n",
       "      <td>sharew1_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q3_d', 'q3_f']</td>\n",
       "      <td>{'q3_d': 'I hardly ever expect things to go my way', 'q3_f': 'I rarely count on good things happening to me'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Pessimism</td>\n",
       "      <td>2</td>\n",
       "      <td>sharew2_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q3_d', 'q3_f']</td>\n",
       "      <td>{'q3_d': 'I hardly ever expect things to go my way', 'q3_f': 'I rarely count on good things happening to me'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      varname  wave                     file_name           var_set  \\\n",
       "42  Pessimism     1  sharew1_rel8-0-0_dropoff.dta  ['q3_d', 'q3_f']   \n",
       "43  Pessimism     2  sharew2_rel8-0-0_dropoff.dta  ['q3_d', 'q3_f']   \n",
       "\n",
       "                                                                                                            Notes  \\\n",
       "42  {'q3_d': 'I hardly ever expect things to go my way', 'q3_f': 'I rarely count on good things happening to me'}   \n",
       "43  {'q3_d': 'I hardly ever expect things to go my way', 'q3_f': 'I rarely count on good things happening to me'}   \n",
       "\n",
       "    recoded  \n",
       "42    False  \n",
       "43    False  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Pessimism'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zpessimism'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Zpessimism',\n",
    " 'var_set': [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q3_d', 'q3_f']},\n",
    "   2: {'sharew2_rel8-0-0_dropoff.dta': ['q3_d', 'q3_f']}}],\n",
    " 'available_waves': [1, 2],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Pessimism',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 1-------\n",
      "0        Neither agree nor disagree\n",
      "1                             Agree\n",
      "2                             Agree\n",
      "3                          Disagree\n",
      "4                             Agree\n",
      "                    ...            \n",
      "20187                Strongly agree\n",
      "20188                         Agree\n",
      "20189                         Agree\n",
      "20190    Neither agree nor disagree\n",
      "20191                         Agree\n",
      "Name: q3_d, Length: 20192, dtype: category\n",
      "Categories (6, object): ['Not answered' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0        Neither agree nor disagree\n",
      "1        Neither agree nor disagree\n",
      "2        Neither agree nor disagree\n",
      "3                          Disagree\n",
      "4                    Strongly agree\n",
      "                    ...            \n",
      "20187                Strongly agree\n",
      "20188    Neither agree nor disagree\n",
      "20189    Neither agree nor disagree\n",
      "20190                      Disagree\n",
      "20191                         Agree\n",
      "Name: q3_f, Length: 20192, dtype: category\n",
      "Categories (6, object): ['Not answered' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Strongly agree', 'Strongly disagree', 'Neither agree nor disagree', 'Disagree', 'Not answered', 'Agree']\n",
      "no replace_dict been found for wave 1\n",
      "do you wish to generate/re-define a replace_dict for wave 1? 1->yes others->no1\n",
      "replace response [Strongly agree] with int .. (999 -> none)5\n",
      "replace response [Strongly disagree] with int .. (999 -> none)1\n",
      "replace response [Neither agree nor disagree] with int .. (999 -> none)3\n",
      "replace response [Disagree] with int .. (999 -> none)2\n",
      "replace response [Not answered] with int .. (999 -> none)999\n",
      "replace response [Agree] with int .. (999 -> none)4\n",
      "do you wish to replace data in 1? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    19458\n",
      "2      460\n",
      "1      274\n",
      "Name: missing_count, dtype: int64\n",
      "please specify the missing count (999 is none)2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 2-------\n",
      "0                            Agree\n",
      "1                            Agree\n",
      "2                         Disagree\n",
      "3       Neither agree nor disagree\n",
      "4                            Agree\n",
      "                   ...            \n",
      "8861    Neither agree nor disagree\n",
      "8862                      Disagree\n",
      "8863                      Disagree\n",
      "8864                         Agree\n",
      "8865                      Disagree\n",
      "Name: q3_d, Length: 8866, dtype: category\n",
      "Categories (7, object): ['Not answered' < 'Don't know' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0       Neither agree nor disagree\n",
      "1                            Agree\n",
      "2       Neither agree nor disagree\n",
      "3                            Agree\n",
      "4       Neither agree nor disagree\n",
      "                   ...            \n",
      "8861                         Agree\n",
      "8862    Neither agree nor disagree\n",
      "8863                         Agree\n",
      "8864                         Agree\n",
      "8865    Neither agree nor disagree\n",
      "Name: q3_f, Length: 8866, dtype: category\n",
      "Categories (7, object): ['Not answered' < 'Don't know' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Strongly agree', 'Strongly disagree', 'Neither agree nor disagree', 'Disagree', \"Don't know\", 'Not answered', 'Agree']\n",
      "no replace_dict been found for wave 2\n",
      "{'sharew1_rel8-0-0_dropoff.dta': {'Strongly agree': 5, 'Strongly disagree': 1, 'Neither agree nor disagree': 3, 'Disagree': 2, 'Not answered': None, 'Agree': 4, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no0\n",
      "do you wish to generate/re-define a replace_dict for wave 2? 1->yes others->no1\n",
      "replace response [Strongly agree] with int .. (999 -> none)5\n",
      "replace response [Strongly disagree] with int .. (999 -> none)1\n",
      "replace response [Neither agree nor disagree] with int .. (999 -> none)3\n",
      "replace response [Disagree] with int .. (999 -> none)2\n",
      "replace response [Don't know] with int .. (999 -> none)999\n",
      "replace response [Not answered] with int .. (999 -> none)999\n",
      "replace response [Agree] with int .. (999 -> none)4\n",
      "do you wish to replace data in 2? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    8625\n",
      "2     122\n",
      "1     119\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_dropoff.dta->{'Strongly agree': 5, 'Strongly disagree': 1, 'Neither agree nor disagree': 3, 'Disagree': 2, 'Not answered': None, 'Agree': 4, 'nan': None}\n",
      "sharew2_rel8-0-0_dropoff.dta->{'Strongly agree': 5, 'Strongly disagree': 1, 'Neither agree nor disagree': 3, 'Disagree': 2, \"Don't know\": None, 'Not answered': None, 'Agree': 4, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimism  `Zoptimism`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Optimism</td>\n",
       "      <td>1</td>\n",
       "      <td>sharew1_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q3_a', 'q3_b', 'q3_c', 'q3_e', 'q3_g']</td>\n",
       "      <td>{'q3_a': 'I pursue my goals with lots of energy', 'q3_b': 'In uncertain times, I usually expect the best', 'q3_c': \"I'm always optimistic about my future \", 'q3_e': 'I still find ways to solve a problem if others have given up', 'q3_g': 'Given my previous experiences I feel well prepared for my future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Optimism</td>\n",
       "      <td>2</td>\n",
       "      <td>sharew2_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q3_a', 'q3_b', 'q3_c', 'q3_e', 'q3_g']</td>\n",
       "      <td>{'q3_a': 'I pursue my goals with lots of energy', 'q3_b': 'In uncertain times, I usually expect the best', 'q3_c': \"I'm always optimistic about my future \", 'q3_e': 'I still find ways to solve a problem if others have given up', 'q3_g': 'Given my previous experiences I feel well prepared for my future'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     varname  wave                     file_name  \\\n",
       "44  Optimism     1  sharew1_rel8-0-0_dropoff.dta   \n",
       "45  Optimism     2  sharew2_rel8-0-0_dropoff.dta   \n",
       "\n",
       "                                     var_set  \\\n",
       "44  ['q3_a', 'q3_b', 'q3_c', 'q3_e', 'q3_g']   \n",
       "45  ['q3_a', 'q3_b', 'q3_c', 'q3_e', 'q3_g']   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                               Notes  \\\n",
       "44  {'q3_a': 'I pursue my goals with lots of energy', 'q3_b': 'In uncertain times, I usually expect the best', 'q3_c': \"I'm always optimistic about my future \", 'q3_e': 'I still find ways to solve a problem if others have given up', 'q3_g': 'Given my previous experiences I feel well prepared for my future'}   \n",
       "45  {'q3_a': 'I pursue my goals with lots of energy', 'q3_b': 'In uncertain times, I usually expect the best', 'q3_c': \"I'm always optimistic about my future \", 'q3_e': 'I still find ways to solve a problem if others have given up', 'q3_g': 'Given my previous experiences I feel well prepared for my future'}   \n",
       "\n",
       "    recoded  \n",
       "44    False  \n",
       "45    False  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Optimism'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zoptimism'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Zoptimism',\n",
    " 'var_set': [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q3_a',\n",
    "     'q3_b',\n",
    "     'q3_c',\n",
    "     'q3_e',\n",
    "     'q3_g']},\n",
    "   2: {'sharew2_rel8-0-0_dropoff.dta': ['q3_a',\n",
    "     'q3_b',\n",
    "     'q3_c',\n",
    "     'q3_e',\n",
    "     'q3_g']}}],\n",
    " 'available_waves': [1, 2],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Optimism',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 1-------\n",
      "0        Neither agree nor disagree\n",
      "1        Neither agree nor disagree\n",
      "2                    Strongly agree\n",
      "3                    Strongly agree\n",
      "4        Neither agree nor disagree\n",
      "                    ...            \n",
      "20187                Strongly agree\n",
      "20188                         Agree\n",
      "20189                         Agree\n",
      "20190                Strongly agree\n",
      "20191                Strongly agree\n",
      "Name: q3_a, Length: 20192, dtype: category\n",
      "Categories (6, object): ['Not answered' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0        Neither agree nor disagree\n",
      "1                             Agree\n",
      "2                      Not answered\n",
      "3                             Agree\n",
      "4                             Agree\n",
      "                    ...            \n",
      "20187                      Disagree\n",
      "20188                Strongly agree\n",
      "20189                         Agree\n",
      "20190                         Agree\n",
      "20191    Neither agree nor disagree\n",
      "Name: q3_b, Length: 20192, dtype: category\n",
      "Categories (6, object): ['Not answered' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0                             Agree\n",
      "1                             Agree\n",
      "2                             Agree\n",
      "3                    Strongly agree\n",
      "4                             Agree\n",
      "                    ...            \n",
      "20187    Neither agree nor disagree\n",
      "20188                Strongly agree\n",
      "20189                         Agree\n",
      "20190                Strongly agree\n",
      "20191                         Agree\n",
      "Name: q3_c, Length: 20192, dtype: category\n",
      "Categories (6, object): ['Not answered' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0        Neither agree nor disagree\n",
      "1                             Agree\n",
      "2                             Agree\n",
      "3                    Strongly agree\n",
      "4                             Agree\n",
      "                    ...            \n",
      "20187                         Agree\n",
      "20188    Neither agree nor disagree\n",
      "20189                         Agree\n",
      "20190                         Agree\n",
      "20191                Strongly agree\n",
      "Name: q3_e, Length: 20192, dtype: category\n",
      "Categories (6, object): ['Not answered' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0                 Agree\n",
      "1                 Agree\n",
      "2        Strongly agree\n",
      "3                 Agree\n",
      "4        Strongly agree\n",
      "              ...      \n",
      "20187    Strongly agree\n",
      "20188    Strongly agree\n",
      "20189             Agree\n",
      "20190    Strongly agree\n",
      "20191    Strongly agree\n",
      "Name: q3_g, Length: 20192, dtype: category\n",
      "Categories (6, object): ['Not answered' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Strongly agree', 'Strongly disagree', 'Neither agree nor disagree', 'Disagree', 'Not answered', 'Agree']\n",
      "no replace_dict been found for wave 1\n",
      "do you wish to generate/re-define a replace_dict for wave 1? 1->yes others->no1\n",
      "replace response [Strongly agree] with int .. (999 -> none)1\n",
      "replace response [Strongly disagree] with int .. (999 -> none)5\n",
      "replace response [Neither agree nor disagree] with int .. (999 -> none)3\n",
      "replace response [Disagree] with int .. (999 -> none)4\n",
      "replace response [Not answered] with int .. (999 -> none)999\n",
      "replace response [Agree] with int .. (999 -> none)2\n",
      "do you wish to replace data in 1? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    19267\n",
      "1      376\n",
      "5      356\n",
      "4       72\n",
      "2       71\n",
      "3       50\n",
      "Name: missing_count, dtype: int64\n",
      "please specify the missing count (999 is none)4\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 2-------\n",
      "0                   Strongly agree\n",
      "1                            Agree\n",
      "2                            Agree\n",
      "3                   Strongly agree\n",
      "4                            Agree\n",
      "                   ...            \n",
      "8861    Neither agree nor disagree\n",
      "8862                         Agree\n",
      "8863                         Agree\n",
      "8864                Strongly agree\n",
      "8865    Neither agree nor disagree\n",
      "Name: q3_a, Length: 8866, dtype: category\n",
      "Categories (7, object): ['Not answered' < 'Don't know' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0       Neither agree nor disagree\n",
      "1                            Agree\n",
      "2                            Agree\n",
      "3                   Strongly agree\n",
      "4                            Agree\n",
      "                   ...            \n",
      "8861                         Agree\n",
      "8862    Neither agree nor disagree\n",
      "8863    Neither agree nor disagree\n",
      "8864                         Agree\n",
      "8865                         Agree\n",
      "Name: q3_b, Length: 8866, dtype: category\n",
      "Categories (7, object): ['Not answered' < 'Don't know' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0                            Agree\n",
      "1                            Agree\n",
      "2                            Agree\n",
      "3                   Strongly agree\n",
      "4                            Agree\n",
      "                   ...            \n",
      "8861                         Agree\n",
      "8862    Neither agree nor disagree\n",
      "8863                         Agree\n",
      "8864                         Agree\n",
      "8865                         Agree\n",
      "Name: q3_c, Length: 8866, dtype: category\n",
      "Categories (7, object): ['Not answered' < 'Don't know' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0                            Agree\n",
      "1       Neither agree nor disagree\n",
      "2                            Agree\n",
      "3                            Agree\n",
      "4                            Agree\n",
      "                   ...            \n",
      "8861                         Agree\n",
      "8862                         Agree\n",
      "8863                         Agree\n",
      "8864                         Agree\n",
      "8865                         Agree\n",
      "Name: q3_e, Length: 8866, dtype: category\n",
      "Categories (7, object): ['Not answered' < 'Don't know' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "0       Neither agree nor disagree\n",
      "1                            Agree\n",
      "2                            Agree\n",
      "3                   Strongly agree\n",
      "4                            Agree\n",
      "                   ...            \n",
      "8861                         Agree\n",
      "8862                         Agree\n",
      "8863                         Agree\n",
      "8864                         Agree\n",
      "8865                         Agree\n",
      "Name: q3_g, Length: 8866, dtype: category\n",
      "Categories (7, object): ['Not answered' < 'Don't know' < 'Strongly agree' < 'Agree' < 'Neither agree nor disagree' < 'Disagree' < 'Strongly disagree']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Strongly agree', 'Strongly disagree', 'Neither agree nor disagree', 'Disagree', \"Don't know\", 'Not answered', 'Agree']\n",
      "no replace_dict been found for wave 2\n",
      "{'sharew1_rel8-0-0_dropoff.dta': {'Strongly agree': 1, 'Strongly disagree': 5, 'Neither agree nor disagree': 3, 'Disagree': 4, 'Not answered': None, 'Agree': 2, 'nan': None}}\n",
      "here are the available dicts, do you wish to use? 1->yes 0->no0\n",
      "do you wish to generate/re-define a replace_dict for wave 2? 1->yes others->no1\n",
      "replace response [Strongly agree] with int .. (999 -> none)1\n",
      "replace response [Strongly disagree] with int .. (999 -> none)5\n",
      "replace response [Neither agree nor disagree] with int .. (999 -> none)3\n",
      "replace response [Disagree] with int .. (999 -> none)4\n",
      "replace response [Don't know] with int .. (999 -> none)999\n",
      "replace response [Not answered] with int .. (999 -> none)999\n",
      "replace response [Agree] with int .. (999 -> none)2\n",
      "do you wish to replace data in 2? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    8514\n",
      "1     187\n",
      "5      86\n",
      "2      34\n",
      "4      27\n",
      "3      18\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 4\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change9\n",
      "we have found the dict as follows\n",
      "sharew1_rel8-0-0_dropoff.dta->{'Strongly agree': 1, 'Strongly disagree': 5, 'Neither agree nor disagree': 3, 'Disagree': 4, 'Not answered': None, 'Agree': 2, 'nan': None}\n",
      "sharew2_rel8-0-0_dropoff.dta->{'Strongly agree': 1, 'Strongly disagree': 5, 'Neither agree nor disagree': 3, 'Disagree': 4, \"Don't know\": None, 'Not answered': None, 'Agree': 2, 'nan': None}\n",
      "do you want to update it? 1->yes 0->no1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Affect `Znegaffect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Negative Affect</td>\n",
       "      <td>1</td>\n",
       "      <td>sharew1_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q4_a', 'q4_b', 'q4_c', 'q4_e', 'q4_f', 'q4_h', 'q4_i', 'q4_j', 'q4_k', 'q4_m']</td>\n",
       "      <td>{'q4_a': 'I felt depressed', 'q4_b': 'I felt that everything I did was an effort', 'q4_c': 'My sleep was restless', 'q4_e': 'I felt lonely', 'q4_f': 'I felt people were unfriendly', 'q4_h': 'I felt sad', 'q4_i': 'I felt that people disliked me', 'q4_j': 'I could not get going', 'q4_k': 'I did not feel like eating/my appetite was poor', 'q4_m': 'I felt tired'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            varname  wave                     file_name  \\\n",
       "46  Negative Affect     1  sharew1_rel8-0-0_dropoff.dta   \n",
       "\n",
       "                                                                             var_set  \\\n",
       "46  ['q4_a', 'q4_b', 'q4_c', 'q4_e', 'q4_f', 'q4_h', 'q4_i', 'q4_j', 'q4_k', 'q4_m']   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                        Notes  \\\n",
       "46  {'q4_a': 'I felt depressed', 'q4_b': 'I felt that everything I did was an effort', 'q4_c': 'My sleep was restless', 'q4_e': 'I felt lonely', 'q4_f': 'I felt people were unfriendly', 'q4_h': 'I felt sad', 'q4_i': 'I felt that people disliked me', 'q4_j': 'I could not get going', 'q4_k': 'I did not feel like eating/my appetite was poor', 'q4_m': 'I felt tired'}   \n",
       "\n",
       "    recoded  \n",
       "46    False  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Negative Affect'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Znegaffect'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Znegaffect',\n",
    " 'var_set': [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q4_a',\n",
    "     'q4_b',\n",
    "     'q4_c',\n",
    "     'q4_e',\n",
    "     'q4_f',\n",
    "     'q4_h',\n",
    "     'q4_i',\n",
    "     'q4_j',\n",
    "     'q4_k',\n",
    "     'q4_m']}}],\n",
    " 'available_waves': [1],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Negative Affect',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 1-------\n",
      "0        Almost none of the time\n",
      "1        Almost none of the time\n",
      "2        Almost none of the time\n",
      "3        Almost none of the time\n",
      "4               Some of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190    Almost none of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_a, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1               Some of the time\n",
      "2        Almost none of the time\n",
      "3        Almost none of the time\n",
      "4               Most of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190           Some of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_b, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1        Almost none of the time\n",
      "2               Some of the time\n",
      "3        Almost none of the time\n",
      "4               Most of the time\n",
      "                  ...           \n",
      "20187           Some of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190    Almost none of the time\n",
      "20191           Some of the time\n",
      "Name: q4_c, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1               Some of the time\n",
      "2        Almost none of the time\n",
      "3        Almost none of the time\n",
      "4               Some of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190    Almost none of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_e, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1        Almost none of the time\n",
      "2        Almost none of the time\n",
      "3        Almost none of the time\n",
      "4               Some of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190           Some of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_f, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1        Almost none of the time\n",
      "2               Some of the time\n",
      "3        Almost none of the time\n",
      "4               Some of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190           Some of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_h, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1        Almost none of the time\n",
      "2        Almost none of the time\n",
      "3        Almost none of the time\n",
      "4               Some of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190           Some of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_i, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1        Almost none of the time\n",
      "2               Some of the time\n",
      "3        Almost none of the time\n",
      "4               Most of the time\n",
      "                  ...           \n",
      "20187           Some of the time\n",
      "20188    Almost none of the time\n",
      "20189               Not answered\n",
      "20190    Almost none of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_j, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost none of the time\n",
      "1        Almost none of the time\n",
      "2        Almost none of the time\n",
      "3        Almost none of the time\n",
      "4               Some of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190    Almost none of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_k, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0               Some of the time\n",
      "1               Some of the time\n",
      "2               Some of the time\n",
      "3               Some of the time\n",
      "4               Some of the time\n",
      "                  ...           \n",
      "20187    Almost none of the time\n",
      "20188    Almost none of the time\n",
      "20189    Almost none of the time\n",
      "20190           Some of the time\n",
      "20191    Almost none of the time\n",
      "Name: q4_m, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Almost none of the time', 'Almost all of the time', 'Most of the time', 'Not answered', 'Some of the time']\n",
      "no replace_dict been found for wave 1\n",
      "do you wish to generate/re-define a replace_dict for wave 1? 1->yes others->no1\n",
      "replace response [Almost none of the time] with int .. (999 -> none)1\n",
      "replace response [Almost all of the time] with int .. (999 -> none)4\n",
      "replace response [Most of the time] with int .. (999 -> none)3\n",
      "replace response [Not answered] with int .. (999 -> none)999\n",
      "replace response [Some of the time] with int .. (999 -> none)2\n",
      "do you wish to replace data in 1? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0     18691\n",
      "1       841\n",
      "10      264\n",
      "2       167\n",
      "9        46\n",
      "3        45\n",
      "8        34\n",
      "4        31\n",
      "5        31\n",
      "6        24\n",
      "7        18\n",
      "Name: missing_count, dtype: int64\n",
      "please specify the missing count (999 is none)9\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive Affect `Zposaffect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "      <th>recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Positive Affect</td>\n",
       "      <td>1</td>\n",
       "      <td>sharew1_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['q4_l', 'q4_g', 'q4_d']</td>\n",
       "      <td>{'q4_l': 'I had a lot of energy', 'q4_g': 'I enjoyed life', 'q4_d': 'I was happy'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            varname  wave                     file_name  \\\n",
       "47  Positive Affect     1  sharew1_rel8-0-0_dropoff.dta   \n",
       "\n",
       "                     var_set  \\\n",
       "47  ['q4_l', 'q4_g', 'q4_d']   \n",
       "\n",
       "                                                                                 Notes  \\\n",
       "47  {'q4_l': 'I had a lot of energy', 'q4_g': 'I enjoyed life', 'q4_d': 'I was happy'}   \n",
       "\n",
       "    recoded  \n",
       "47    False  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Positive Affect'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'Zposaffect'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'Zposaffect',\n",
    " 'var_set': [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q4_l', 'q4_g', 'q4_d']}}],\n",
    " 'available_waves': [1],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Positive Affect',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 1-------\n",
      "0              Most of the time\n",
      "1              Most of the time\n",
      "2        Almost all of the time\n",
      "3        Almost all of the time\n",
      "4              Some of the time\n",
      "                  ...          \n",
      "20187          Most of the time\n",
      "20188          Most of the time\n",
      "20189          Most of the time\n",
      "20190    Almost all of the time\n",
      "20191          Most of the time\n",
      "Name: q4_l, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0        Almost all of the time\n",
      "1              Some of the time\n",
      "2        Almost all of the time\n",
      "3        Almost all of the time\n",
      "4        Almost all of the time\n",
      "                  ...          \n",
      "20187    Almost all of the time\n",
      "20188          Some of the time\n",
      "20189          Most of the time\n",
      "20190    Almost all of the time\n",
      "20191    Almost all of the time\n",
      "Name: q4_g, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "0              Most of the time\n",
      "1              Most of the time\n",
      "2              Most of the time\n",
      "3        Almost all of the time\n",
      "4              Most of the time\n",
      "                  ...          \n",
      "20187          Some of the time\n",
      "20188          Most of the time\n",
      "20189          Most of the time\n",
      "20190          Most of the time\n",
      "20191          Some of the time\n",
      "Name: q4_d, Length: 20192, dtype: category\n",
      "Categories (5, object): ['Not answered' < 'Almost all of the time' < 'Most of the time' < 'Some of the time' < 'Almost none of the time']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['Almost none of the time', 'Almost all of the time', 'Most of the time', 'Not answered', 'Some of the time']\n",
      "no replace_dict been found for wave 1\n",
      "do you wish to generate/re-define a replace_dict for wave 1? 1->yes others->no1\n",
      "replace response [Almost none of the time] with int .. (999 -> none)4\n",
      "replace response [Almost all of the time] with int .. (999 -> none)1\n",
      "replace response [Most of the time] with int .. (999 -> none)2\n",
      "replace response [Not answered] with int .. (999 -> none)999\n",
      "replace response [Some of the time] with int .. (999 -> none)3\n",
      "do you wish to replace data in 1? 1->yes others->no1\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "0    19330\n",
      "1      425\n",
      "3      324\n",
      "2      113\n",
      "Name: missing_count, dtype: int64\n",
      "please specify the missing count (999 is none)2\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_42983/118354046.py:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_recode_record=df_recode_record.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for latest_wave in row['available_waves']:\n",
    "    print(f'--------wave {latest_wave}-------')\n",
    "    #0. retreive data\n",
    "    varname = row['varname']\n",
    "    var_set, file_name = get_raw_info(row,latest_wave)\n",
    "    df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "    sliced_data = df_temp[var_set]\n",
    "    df_temp = df_temp[['mergeid']]\n",
    "\n",
    "    for column in sliced_data.columns:\n",
    "        print(sliced_data[column])\n",
    "    df_recode_record,df_raw_recoded=raw_multi_response_procedure(sliced_data,file_name,latest_wave,row,df_recode_record,df_raw_recoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sliced_data.columns:\n",
    "    print(sliced_data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_multi_response_procedure(sliced_data,file_name,latest_wave,row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult Psychosocial Adversity `sumadultAE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>wave</th>\n",
       "      <th>file_name</th>\n",
       "      <th>var_set</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Adult Psychosocial Adversity</td>\n",
       "      <td>1</td>\n",
       "      <td>sharew1_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['ilq6', 'ilq15', 'ilq18', 'ilq21', 'ilq24', 'ilq37', 'ilq87', 'ilq96', 'ilq111']</td>\n",
       "      <td>{'ilq6': 'Experienced the death of a (grand)child', 'ilq15': 'Experienced sexual assault (rape or harassment)', 'ilq18': 'Been victim of violence/abuse', 'ilq21': 'Been victim of crime (theft or fraud)', 'ilq24': 'Witnessed accident/violent act in which someone was killed/seriously injured', 'ilq37': 'During wwII, ever resided in country under nazi/pro-nazi regime', 'ilq87': 'Been wounded in war/military action', 'ilq96': 'Been wounded in a terrorist act (an attack by terrorists against civilians)', 'ilq111': 'Experienced the death of a spouse'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Adult Psychosocial Adversity</td>\n",
       "      <td>2</td>\n",
       "      <td>sharew2_rel8-0-0_dropoff.dta</td>\n",
       "      <td>['ilq6', 'ilq15', 'ilq18', 'ilq21', 'ilq24', 'ilq37', 'ilq87', 'ilq96', 'ilq111']</td>\n",
       "      <td>{'ilq6': 'Experienced the death of a (grand)child', 'ilq15': 'Experienced sexual assault (rape or harassment)', 'ilq18': 'Been victim of violence/abuse', 'ilq21': 'Been victim of crime (theft or fraud)', 'ilq24': 'Witnessed accident/violent act in which someone was killed/seriously injured', 'ilq37': 'During wwII, ever resided in country under nazi/pro-nazi regime', 'ilq87': 'Been wounded in war/military action', 'ilq96': 'Been wounded in a terrorist act (an attack by terrorists against civilians)', 'ilq111': 'Experienced the death of a spouse'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         varname  wave                     file_name  \\\n",
       "18  Adult Psychosocial Adversity     1  sharew1_rel8-0-0_dropoff.dta   \n",
       "19  Adult Psychosocial Adversity     2  sharew2_rel8-0-0_dropoff.dta   \n",
       "\n",
       "                                                                              var_set  \\\n",
       "18  ['ilq6', 'ilq15', 'ilq18', 'ilq21', 'ilq24', 'ilq37', 'ilq87', 'ilq96', 'ilq111']   \n",
       "19  ['ilq6', 'ilq15', 'ilq18', 'ilq21', 'ilq24', 'ilq37', 'ilq87', 'ilq96', 'ilq111']   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Notes  \n",
       "18  {'ilq6': 'Experienced the death of a (grand)child', 'ilq15': 'Experienced sexual assault (rape or harassment)', 'ilq18': 'Been victim of violence/abuse', 'ilq21': 'Been victim of crime (theft or fraud)', 'ilq24': 'Witnessed accident/violent act in which someone was killed/seriously injured', 'ilq37': 'During wwII, ever resided in country under nazi/pro-nazi regime', 'ilq87': 'Been wounded in war/military action', 'ilq96': 'Been wounded in a terrorist act (an attack by terrorists against civilians)', 'ilq111': 'Experienced the death of a spouse'}  \n",
       "19  {'ilq6': 'Experienced the death of a (grand)child', 'ilq15': 'Experienced sexual assault (rape or harassment)', 'ilq18': 'Been victim of violence/abuse', 'ilq21': 'Been victim of crime (theft or fraud)', 'ilq24': 'Witnessed accident/violent act in which someone was killed/seriously injured', 'ilq37': 'During wwII, ever resided in country under nazi/pro-nazi regime', 'ilq87': 'Been wounded in war/military action', 'ilq96': 'Been wounded in a terrorist act (an attack by terrorists against civilians)', 'ilq111': 'Experienced the death of a spouse'}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varname_in_raw_recoder= 'Adult Psychosocial Adversity'\n",
    "record = df_vars_found_in_raw.loc[df_vars_found_in_raw['varname']==varname_in_raw_recoder,]\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varname = 'sumadultAE'\n",
    "var_set, available_waves = return_var_set_lst(record)\n",
    "\n",
    "replace_dict=  None\n",
    "notes = \"Raw Recode, Manual\" \n",
    "\n",
    "new_row=new_var_record_input(varname,[var_set],available_waves,replace_dict,notes)\n",
    "df_recode_record=add_row_to_df_record(new_row,df_recode_record)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "row={'varname': 'sumadultAE',\n",
    " 'var_set': [{1: {'sharew1_rel8-0-0_dropoff.dta': ['ilq6',\n",
    "     'ilq15',\n",
    "     'ilq18',\n",
    "     'ilq21',\n",
    "     'ilq24',\n",
    "     'ilq37',\n",
    "     'ilq87',\n",
    "     'ilq96',\n",
    "     'ilq111']},\n",
    "   2: {'sharew2_rel8-0-0_dropoff.dta': ['ilq6',\n",
    "     'ilq15',\n",
    "     'ilq18',\n",
    "     'ilq21',\n",
    "     'ilq24',\n",
    "     'ilq37',\n",
    "     'ilq87',\n",
    "     'ilq96',\n",
    "     'ilq111']}}],\n",
    " 'available_waves': [1, 2],\n",
    " 'replace_dict': None,\n",
    " 'notes': 'Raw Recode, Manual',\n",
    " 'conventional_name': 'Adult Psychosocial Adversity',\n",
    " 'domain': 'Adulthood Psychological',\n",
    " 'recode_type': 'row_manual',\n",
    " 'wave_controller': 'manual',\n",
    " 'reverse_code': False,\n",
    " 'maximum_missing_response': None,\n",
    " 'standardise': True,\n",
    " 'in_HRS': True,\n",
    " 'in_ELSA': False,\n",
    " 'recode_date': '2023-02-23'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------wave 2-------\n",
      "0       NaN\n",
      "1       NaN\n",
      "2       NaN\n",
      "3       NaN\n",
      "4       NaN\n",
      "       ... \n",
      "8861    NaN\n",
      "8862    NaN\n",
      "8863    NaN\n",
      "8864    NaN\n",
      "8865    NaN\n",
      "Name: ilq6, Length: 8866, dtype: category\n",
      "Categories (4, object): ['Not answered' < 'Refusal' < 'Yes' < 'No']\n",
      "0       NaN\n",
      "1       NaN\n",
      "2       NaN\n",
      "3       NaN\n",
      "4       NaN\n",
      "       ... \n",
      "8861    NaN\n",
      "8862    NaN\n",
      "8863    NaN\n",
      "8864    NaN\n",
      "8865    NaN\n",
      "Name: ilq15, Length: 8866, dtype: category\n",
      "Categories (4, object): ['Not answered' < 'Refusal' < 'Yes' < 'No']\n",
      "0       NaN\n",
      "1       NaN\n",
      "2       NaN\n",
      "3       NaN\n",
      "4       NaN\n",
      "       ... \n",
      "8861    NaN\n",
      "8862    NaN\n",
      "8863    NaN\n",
      "8864    NaN\n",
      "8865    NaN\n",
      "Name: ilq18, Length: 8866, dtype: category\n",
      "Categories (4, object): ['Not answered' < 'Refusal' < 'Yes' < 'No']\n",
      "0       NaN\n",
      "1       NaN\n",
      "2       NaN\n",
      "3       NaN\n",
      "4       NaN\n",
      "       ... \n",
      "8861    NaN\n",
      "8862    NaN\n",
      "8863    NaN\n",
      "8864    NaN\n",
      "8865    NaN\n",
      "Name: ilq21, Length: 8866, dtype: category\n",
      "Categories (4, object): ['Not answered' < 'Refusal' < 'Yes' < 'No']\n",
      "0       NaN\n",
      "1       NaN\n",
      "2       NaN\n",
      "3       NaN\n",
      "4       NaN\n",
      "       ... \n",
      "8861    NaN\n",
      "8862    NaN\n",
      "8863    NaN\n",
      "8864    NaN\n",
      "8865    NaN\n",
      "Name: ilq24, Length: 8866, dtype: category\n",
      "Categories (4, object): ['Not answered' < 'Refusal' < 'Yes' < 'No']\n",
      "0       NaN\n",
      "1       NaN\n",
      "2       NaN\n",
      "3       NaN\n",
      "4       NaN\n",
      "       ... \n",
      "8861    NaN\n",
      "8862    NaN\n",
      "8863    NaN\n",
      "8864    NaN\n",
      "8865    NaN\n",
      "Name: ilq37, Length: 8866, dtype: category\n",
      "Categories (4, object): ['Not applicable' < 'Not answered' < 'Yes' < 'No']\n",
      "0       NaN\n",
      "1       NaN\n",
      "2       NaN\n",
      "3       NaN\n",
      "4       NaN\n",
      "       ... \n",
      "8861    NaN\n",
      "8862    NaN\n",
      "8863    NaN\n",
      "8864    NaN\n",
      "8865    NaN\n",
      "Name: ilq87, Length: 8866, dtype: category\n",
      "Categories (4, object): ['Not answered' < 'Refusal' < 'Yes' < 'No']\n",
      "0       NaN\n",
      "1       NaN\n",
      "2       NaN\n",
      "3       NaN\n",
      "4       NaN\n",
      "       ... \n",
      "8861    NaN\n",
      "8862    NaN\n",
      "8863    NaN\n",
      "8864    NaN\n",
      "8865    NaN\n",
      "Name: ilq96, Length: 8866, dtype: category\n",
      "Categories (4, object): ['Not answered' < 'Refusal' < 'Yes' < 'No']\n",
      "0       NaN\n",
      "1       NaN\n",
      "2       NaN\n",
      "3       NaN\n",
      "4       NaN\n",
      "       ... \n",
      "8861    NaN\n",
      "8862    NaN\n",
      "8863    NaN\n",
      "8864    NaN\n",
      "8865    NaN\n",
      "Name: ilq111, Length: 8866, dtype: category\n",
      "Categories (4, object): ['Not answered' < 'Refusal' < 'Yes' < 'No']\n",
      "Replace Procedures start..\n",
      "\n",
      "all responses are: ['No', 'Refusal', 'Yes', 'Not answered', 'Not applicable']\n",
      "no replace_dict been found for wave 2\n",
      "do you wish to generate/re-define a replace_dict for wave 2? 1->yes others->no0\n",
      "do you wish to replace data in 2? 1->yes others->no0\n",
      "Replace Procedures end..\n",
      "\n",
      "0. missing information -------- start\n",
      "9    8300\n",
      "0     566\n",
      "Name: missing_count, dtype: int64\n",
      "the maximum missing response is 8\n",
      "the reverse code is False\n",
      "wish to redefine reverse_conde controller? 1->Change any.other->Not Change0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "latest_wave =2\n",
    "print(f'--------wave {latest_wave}-------')\n",
    "#0. retreive data\n",
    "varname = row['varname']\n",
    "var_set, file_name = get_raw_info(row,latest_wave)\n",
    "df_temp = pd.read_stata(share_path/f'raw/{folder_name(latest_wave)}/{file_name}')\n",
    "sliced_data = df_temp[var_set]\n",
    "df_temp = df_temp[['mergeid']]\n",
    "\n",
    "for column in sliced_data.columns:\n",
    "    print(sliced_data[column])\n",
    "\n",
    "#1. replace\n",
    "row,sliced_data = replace_procedure(sliced_data,file_name,latest_wave,row)\n",
    "\n",
    "#2. deal with maximum missing response\n",
    "if len(var_set)>1:\n",
    "    missing_count(sliced_data)\n",
    "\n",
    "    if row['maximum_missing_response']:\n",
    "        print(f'the maximum missing response is {row[\"maximum_missing_response\"]}')\n",
    "    else:\n",
    "        missing_count_controller = int(input('please specify the missing count (999 is none)'))\n",
    "        row['maximum_missing_response'] = missing_count_controller if not missing_count_controller==999 else None\n",
    "\n",
    "#3. deal with reverse_code\n",
    "print(f'the reverse code is {row[\"reverse_code\"]}')\n",
    "reverse_control = input('wish to redefine reverse_conde controller? 1->Change any.other->Not Change')\n",
    "row[\"reverse_code\"]= not row[\"reverse_code\"] if reverse_control=='1' else row[\"reverse_code\"]\n",
    "\n",
    "# reverse control\n",
    "if row[\"reverse_code\"]:\n",
    "    unique_vals = get_unique_valaues(sliced_data)\n",
    "    print(\"4. unique_vals are {}\".format(unique_vals))\n",
    "    replace_dict = generate_value_replace_dict(unique_vals)\n",
    "    print(\"5. dict is {}\".format(replace_dict))\n",
    "    sliced_data.replace(replace_dict,inplace=True)\n",
    "\n",
    "# categorical column pretreatment\n",
    "for column in sliced_data.columns:\n",
    "    if isinstance(sliced_data[column].dtype,pd.api.types.CategoricalDtype):\n",
    "        sliced_data[column]=np.asarray(sliced_data[column])\n",
    "\n",
    "        # multiple response\n",
    "if len(var_set)==1:\n",
    "    df_temp[f'{varname}_{latest_wave}']=sliced_data[var_set[0]]\n",
    "else:    \n",
    "    df_temp[f'{varname}_{latest_wave}']=sliced_data.apply(count_times,axis=1,response_to_count='Yes')\n",
    "\n",
    "# savezone\n",
    "df_raw_recoded=pd.merge(left=df_raw_recoded,right=df_temp,on='mergeid',how='outer')\n",
    "mark_df_vars_found_in_raw(varname_in_raw_recoder,latest_wave)\n",
    "df_recode_record=add_row_to_df_record(row,df_recode_record)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_multi_response_procedure(sliced_data,file_name,latest_wave,row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardise and Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wave Informations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ['length of current marriage',\n",
       "  'Current Marital Status: With Partnership',\n",
       "  'Lower Education',\n",
       "  'Residence in Rurual',\n",
       "  'Citizenship Status',\n",
       "  'Foreign Born',\n",
       "  'Male',\n",
       "  'Age at Interview',\n",
       "  'History of Unemployment',\n",
       "  'Low/No Vigorous Activity',\n",
       "  'Low/No Moderate Activity',\n",
       "  'History of Smoking',\n",
       "  'Current Smoker',\n",
       "  'Sum of Childhood Stressful Events',\n",
       "  'History Of Renting',\n",
       "  'Sleep Problems',\n",
       "  'History Of Divorce',\n",
       "  'Never Married',\n",
       "  'Lower Maternal Education',\n",
       "  'Lower Paternal Education',\n",
       "  'Lower Main Carer Occupational Status',\n",
       "  'Wealth',\n",
       "  'Perceived Constraints',\n",
       "  'Hopelessness',\n",
       "  'Pessimism',\n",
       "  'Optimism',\n",
       "  'Negative Affect',\n",
       "  'Positive Affect',\n",
       "  'Adult Psychosocial Adversity',\n",
       "  'Death Year'],\n",
       " 2: ['Lower Education',\n",
       "  'Citizenship Status',\n",
       "  'Foreign Born',\n",
       "  'Male',\n",
       "  'Alcohol Abuse',\n",
       "  'History of drink',\n",
       "  'Sum of Childhood Stressful Events',\n",
       "  'Life Satisfaction',\n",
       "  'Lower Maternal Education',\n",
       "  'Lower Paternal Education',\n",
       "  'Lower Main Carer Occupational Status',\n",
       "  'Total Income',\n",
       "  'Total Household Income',\n",
       "  'Death Year'],\n",
       " 3: ['Lower Education',\n",
       "  'Citizenship Status',\n",
       "  'Foreign Born',\n",
       "  'Male',\n",
       "  'Sum of Childhood Stressful Events',\n",
       "  'History of Financial Difficulties',\n",
       "  'Lower Maternal Education',\n",
       "  'Lower Paternal Education',\n",
       "  'Lower Main Carer Occupational Status',\n",
       "  'Death Year'],\n",
       " 4: ['Lower Education',\n",
       "  'Citizenship Status',\n",
       "  'Foreign Born',\n",
       "  'Male',\n",
       "  'Sum of Childhood Stressful Events',\n",
       "  'Lower Maternal Education',\n",
       "  'Lower Paternal Education',\n",
       "  'Lower Main Carer Occupational Status',\n",
       "  'Trait Anxiety',\n",
       "  'loneliness',\n",
       "  'Death Year'],\n",
       " 5: ['Lower Education',\n",
       "  'Citizenship Status',\n",
       "  'Foreign Born',\n",
       "  'Male',\n",
       "  'Sum of Childhood Stressful Events',\n",
       "  'Lower Maternal Education',\n",
       "  'Lower Paternal Education',\n",
       "  'Lower Main Carer Occupational Status',\n",
       "  'Death Year'],\n",
       " 6: ['Lower Education',\n",
       "  'Citizenship Status',\n",
       "  'Foreign Born',\n",
       "  'Male',\n",
       "  'Sum of Childhood Stressful Events',\n",
       "  'Lower Maternal Education',\n",
       "  'Lower Paternal Education',\n",
       "  'Lower Main Carer Occupational Status',\n",
       "  'Death Year'],\n",
       " 7: ['Lower Education',\n",
       "  'Citizenship Status',\n",
       "  'Foreign Born',\n",
       "  'Male',\n",
       "  'Sum of Childhood Stressful Events',\n",
       "  'Lower Maternal Education',\n",
       "  'Lower Paternal Education',\n",
       "  'Lower Main Carer Occupational Status',\n",
       "  'Agreeableness',\n",
       "  'Extroversion',\n",
       "  'Neuroticism',\n",
       "  'Death Year'],\n",
       " 8: ['Lower Education',\n",
       "  'Citizenship Status',\n",
       "  'Foreign Born',\n",
       "  'Male',\n",
       "  'Sum of Childhood Stressful Events',\n",
       "  'Lower Maternal Education',\n",
       "  'Lower Paternal Education',\n",
       "  'Lower Main Carer Occupational Status',\n",
       "  'Death Year']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "wave_dict={}\n",
    "for wave in range(1,9):\n",
    "    wave_dict[wave]=[]\n",
    "    for ind,row in df_recode_record.iterrows():\n",
    "        if isinstance(row['available_waves'],str):\n",
    "            avaliable_waves = row['available_waves'].replace('[','').replace(']','').split(',')   \n",
    "        else:\n",
    "            avaliable_waves=row['available_waves']\n",
    "        \n",
    "        if str(wave) in avaliable_waves or '0' in avaliable_waves:\n",
    "            wave_dict[wave].append(row['conventional_name'])\n",
    "wave_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for wave 1, there are 31 variables\n",
      "for wave 2, there are 14 variables\n",
      "for wave 3, there are 10 variables\n",
      "for wave 4, there are 11 variables\n",
      "for wave 5, there are 9 variables\n",
      "for wave 6, there are 9 variables\n",
      "for wave 7, there are 12 variables\n",
      "for wave 8, there are 9 variables\n"
     ]
    }
   ],
   "source": [
    "for wave in wave_dict.keys():\n",
    "    print(f'for wave {wave}, there are {len(wave_dict[wave])} variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wave1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(share_path/'only_id_and_deathY_for_wave_merging.csv')\n",
    "df_raw_recoded=pd.read_csv(share_path/'raw_recoded_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to deal with var length of current marriage\n",
      "In Recorder: \n",
      "var_set=['r1mcurln']\n",
      "replace_dic=0    NaN\n",
      "Name: replace_dict, dtype: object\n",
      "count    21710.000000\n",
      "mean        35.903685\n",
      "std         11.649478\n",
      "min          0.000000\n",
      "25%         29.000000\n",
      "50%         36.000000\n",
      "75%         44.000000\n",
      "max         85.000000\n",
      "Name: lencurmarridge, dtype: float64\n",
      "start to deal with var Current Marital Status: With Partnership\n",
      "In Recorder: \n",
      "var_set=['r1mstat']\n",
      "replace_dic=1    NaN\n",
      "Name: replace_dict, dtype: object\n",
      "all responses are: ['5.divorced', '7.widowed', '4.separated', '1.married', '8.never married', '3.partnered']\n",
      "replace response [5.divorced] with int .. (999 -> none)-1\n",
      "replace response [7.widowed] with int .. (999 -> none)-1\n",
      "replace response [4.separated] with int .. (999 -> none)-1\n",
      "replace response [1.married] with int .. (999 -> none)1\n",
      "replace response [8.never married] with int .. (999 -> none)-1\n",
      "replace response [3.partnered] with int .. (999 -> none)1\n",
      "\n",
      "1.the replace dict is \n",
      "{'5.divorced': -1, '7.widowed': -1, '4.separated': -1, '1.married': 1, '8.never married': -1, '3.partnered': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'currentpaternered', 'conventional_name': 'Current Marital Status: With Partnership', 'varname_in_raw': nan, 'domain': 'Adulthood Socioeconomic', 'available_waves': '[1, 2, 3, 4, 5, 6, 7, 8]', 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': nan, 'replace_dict': nan, 'standardise': True, 'notes': nan, 'recode_date': '2023-01-10', 'var_set': ['r1mstat'], 'in_ELSA': True, 'in_HRS': False, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "1     22824\n",
      "-1     7572\n",
      "Name: currentpaternered, dtype: int64\n",
      "start to deal with var Lower Education\n",
      "In Recorder: \n",
      "var_set=['raedisced']\n",
      "replace_dic=2    {'1.Primary education': 1, '3.Upper secondary ...\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.Primary education': 1, '3.Upper secondary education': 3, '2.Lower secondary education': 2, '5.First stage of tertiary education': 5, '0.None': None, '6.Second stage of tertiary education': 6, '4.Post-secondary non tertiary education': 4, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'Zeduccat', 'conventional_name': 'Lower Education', 'varname_in_raw': nan, 'domain': 'Adulthood Socioeconomic', 'available_waves': '[0]', 'recode_type': 'replace_only', 'reverse_code': True, 'maximum_missing_response': nan, 'replace_dict': {'1.Primary education': 1, '3.Upper secondary education': 3, '2.Lower secondary education': 2, '5.First stage of tertiary education': 5, '0.None': None, '6.Second stage of tertiary education': 6, '4.Post-secondary non tertiary education': 4, 'nan': None}, 'standardise': True, 'notes': 'not same as HRS, we use the ISCED 2 code for education category', 'recode_date': '2023-01-10', 'var_set': ['raedisced'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "4.0    46941\n",
      "2.0    27578\n",
      "5.0    25455\n",
      "6.0    25082\n",
      "3.0     6080\n",
      "1.0      980\n",
      "Name: Zeduccat, dtype: int64\n",
      "start to deal with var Residence in Rurual\n",
      "In Recorder: \n",
      "var_set=['h1rural']\n",
      "replace_dic=3    {'1.rural': 1, '0.urban': -1, 'nan': None}\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.rural': 1, '0.urban': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'rural', 'conventional_name': 'Residence in Rurual', 'varname_in_raw': nan, 'domain': 'Demographic', 'available_waves': '[1, 2, 3, 4, 5, 6, 7, 8]', 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': nan, 'replace_dict': {'1.rural': 1, '0.urban': -1, 'nan': None}, 'standardise': True, 'notes': '1:rural;-1:urban', 'recode_date': '2023-01-10', 'var_set': ['h1rural'], 'in_ELSA': False, 'in_HRS': False, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1    22540\n",
      "1      6497\n",
      "Name: rural, dtype: int64\n",
      "start to deal with var Citizenship Status\n",
      "In Recorder: \n",
      "var_set=['racitizen']\n",
      "replace_dic=4    {'0.No': -1, '1.Yes': 1, 'nan': None}\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'0.No': -1, '1.Yes': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'citizenship', 'conventional_name': 'Citizenship Status', 'varname_in_raw': nan, 'domain': 'Demographic', 'available_waves': '[0]', 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': nan, 'replace_dict': {'0.No': -1, '1.Yes': 1, 'nan': None}, 'standardise': True, 'notes': 'whether citizen at baseline interview', 'recode_date': '2023-01-10', 'var_set': ['racitizen'], 'in_ELSA': False, 'in_HRS': False, 'wave_controller': 'single_wave'}\n",
      "\n",
      "3. statistics\n",
      "1     133671\n",
      "-1      4994\n",
      "Name: citizenship, dtype: int64\n",
      "start to deal with var Foreign Born\n",
      "In Recorder: \n",
      "var_set=['rabcountry']\n",
      "replace_dic=5    {'1.in country': -1, '0.out of country': 1, 'n...\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.in country': -1, '0.out of country': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'migrantYN', 'conventional_name': 'Foreign Born', 'varname_in_raw': nan, 'domain': 'Demographic', 'available_waves': '[0]', 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': nan, 'replace_dict': {'1.in country': -1, '0.out of country': 1, 'nan': None}, 'standardise': True, 'notes': 'Born in Country of Interview', 'recode_date': '2023-01-10', 'var_set': ['rabcountry'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'single_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1    124238\n",
      "1      14485\n",
      "Name: migrantYN, dtype: int64\n",
      "start to deal with var Male\n",
      "In Recorder: \n",
      "var_set=['ragender']\n",
      "replace_dic=6    {'1.man': 1, '2.woman': -1, 'nan': None}\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.man': 1, '2.woman': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'maleYN', 'conventional_name': 'Male', 'varname_in_raw': nan, 'domain': 'Demographic', 'available_waves': '[0]', 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': nan, 'replace_dict': {'1.man': 1, '2.woman': -1, 'nan': None}, 'standardise': True, 'notes': nan, 'recode_date': '2023-01-10', 'var_set': ['ragender'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'single_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1    77707\n",
      "1     61913\n",
      "Name: maleYN, dtype: int64\n",
      "start to deal with var Age at Interview\n",
      "In Recorder: \n",
      "var_set=['r1agey']\n",
      "replace_dic=7    NaN\n",
      "Name: replace_dict, dtype: object\n",
      "count    30416.000000\n",
      "mean        63.814473\n",
      "std         10.570101\n",
      "min         25.000000\n",
      "25%         55.000000\n",
      "50%         62.000000\n",
      "75%         71.000000\n",
      "max        103.000000\n",
      "Name: age, dtype: float64\n",
      "start to deal with var History of Unemployment\n",
      "In Recorder: \n",
      "var_set=['r1unemp', 'r2unemp', 'r4unemp', 'r5unemp', 'r6unemp', 'r7unemp', 'r8unemp']\n",
      "replace_dic=8    {'0.No': -1, '1.Yes': 1, 'nan': None}\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'0.No': -1, '1.Yes': 1, 'nan': None}\n",
      "-1    132195\n",
      " 1      7425\n",
      "Name: everunemployed, dtype: int64\n",
      "start to deal with var Low/No Vigorous Activity\n",
      "In Recorder: \n",
      "var_set=['r1vgactx']\n",
      "replace_dic=9    {'3.1 per week': -1, '4.1-3 per mon': 1, '2.> ...\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'vigactivityYN', 'conventional_name': 'Low/No Vigorous Activity', 'varname_in_raw': nan, 'domain': 'Adulthood Health Behaviors', 'available_waves': '[1, 2, 4, 5, 6, 7, 8]', 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': nan, 'replace_dict': {'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None}, 'standardise': True, 'notes': '>=1 times/week, -1', 'recode_date': '2023-01-10', 'var_set': ['r1vgactx'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "1     15144\n",
      "-1    15108\n",
      "Name: vigactivityYN, dtype: int64\n",
      "start to deal with var Low/No Moderate Activity\n",
      "In Recorder: \n",
      "var_set=['r1mdactx']\n",
      "replace_dic=10    {'3.1 per week': -1, '4.1-3 per mon': 1, '2.> ...\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'modactivityYN', 'conventional_name': 'Low/No Moderate Activity', 'varname_in_raw': nan, 'domain': 'Adulthood Health Behaviors', 'available_waves': '[1, 2, 4, 5, 6, 7, 8]', 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': nan, 'replace_dict': {'3.1 per week': -1, '4.1-3 per mon': 1, '2.> 1 per week': -1, '5.hardly ever or never': 1, 'nan': None}, 'standardise': True, 'notes': '>=1 times/week, -1', 'recode_date': '2023-01-10', 'var_set': ['r1mdactx'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1    24880\n",
      "1      5376\n",
      "Name: modactivityYN, dtype: int64\n",
      "start to deal with var History of Smoking\n",
      "In Recorder: \n",
      "var_set=['r1smokev', 'r2smokev', 'r4smokev', 'r5smokev', 'r6smokev', 'r7smokev', 'r8smokev']\n",
      "replace_dic=12    {'0.No': -1, '1.Yes': 1, 'nan': None}\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'0.No': -1, '1.Yes': 1, 'nan': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1    77943\n",
      " 1    61677\n",
      "Name: eversmokeYN, dtype: int64\n",
      "start to deal with var Current Smoker\n",
      "In Recorder: \n",
      "var_set=['r1smokev']\n",
      "replace_dic=13    {'0.No': -1, '1.Yes': 1, 'nan': None}\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'0.No': -1, '1.Yes': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'currsmokeYN', 'conventional_name': 'Current Smoker', 'varname_in_raw': nan, 'domain': 'Adulthood Health Behaviors', 'available_waves': '[1, 2, 4, 5, 6, 7, 8]', 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': nan, 'replace_dict': {'0.No': -1, '1.Yes': 1, 'nan': None}, 'standardise': True, 'notes': nan, 'recode_date': '2023-01-10', 'var_set': ['r1smokev'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1    16000\n",
      "1     14260\n",
      "Name: currsmokeYN, dtype: int64\n",
      "start to deal with var Sum of Childhood Stressful Events\n",
      "In Recorder: \n",
      "var_set=['racsevent_s']\n",
      "replace_dic=15    NaN\n",
      "Name: replace_dict, dtype: object\n",
      "count    91143.000000\n",
      "mean         0.179169\n",
      "std          0.425150\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          4.000000\n",
      "Name: chilstrevents, dtype: float64\n",
      "start to deal with var History Of Renting\n",
      "In Recorder: \n",
      "var_set=['r1hownrnt', 'r2hownrnt', 'r4hownrnt', 'r5hownrnt', 'r6hownrnt', 'r7hownrnt', 'r8hownrnt']\n",
      "replace_dic=17    {'3.other arrangements': -1, '2.rents home': 1...\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'3.other arrangements': -1, '2.rents home': 1, '1.owns home': -1, 'nan': None}\n",
      "-1    120718\n",
      " 1     18902\n",
      "Name: everrent, dtype: int64\n",
      "start to deal with var Sleep Problems\n",
      "In Recorder: \n",
      "var_set=['r1sleep']\n",
      "replace_dic=18    {'1.yes': 1, '0.no': -1, 'nan': None}\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'1.yes': 1, '0.no': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'sleepYN', 'conventional_name': 'Sleep Problems', 'varname_in_raw': nan, 'domain': 'Adulthood Health Behaviors', 'available_waves': '[1, 2, 4, 5, 6, 7, 8]', 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': nan, 'replace_dict': {'1.yes': 1, '0.no': -1, 'nan': None}, 'standardise': True, 'notes': 'r been asked have you have trouble recently in sleeping', 'recode_date': '2023-01-11', 'var_set': ['r1sleep'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1    20557\n",
      "1      9385\n",
      "Name: sleepYN, dtype: int64\n",
      "start to deal with var History Of Divorce\n",
      "In Recorder: \n",
      "var_set=['r1mstat', 'r2mstat', 'r4mstat', 'r5mstat', 'r6mstat', 'r7mstat', 'r8mstat']\n",
      "replace_dic=19    {'7.widowed': -1, '1.married': -1, '8.never ma...\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'7.widowed': -1, '1.married': -1, '8.never married': -1, '3.partnered': -1, '5.divorced': 1, '4.separated': 1, 'nan': None}\n",
      "-1    129122\n",
      " 1     10498\n",
      "Name: everdivorced, dtype: int64\n",
      "start to deal with var Never Married\n",
      "In Recorder: \n",
      "var_set=['r1mstat']\n",
      "replace_dic=20    {'7.widowed': -1, '1.married': -1, '8.never ma...\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'7.widowed': -1, '1.married': -1, '8.never married': 1, '3.partnered': -1, '5.divorced': -1, '4.separated': -1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'nevermarried', 'conventional_name': 'Never Married', 'varname_in_raw': nan, 'domain': 'Adulthood Socioeconomic', 'available_waves': '[1, 2, 4, 5, 6, 7, 8]', 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': nan, 'replace_dict': {'7.widowed': -1, '1.married': -1, '8.never married': 1, '3.partnered': -1, '5.divorced': -1, '4.separated': -1, 'nan': None}, 'standardise': True, 'notes': nan, 'recode_date': '2023-01-11', 'var_set': ['r1mstat'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'latest_wave'}\n",
      "\n",
      "3. statistics\n",
      "-1    28954\n",
      "1      1442\n",
      "Name: nevermarried, dtype: int64\n",
      "start to deal with var Lower Maternal Education\n",
      "In Recorder: \n",
      "var_set=['ramomedisced']\n",
      "replace_dic=22    {'6.Second stage of tertiary education': 6, '2...\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'Zmotherseduc', 'conventional_name': 'Lower Maternal Education', 'varname_in_raw': nan, 'domain': 'Childhood Adversity', 'available_waves': '[0]', 'recode_type': 'replace_only', 'reverse_code': True, 'maximum_missing_response': nan, 'replace_dict': {'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None}, 'standardise': True, 'notes': 'isced standard', 'recode_date': '2023-01-11', 'var_set': ['ramomedisced'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'single_wave'}\n",
      "\n",
      "3. statistics\n",
      "6.0    28811\n",
      "5.0    19041\n",
      "4.0    12686\n",
      "2.0     3460\n",
      "3.0      867\n",
      "1.0       74\n",
      "Name: Zmotherseduc, dtype: int64\n",
      "start to deal with var Lower Paternal Education\n",
      "In Recorder: \n",
      "var_set=['radadedisced']\n",
      "replace_dic=23    {'6.Second stage of tertiary education': 6, '2...\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'Zfatherseduc', 'conventional_name': 'Lower Paternal Education', 'varname_in_raw': nan, 'domain': 'Childhood Adversity', 'available_waves': '[0]', 'recode_type': 'replace_only', 'reverse_code': True, 'maximum_missing_response': nan, 'replace_dict': {'6.Second stage of tertiary education': 6, '2.Lower secondary education': 2, '1.Primary education': 1, '3.Upper secondary education': 3, '0.None': None, '5.First stage of tertiary education': 5, '4.Post-secondary non tertiary education': 4, 'nan': None}, 'standardise': True, 'notes': 'isced standard', 'recode_date': '2023-01-11', 'var_set': ['radadedisced'], 'in_ELSA': True, 'in_HRS': True, 'wave_controller': 'single_wave'}\n",
      "\n",
      "3. statistics\n",
      "6.0    24435\n",
      "4.0    19622\n",
      "5.0    13075\n",
      "2.0     7116\n",
      "3.0     1285\n",
      "1.0      504\n",
      "Name: Zfatherseduc, dtype: int64\n",
      "start to deal with var Lower Main Carer Occupational Status\n",
      "In Recorder: \n",
      "var_set=['ramaoccup']\n",
      "replace_dic=24    {'7.Craft or related trades worker': 5, '6.Ski...\n",
      "Name: replace_dict, dtype: object\n",
      "\n",
      "1.the replace dict is \n",
      "{'7.Craft or related trades worker': 5, '6.Skilled agricultural or fishery worker': 5, '11.Spontaneous only: there was no main breadwinner': None, '2.Professional': 2, '9.Elementary occupation': 6, '10.Armed forces': 4, '4.Clerk': 3, '8.Plant/machine operator or assembler': 6, '5.Service, shop or market sales worker': 3, '3.Technician or associate professional': 2, '1.Legislator, senior official or manager': 1, 'nan': None}\n",
      "\n",
      "2. the updated var_dict is\n",
      "{'varname': 'fathersocc', 'conventional_name': 'Lower Main Carer Occupational Status', 'varname_in_raw': nan, 'domain': 'Childhood Adversity', 'available_waves': '[0]', 'recode_type': 'replace_only', 'reverse_code': False, 'maximum_missing_response': nan, 'replace_dict': {'7.Craft or related trades worker': 5, '6.Skilled agricultural or fishery worker': 5, '11.Spontaneous only: there was no main breadwinner': None, '2.Professional': 2, '9.Elementary occupation': 6, '10.Armed forces': 4, '4.Clerk': 3, '8.Plant/machine operator or assembler': 6, '5.Service, shop or market sales worker': 3, '3.Technician or associate professional': 2, '1.Legislator, senior official or manager': 1, 'nan': None}, 'standardise': True, 'notes': 'not just for father, but the main carer', 'recode_date': '2023-01-11', 'var_set': ['ramaoccup'], 'in_ELSA': False, 'in_HRS': True, 'wave_controller': 'single_wave'}\n",
      "\n",
      "3. statistics\n",
      "5.0    35257\n",
      "6.0    15415\n",
      "2.0    10414\n",
      "3.0     9521\n",
      "1.0     4053\n",
      "4.0      435\n",
      "Name: fathersocc, dtype: int64\n",
      "start to deal with var Wealth\n",
      "In Recorder: \n",
      "var_set=['h1atotb']\n",
      "replace_dic=25    NaN\n",
      "Name: replace_dict, dtype: object\n",
      "count    2.961500e+04\n",
      "mean     2.316373e+05\n",
      "std      6.360549e+05\n",
      "min     -5.492232e+05\n",
      "25%      4.511252e+04\n",
      "50%      1.442670e+05\n",
      "75%      2.812052e+05\n",
      "max      7.030952e+07\n",
      "Name: ZwealthT, dtype: float64\n",
      "start to deal with var Perceived Constraints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to deal with var Hopelessness\n",
      "start to deal with var Pessimism\n",
      "start to deal with var Optimism\n",
      "start to deal with var Negative Affect\n",
      "start to deal with var Positive Affect\n",
      "start to deal with var Adult Psychosocial Adversity\n",
      "start to deal with var Death Year\n",
      "In Recorder: \n",
      "var_set=['radyear']\n",
      "replace_dic=40    NaN\n",
      "Name: replace_dict, dtype: object\n",
      "count    18349.000000\n",
      "mean      2014.411630\n",
      "std          4.017226\n",
      "min       2004.000000\n",
      "25%       2012.000000\n",
      "50%       2015.000000\n",
      "75%       2018.000000\n",
      "max       2021.000000\n",
      "Name: deathY, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "for var in wave_dict[1]: \n",
    "\n",
    "    c1 = df_recode_record['conventional_name']==var\n",
    "    recode_record = df_recode_record.loc[c1,].copy()\n",
    "    varname = recode_record['varname'].values[0]\n",
    "    print(f'start to deal with var {var}')\n",
    "    # raw_coded\n",
    "    if recode_record['recode_type'].values[0]=='row_manual':\n",
    "        # find the vars in the saved file df_raw_recoded\n",
    "        col_name = varname+f'_{latest_wave}'\n",
    "        df=pd.merge(left=df_raw_recoded[['mergeid',col_name]],right=df,on='mergeid',how='right')\n",
    "        df.rename(columns={col_name:varname},inplace=True)\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        # firstly retrieve all information\n",
    "        \n",
    "        \n",
    "        if not recode_record['replace_dict'].isna().values[0]:\n",
    "            replace_dict = ast.literal_eval(recode_record['replace_dict'].values[0])\n",
    "            recode_record['replace_dict']=[replace_dict]\n",
    "        var_set = ast.literal_eval(recode_record['var_set'].values[0])\n",
    "        # available_waves = ast.literal_eval(recode_record['available_waves'].values[0])\n",
    "\n",
    "\n",
    "        if recode_record['recode_type'].values[0] in ['special_code','replace_only','direct_use']:\n",
    "            # replacing the var names in var_set \n",
    "            var_set=[re.sub('(\\d)',latest_wave,var) for var in var_set]\n",
    "\n",
    "        # no need to change # historical response\n",
    "\n",
    "        recode_record['var_set']=[var_set]\n",
    "        \n",
    "        # recode_record['available_waves']=[available_waves]\n",
    "        print(f\"In Recorder: \\nvar_set={var_set}\\nreplace_dic={recode_record['replace_dict']}\")\n",
    "\n",
    "        df,temp=recode_processor(varname,recode_record,df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original df shape is (139620, 34), now we start to delete rows that have more than 80% missing data (27 cols) before fitting into missing forest\n",
      "now df shape is (21325, 34)\n"
     ]
    }
   ],
   "source": [
    "print(f\"original df shape is {df.shape}, now we start to delete rows that have more than 80% missing data ({int(0.8*len(df.columns))} cols) before fitting into missing forest\")\n",
    "df=df.dropna(thresh=int(0.8*len(df.columns)))\n",
    "print(f\"now df shape is {df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={x:x[0:len(x)-3] for x in df.columns if '_1' in x},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardise & Missing Value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(share_path/f'recoded_data_wave_{latest_wave}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16998\n",
       "1     4327\n",
       "Name: death, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['death'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21325, 30)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_non_missing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=2022\n",
    "\n",
    "df['death'] = [0 if np.isnan(x) else 1 for x in df['deathY']]\n",
    "drop_columns = ['mergeid','hhid','deathY','pn','death','isocountry']\n",
    "df_to_missing_forest=df.drop(columns=drop_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardise \n",
    "for column in df_to_missing_forest.columns:\n",
    "    break\n",
    "    temp = df_to_missing_forest[column] \n",
    "    mean = np.mean(temp)\n",
    "    std = np.std(temp)\n",
    "    df_to_missing_forest[column] = (temp-mean)/std\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/valler/Python/OX_Thesis/OX_thesis/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2\n"
     ]
    }
   ],
   "source": [
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest\n",
    "\n",
    "imputer = MissForest(n_estimators=500, max_iter=5,random_state=random_state,criterion='squared_error')\n",
    "df_imputed = imputer.fit_transform(df_to_missing_forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_19573/2083311934.py:3: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_non_missing.loc[:,drop_columns]=df.loc[:,drop_columns]\n"
     ]
    }
   ],
   "source": [
    "data_non_missing = pd.DataFrame(columns=df_to_missing_forest.columns,data=df_imputed)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "data_non_missing.loc[:,drop_columns]=df.loc[:,drop_columns]\n",
    "data_non_missing.to_csv(share_path/f'recoded_data_wave_{latest_wave}_no_missing.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sumadultAE', 'Zposaffect', 'Znegaffect', 'Zoptimism', 'Zpessimism',\n",
       "       'Zhopelessness', 'Zperceivedconstraints', 'lencurmarridge',\n",
       "       'currentpaternered', 'Zeduccat', 'rural', 'citizenship', 'migrantYN',\n",
       "       'maleYN', 'age', 'everunemployed', 'vigactivityYN', 'modactivityYN',\n",
       "       'eversmokeYN', 'currsmokeYN', 'chilstrevents', 'everrent', 'sleepYN',\n",
       "       'everdivorced', 'nevermarried', 'Zmotherseduc', 'Zfatherseduc',\n",
       "       'fathersocc', 'ZwealthT', 'mergeid', 'hhid', 'deathY', 'pn', 'death',\n",
       "       'isocountry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src import DataImport\n",
    "import matplotlib.pyplot as plt\n",
    "from src import Models\n",
    "import pandas as pd \n",
    "import xgboost\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from src import Evaluate\n",
    "\n",
    "data_non_missing=pd.read_csv(share_path/f'recoded_data_wave_{latest_wave}_no_missing.csv')\n",
    "data_non_missing['deathY'].value_counts()\n",
    "data_non_missing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "imv=0.05077597926272015,\n",
      "roc-auc=0.7740091181503215,\n",
      "pr-auc=0.4794988629067089,\n",
      "f1=0.42801556420233466,\n",
      "efron_r2=0.1558489438390528,\n",
      "ffc_r2=0.422021440553761,\n",
      "IP=0.20332283781067864\n",
      "\n",
      "lgb\n",
      "imv=0.07710822293959829,\n",
      "roc-auc=0.7986583804156828,\n",
      "pr-auc=0.5213983565810563,\n",
      "f1=0.42470648289943846,\n",
      "efron_r2=0.20894728676876384,\n",
      "ffc_r2=0.45837714197889246,\n",
      "IP=0.20332283781067864\n"
     ]
    }
   ],
   "source": [
    "data_non_missing.drop(columns=['mergeid','hhid','pn','deathY','isocountry'],inplace=True)\n",
    "domain_list = list(data_non_missing.columns)\n",
    "domain_list.remove('death')\n",
    "for model_selection in ['xgb','lgb']:\n",
    "    print(f'\\n{model_selection}')\n",
    "    model = Models.Model_fixed_test_size(data=data_non_missing, \n",
    "                                         test_size=0.3,\n",
    "                                         domain_list=domain_list, model=model_selection,train_subset_size=1, order=0, y_colname='death')\n",
    "    evas = Evaluate.metric(model)\n",
    "    print(f'imv={evas.imv},\\nroc-auc={evas.auc_score},\\npr-auc={evas.pr_auc},\\nf1={evas.pr_f1},\\nefron_r2={evas.efron_rsquare},\\nffc_r2={evas.ffc_r2},\\nIP={evas.pr_no_skill}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16998\n",
       "1     4327\n",
       "Name: death, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_non_missing['death'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_csv(share_path/'only_id_and_deathY_for_wave_merging.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recode_record.to_csv(share_path/'recode_record.csv',index=False)\n",
    "df_raw_recoded.to_csv(share_path/'raw_recoded_data.csv',index=False)\n",
    "df_vars_found_in_raw.to_csv(Path.cwd()/'vars_found_in_raw'/'SHARE.csv',index=False)\n",
    "df.to_pickle(share_path/f'recoded_data_wave_{latest_wave}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp Func Zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_recode_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total\n",
      "you have code 42 vars in total\n",
      "you have code 35 vars that are in HRS \n",
      "you have code 22 vars that are in ELSA \n",
      "\n",
      "Today\n",
      "you have code 1 vars in total\n",
      "you have code 1 vars that are in HRS \n",
      "you have code 0 vars that are in ELSA \n"
     ]
    }
   ],
   "source": [
    "print('In total')\n",
    "print('you have code {} vars in total'.format(len(df_recode_record)))\n",
    "print('you have code {} vars that are in HRS '.format(len(df_recode_record.loc[df_recode_record['in_HRS']==True])))\n",
    "print('you have code {} vars that are in ELSA '.format(len(df_recode_record.loc[df_recode_record['in_ELSA']==True])))\n",
    "\n",
    "print('\\nToday')\n",
    "df_recode_today=df_recode_record.loc[df_recode_record['recode_date']==today].copy()\n",
    "print('you have code {} vars in total'.format(len(df_recode_today)))\n",
    "print('you have code {} vars that are in HRS '.format(len(df_recode_today.loc[df_recode_today['in_HRS']==True])))\n",
    "print('you have code {} vars that are in ELSA '.format(len(df_recode_today.loc[df_recode_today['in_ELSA']==True])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>conventional_name</th>\n",
       "      <th>varname_in_raw</th>\n",
       "      <th>domain</th>\n",
       "      <th>available_waves</th>\n",
       "      <th>recode_type</th>\n",
       "      <th>reverse_code</th>\n",
       "      <th>maximum_missing_response</th>\n",
       "      <th>replace_dict</th>\n",
       "      <th>standardise</th>\n",
       "      <th>notes</th>\n",
       "      <th>recode_date</th>\n",
       "      <th>var_set</th>\n",
       "      <th>in_ELSA</th>\n",
       "      <th>in_HRS</th>\n",
       "      <th>wave_controller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lencurmarridge</td>\n",
       "      <td>length of current marriage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r1mcurln']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>currentpaternered</td>\n",
       "      <td>Current Marital Status: With Partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r8mstat']</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zeduccat</td>\n",
       "      <td>Lower Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.Primary education': 1, '3.Upper secondary ...</td>\n",
       "      <td>True</td>\n",
       "      <td>not same as HRS, we use the ISCED 2 code for e...</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['raedisced']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rural</td>\n",
       "      <td>Residence in Rurual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.rural': 1, '0.urban': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>1:rural;-1:urban</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['h8rural']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>citizenship</td>\n",
       "      <td>Citizenship Status</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>whether citizen at baseline interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['racitizen']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>migrantYN</td>\n",
       "      <td>Foreign Born</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.in country': -1, '0.out of country': 1, 'n...</td>\n",
       "      <td>True</td>\n",
       "      <td>Born in Country of Interview</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['rabcountry']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>maleYN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.man': 1, '2.woman': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['ragender']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deathY</td>\n",
       "      <td>Death Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Others</td>\n",
       "      <td>[0]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['radyear']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>age</td>\n",
       "      <td>Age at Interview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r8agey']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>everunemployed</td>\n",
       "      <td>History of Unemployment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r1unemp', 'r2unemp', 'r4unemp', 'r5unemp', '...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vigactivityYN</td>\n",
       "      <td>Low/No Vigorous Activity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Health Behaviors</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'3.1 per week': -1, '4.1-3 per mon': 1, '2.&gt; ...</td>\n",
       "      <td>True</td>\n",
       "      <td>&gt;=1 times/week, -1</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r8vgactx']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>modactivityYN</td>\n",
       "      <td>Low/No Moderate Activity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Health Behaviors</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'3.1 per week': -1, '4.1-3 per mon': 1, '2.&gt; ...</td>\n",
       "      <td>True</td>\n",
       "      <td>&gt;=1 times/week, -1</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r8mdactx']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>alcoholYN</td>\n",
       "      <td>Alcohol Abuse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Health Behaviors</td>\n",
       "      <td>[2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.yes': 1, '0.no': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>Directly using the definition of binge drunk f...</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r8drinkb']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>eversmokeYN</td>\n",
       "      <td>History of Smoking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Health Behaviors</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r1smokev', 'r2smokev', 'r4smokev', 'r5smokev...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>currsmokeYN</td>\n",
       "      <td>Current Smoker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Health Behaviors</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0.No': -1, '1.Yes': 1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r8smokev']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>everalcoholYN</td>\n",
       "      <td>History of drink</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Health Behaviors</td>\n",
       "      <td>[2, 4, 5]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.yes': 1, '0.no': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r2drinkev', 'r4drinkev', 'r5drinkev']</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>drink_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>chilstrevents</td>\n",
       "      <td>Sum of Childhood Stressful Events</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Childhood Adversity</td>\n",
       "      <td>[0]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['racsevent_s']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>everfindiff</td>\n",
       "      <td>History of Financial Difficulties</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[3, 7]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.yes': 1, '0.no': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['r3sfnhe', 'r7sfnhe']</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>financial_difficulties_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>everrent</td>\n",
       "      <td>History Of Renting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'3.other arrangements': -1, '2.rents home': 1...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>['r1hownrnt', 'r2hownrnt', 'r4hownrnt', 'r5how...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sleepYN</td>\n",
       "      <td>Sleep Problems</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Health Behaviors</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'1.yes': 1, '0.no': -1, 'nan': None}</td>\n",
       "      <td>True</td>\n",
       "      <td>r been asked have you have trouble recently in...</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['r8sleep']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>everdivorced</td>\n",
       "      <td>History Of Divorce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>historical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'7.widowed': -1, '1.married': -1, '8.never ma...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['r1mstat', 'r2mstat', 'r4mstat', 'r5mstat', '...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nevermarried</td>\n",
       "      <td>Never Married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'7.widowed': -1, '1.married': -1, '8.never ma...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['r8mstat']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Zlifesatis</td>\n",
       "      <td>Life Satisfaction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>This is an one-question Z-score, different to ...</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['r8satlifez']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Zmotherseduc</td>\n",
       "      <td>Lower Maternal Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Childhood Adversity</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'6.Second stage of tertiary education': 6, '2...</td>\n",
       "      <td>True</td>\n",
       "      <td>isced standard</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['ramomedisced']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Zfatherseduc</td>\n",
       "      <td>Lower Paternal Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Childhood Adversity</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'6.Second stage of tertiary education': 6, '2...</td>\n",
       "      <td>True</td>\n",
       "      <td>isced standard</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['radadedisced']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fathersocc</td>\n",
       "      <td>Lower Main Carer Occupational Status</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Childhood Adversity</td>\n",
       "      <td>[0]</td>\n",
       "      <td>replace_only</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'7.Craft or related trades worker': 5, '6.Ski...</td>\n",
       "      <td>True</td>\n",
       "      <td>not just for father, but the main carer</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>['ramaoccup']</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>single_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ZwealthT</td>\n",
       "      <td>Wealth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>['h8atotb']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ZincomeT</td>\n",
       "      <td>Total Income</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>special_code</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(after tax) adding together Individual Earning...</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>['r8itearn', 'r8itsemp', 'r8itpena', 'r8itpubp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HIncome</td>\n",
       "      <td>Total Household Income</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Socioeconomic</td>\n",
       "      <td>[2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>direct_use</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>['h8ittot']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Row Recode, Manual</td>\n",
       "      <td>2023-02-18</td>\n",
       "      <td>[{1: ['q2_b', 'q2_c'], 2: ['ac015_'], 4: ['ac0...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Zperceivedconstraints</td>\n",
       "      <td>Perceived Constraints</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'sharew1_rel8-0-0_dropoff.dta': {1.0: 1, 2.0:...</td>\n",
       "      <td>False</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-18</td>\n",
       "      <td>[{1: {'sharew1_rel8-0-0_dropoff.dta': ['q2_b',...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>latest_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Zanxiety</td>\n",
       "      <td>Trait Anxiety</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>{'sharew4_rel8-0-0_mh.dta': {'Hardly ever': 2,...</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{4: {'sharew4_rel8-0-0_mh.dta': ['mh023_', 'm...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Zhopelessness</td>\n",
       "      <td>Hopelessness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'sharew1_rel8-0-0_mh.dta': {'Refusal': None, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{1: {'sharew1_rel8-0-0_mh.dta': ['mh003_']}, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Zloneliness</td>\n",
       "      <td>loneliness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[4, 5, 6, 7, 8]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>{'sharew4_rel8-0-0_dropoff.dta': {'Hardly ever...</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{4: {'sharew4_rel8-0-0_dropoff.dta': ['q5a', ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Zagreeableness</td>\n",
       "      <td>Agreeableness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'sharew7_rel8-0-0_ac.dta': {'Disagree a littl...</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{7: {'sharew7_rel8-0-0_ac.dta': ['ac702_', 'a...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Zextroversion</td>\n",
       "      <td>Extroversion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'sharew7_rel8-0-0_ac.dta': {'Disagree a littl...</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{7: {'sharew7_rel8-0-0_ac.dta': ['ac706_', 'a...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Zneuroticism</td>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Adverse Experiences</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{7: {'sharew7_rel8-0-0_ac.dta': ['ac709_', 'a...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Zpessimism</td>\n",
       "      <td>Pessimism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'sharew1_rel8-0-0_dropoff.dta': {'Strongly ag...</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{1: {'sharew1_rel8-0-0_dropoff.dta': ['q3_d',...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Zoptimism</td>\n",
       "      <td>Optimism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>{'sharew1_rel8-0-0_dropoff.dta': {'Strongly ag...</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{1: {'sharew1_rel8-0-0_dropoff.dta': ['q3_a',...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Znegaffect</td>\n",
       "      <td>Negative Affect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[1]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>{'sharew1_rel8-0-0_dropoff.dta': {'Almost none...</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{1: {'sharew1_rel8-0-0_dropoff.dta': ['q4_a',...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Zposaffect</td>\n",
       "      <td>Positive Affect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[1]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'sharew1_rel8-0-0_dropoff.dta': {'Almost none...</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>[{1: {'sharew1_rel8-0-0_dropoff.dta': ['q4_l',...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sumadultAE</td>\n",
       "      <td>Adult Psychosocial Adversity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adulthood Psychological</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>row_manual</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Raw Recode, Manual</td>\n",
       "      <td>2023-02-23</td>\n",
       "      <td>[{1: {'sharew1_rel8-0-0_dropoff.dta': ['ilq6',...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  varname                         conventional_name  \\\n",
       "0          lencurmarridge                length of current marriage   \n",
       "1       currentpaternered  Current Marital Status: With Partnership   \n",
       "2                Zeduccat                           Lower Education   \n",
       "3                   rural                       Residence in Rurual   \n",
       "4             citizenship                        Citizenship Status   \n",
       "5               migrantYN                              Foreign Born   \n",
       "6                  maleYN                                      Male   \n",
       "7                  deathY                                Death Year   \n",
       "8                     age                          Age at Interview   \n",
       "9          everunemployed                   History of Unemployment   \n",
       "10          vigactivityYN                  Low/No Vigorous Activity   \n",
       "11          modactivityYN                  Low/No Moderate Activity   \n",
       "12              alcoholYN                             Alcohol Abuse   \n",
       "13            eversmokeYN                        History of Smoking   \n",
       "14            currsmokeYN                            Current Smoker   \n",
       "15          everalcoholYN                          History of drink   \n",
       "16          chilstrevents         Sum of Childhood Stressful Events   \n",
       "17            everfindiff         History of Financial Difficulties   \n",
       "18               everrent                        History Of Renting   \n",
       "19                sleepYN                            Sleep Problems   \n",
       "20           everdivorced                        History Of Divorce   \n",
       "21           nevermarried                             Never Married   \n",
       "22             Zlifesatis                         Life Satisfaction   \n",
       "23           Zmotherseduc                  Lower Maternal Education   \n",
       "24           Zfatherseduc                  Lower Paternal Education   \n",
       "25             fathersocc      Lower Main Carer Occupational Status   \n",
       "26               ZwealthT                                    Wealth   \n",
       "27               ZincomeT                              Total Income   \n",
       "28                HIncome                    Total Household Income   \n",
       "29  Perceived Constraints                     Perceived Constraints   \n",
       "30  Zperceivedconstraints                     Perceived Constraints   \n",
       "31               Zanxiety                             Trait Anxiety   \n",
       "32          Zhopelessness                              Hopelessness   \n",
       "33            Zloneliness                                loneliness   \n",
       "34         Zagreeableness                             Agreeableness   \n",
       "35          Zextroversion                              Extroversion   \n",
       "36           Zneuroticism                               Neuroticism   \n",
       "37             Zpessimism                                 Pessimism   \n",
       "38              Zoptimism                                  Optimism   \n",
       "39             Znegaffect                           Negative Affect   \n",
       "40             Zposaffect                           Positive Affect   \n",
       "41             sumadultAE              Adult Psychosocial Adversity   \n",
       "\n",
       "    varname_in_raw                         domain           available_waves  \\\n",
       "0              NaN        Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "1              NaN        Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "2              NaN        Adulthood Socioeconomic                       [0]   \n",
       "3              NaN                    Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "4              NaN                    Demographic                       [0]   \n",
       "5              NaN                    Demographic                       [0]   \n",
       "6              NaN                    Demographic                       [0]   \n",
       "7              NaN                         Others                       [0]   \n",
       "8              NaN                    Demographic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "9              NaN        Adulthood Socioeconomic     [1, 2, 4, 5, 6, 7, 8]   \n",
       "10             NaN     Adulthood Health Behaviors     [1, 2, 4, 5, 6, 7, 8]   \n",
       "11             NaN     Adulthood Health Behaviors     [1, 2, 4, 5, 6, 7, 8]   \n",
       "12             NaN     Adulthood Health Behaviors        [2, 4, 5, 6, 7, 8]   \n",
       "13             NaN     Adulthood Health Behaviors     [1, 2, 4, 5, 6, 7, 8]   \n",
       "14             NaN     Adulthood Health Behaviors     [1, 2, 4, 5, 6, 7, 8]   \n",
       "15             NaN     Adulthood Health Behaviors                 [2, 4, 5]   \n",
       "16             NaN            Childhood Adversity                       [0]   \n",
       "17             NaN        Adulthood Socioeconomic                    [3, 7]   \n",
       "18             NaN        Adulthood Socioeconomic     [1, 2, 4, 5, 6, 7, 8]   \n",
       "19             NaN     Adulthood Health Behaviors     [1, 2, 4, 5, 6, 7, 8]   \n",
       "20             NaN        Adulthood Socioeconomic     [1, 2, 4, 5, 6, 7, 8]   \n",
       "21             NaN        Adulthood Socioeconomic     [1, 2, 4, 5, 6, 7, 8]   \n",
       "22             NaN        Adulthood Psychological        [2, 4, 5, 6, 7, 8]   \n",
       "23             NaN            Childhood Adversity                       [0]   \n",
       "24             NaN            Childhood Adversity                       [0]   \n",
       "25             NaN            Childhood Adversity                       [0]   \n",
       "26             NaN        Adulthood Socioeconomic  [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "27             NaN        Adulthood Socioeconomic        [2, 4, 5, 6, 7, 8]   \n",
       "28             NaN        Adulthood Socioeconomic        [2, 4, 5, 6, 7, 8]   \n",
       "29             NaN        Adulthood Psychological     [1, 2, 4, 5, 6, 7, 8]   \n",
       "30             NaN        Adulthood Psychological     [1, 2, 4, 5, 6, 7, 8]   \n",
       "31             NaN        Adulthood Psychological                    [4, 5]   \n",
       "32             NaN        Adulthood Psychological     [1, 2, 4, 5, 6, 7, 8]   \n",
       "33             NaN        Adulthood Psychological           [4, 5, 6, 7, 8]   \n",
       "34             NaN        Adulthood Psychological                    [7, 8]   \n",
       "35             NaN        Adulthood Psychological                    [7, 8]   \n",
       "36             NaN  Adulthood Adverse Experiences                    [7, 8]   \n",
       "37             NaN        Adulthood Psychological                    [1, 2]   \n",
       "38             NaN        Adulthood Psychological                    [1, 2]   \n",
       "39             NaN        Adulthood Psychological                       [1]   \n",
       "40             NaN        Adulthood Psychological                       [1]   \n",
       "41             NaN        Adulthood Psychological                    [1, 2]   \n",
       "\n",
       "     recode_type  reverse_code  maximum_missing_response  \\\n",
       "0     direct_use         False                       NaN   \n",
       "1   replace_only         False                       NaN   \n",
       "2   replace_only          True                       NaN   \n",
       "3   replace_only         False                       NaN   \n",
       "4   replace_only         False                       NaN   \n",
       "5   replace_only         False                       NaN   \n",
       "6   replace_only         False                       NaN   \n",
       "7     direct_use         False                       NaN   \n",
       "8     direct_use         False                       NaN   \n",
       "9     historical         False                       NaN   \n",
       "10  replace_only         False                       NaN   \n",
       "11  replace_only         False                       NaN   \n",
       "12  replace_only         False                       NaN   \n",
       "13    historical         False                       NaN   \n",
       "14  replace_only         False                       NaN   \n",
       "15    historical         False                       NaN   \n",
       "16    direct_use         False                       NaN   \n",
       "17    historical         False                       NaN   \n",
       "18    historical         False                       NaN   \n",
       "19  replace_only         False                       NaN   \n",
       "20    historical         False                       NaN   \n",
       "21  replace_only         False                       NaN   \n",
       "22    direct_use         False                       NaN   \n",
       "23  replace_only          True                       NaN   \n",
       "24  replace_only          True                       NaN   \n",
       "25  replace_only         False                       NaN   \n",
       "26    direct_use         False                       NaN   \n",
       "27  special_code         False                       NaN   \n",
       "28    direct_use         False                       NaN   \n",
       "29    row_manual         False                       NaN   \n",
       "30    row_manual         False                       NaN   \n",
       "31    row_manual         False                       3.0   \n",
       "32    row_manual         False                       NaN   \n",
       "33    row_manual         False                       4.0   \n",
       "34    row_manual         False                       2.0   \n",
       "35    row_manual         False                       2.0   \n",
       "36    row_manual         False                       NaN   \n",
       "37    row_manual         False                       2.0   \n",
       "38    row_manual         False                       4.0   \n",
       "39    row_manual         False                       9.0   \n",
       "40    row_manual         False                       2.0   \n",
       "41    row_manual         False                       8.0   \n",
       "\n",
       "                                         replace_dict  standardise  \\\n",
       "0                                                 NaN         True   \n",
       "1                                                 NaN         True   \n",
       "2   {'1.Primary education': 1, '3.Upper secondary ...         True   \n",
       "3          {'1.rural': 1, '0.urban': -1, 'nan': None}         True   \n",
       "4               {'0.No': -1, '1.Yes': 1, 'nan': None}         True   \n",
       "5   {'1.in country': -1, '0.out of country': 1, 'n...         True   \n",
       "6            {'1.man': 1, '2.woman': -1, 'nan': None}         True   \n",
       "7                                                 NaN        False   \n",
       "8                                                 NaN         True   \n",
       "9               {'0.No': -1, '1.Yes': 1, 'nan': None}         True   \n",
       "10  {'3.1 per week': -1, '4.1-3 per mon': 1, '2.> ...         True   \n",
       "11  {'3.1 per week': -1, '4.1-3 per mon': 1, '2.> ...         True   \n",
       "12              {'1.yes': 1, '0.no': -1, 'nan': None}         True   \n",
       "13              {'0.No': -1, '1.Yes': 1, 'nan': None}         True   \n",
       "14              {'0.No': -1, '1.Yes': 1, 'nan': None}         True   \n",
       "15              {'1.yes': 1, '0.no': -1, 'nan': None}         True   \n",
       "16                                                NaN         True   \n",
       "17              {'1.yes': 1, '0.no': -1, 'nan': None}         True   \n",
       "18  {'3.other arrangements': -1, '2.rents home': 1...         True   \n",
       "19              {'1.yes': 1, '0.no': -1, 'nan': None}         True   \n",
       "20  {'7.widowed': -1, '1.married': -1, '8.never ma...         True   \n",
       "21  {'7.widowed': -1, '1.married': -1, '8.never ma...         True   \n",
       "22                                                NaN         True   \n",
       "23  {'6.Second stage of tertiary education': 6, '2...         True   \n",
       "24  {'6.Second stage of tertiary education': 6, '2...         True   \n",
       "25  {'7.Craft or related trades worker': 5, '6.Ski...         True   \n",
       "26                                                NaN         True   \n",
       "27                                                NaN         True   \n",
       "28                                                NaN         True   \n",
       "29                                                NaN        False   \n",
       "30  {'sharew1_rel8-0-0_dropoff.dta': {1.0: 1, 2.0:...        False   \n",
       "31  {'sharew4_rel8-0-0_mh.dta': {'Hardly ever': 2,...         True   \n",
       "32  {'sharew1_rel8-0-0_mh.dta': {'Refusal': None, ...         True   \n",
       "33  {'sharew4_rel8-0-0_dropoff.dta': {'Hardly ever...         True   \n",
       "34  {'sharew7_rel8-0-0_ac.dta': {'Disagree a littl...         True   \n",
       "35  {'sharew7_rel8-0-0_ac.dta': {'Disagree a littl...         True   \n",
       "36                                                NaN         True   \n",
       "37  {'sharew1_rel8-0-0_dropoff.dta': {'Strongly ag...         True   \n",
       "38  {'sharew1_rel8-0-0_dropoff.dta': {'Strongly ag...         True   \n",
       "39  {'sharew1_rel8-0-0_dropoff.dta': {'Almost none...         True   \n",
       "40  {'sharew1_rel8-0-0_dropoff.dta': {'Almost none...         True   \n",
       "41                                                NaN         True   \n",
       "\n",
       "                                                notes recode_date  \\\n",
       "0                                                 NaN  2023-01-10   \n",
       "1                                                 NaN  2023-01-10   \n",
       "2   not same as HRS, we use the ISCED 2 code for e...  2023-01-10   \n",
       "3                                    1:rural;-1:urban  2023-01-10   \n",
       "4               whether citizen at baseline interview  2023-01-10   \n",
       "5                        Born in Country of Interview  2023-01-10   \n",
       "6                                                 NaN  2023-01-10   \n",
       "7                                                 NaN  2023-01-10   \n",
       "8                                                 NaN  2023-01-10   \n",
       "9                                                 NaN  2023-01-10   \n",
       "10                                 >=1 times/week, -1  2023-01-10   \n",
       "11                                 >=1 times/week, -1  2023-01-10   \n",
       "12  Directly using the definition of binge drunk f...  2023-01-10   \n",
       "13                                                NaN  2023-01-10   \n",
       "14                                                NaN  2023-01-10   \n",
       "15                                                NaN  2023-01-10   \n",
       "16                                                NaN  2023-01-11   \n",
       "17                                                NaN  2023-01-11   \n",
       "18                                                NaN  2023-01-10   \n",
       "19  r been asked have you have trouble recently in...  2023-01-11   \n",
       "20                                                NaN  2023-01-11   \n",
       "21                                                NaN  2023-01-11   \n",
       "22  This is an one-question Z-score, different to ...  2023-01-11   \n",
       "23                                     isced standard  2023-01-11   \n",
       "24                                     isced standard  2023-01-11   \n",
       "25            not just for father, but the main carer  2023-01-11   \n",
       "26                                                NaN  2023-01-12   \n",
       "27  (after tax) adding together Individual Earning...  2023-01-12   \n",
       "28                                                NaN  2023-01-12   \n",
       "29                                 Row Recode, Manual  2023-02-18   \n",
       "30                                 Raw Recode, Manual  2023-02-18   \n",
       "31                                 Raw Recode, Manual  2023-02-19   \n",
       "32                                 Raw Recode, Manual  2023-02-19   \n",
       "33                                 Raw Recode, Manual  2023-02-19   \n",
       "34                                 Raw Recode, Manual  2023-02-19   \n",
       "35                                 Raw Recode, Manual  2023-02-19   \n",
       "36                                 Raw Recode, Manual  2023-02-19   \n",
       "37                                 Raw Recode, Manual  2023-02-19   \n",
       "38                                 Raw Recode, Manual  2023-02-19   \n",
       "39                                 Raw Recode, Manual  2023-02-19   \n",
       "40                                 Raw Recode, Manual  2023-02-19   \n",
       "41                                 Raw Recode, Manual  2023-02-23   \n",
       "\n",
       "                                              var_set  in_ELSA  in_HRS  \\\n",
       "0                                        ['r1mcurln']    False   False   \n",
       "1                                         ['r8mstat']     True   False   \n",
       "2                                       ['raedisced']     True    True   \n",
       "3                                         ['h8rural']    False   False   \n",
       "4                                       ['racitizen']    False   False   \n",
       "5                                      ['rabcountry']     True    True   \n",
       "6                                        ['ragender']     True    True   \n",
       "7                                         ['radyear']     True    True   \n",
       "8                                          ['r8agey']     True    True   \n",
       "9   ['r1unemp', 'r2unemp', 'r4unemp', 'r5unemp', '...     True    True   \n",
       "10                                       ['r8vgactx']     True    True   \n",
       "11                                       ['r8mdactx']     True    True   \n",
       "12                                       ['r8drinkb']     True    True   \n",
       "13  ['r1smokev', 'r2smokev', 'r4smokev', 'r5smokev...     True    True   \n",
       "14                                       ['r8smokev']     True    True   \n",
       "15            ['r2drinkev', 'r4drinkev', 'r5drinkev']     True   False   \n",
       "16                                    ['racsevent_s']    False   False   \n",
       "17                             ['r3sfnhe', 'r7sfnhe']    False    True   \n",
       "18  ['r1hownrnt', 'r2hownrnt', 'r4hownrnt', 'r5how...     True    True   \n",
       "19                                        ['r8sleep']     True    True   \n",
       "20  ['r1mstat', 'r2mstat', 'r4mstat', 'r5mstat', '...     True    True   \n",
       "21                                        ['r8mstat']     True    True   \n",
       "22                                     ['r8satlifez']     True    True   \n",
       "23                                   ['ramomedisced']     True    True   \n",
       "24                                   ['radadedisced']     True    True   \n",
       "25                                      ['ramaoccup']    False    True   \n",
       "26                                        ['h8atotb']     True    True   \n",
       "27  ['r8itearn', 'r8itsemp', 'r8itpena', 'r8itpubp...     True    True   \n",
       "28                                        ['h8ittot']    False   False   \n",
       "29  [{1: ['q2_b', 'q2_c'], 2: ['ac015_'], 4: ['ac0...    False    True   \n",
       "30  [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q2_b',...    False    True   \n",
       "31  [{4: {'sharew4_rel8-0-0_mh.dta': ['mh023_', 'm...    False    True   \n",
       "32  [{1: {'sharew1_rel8-0-0_mh.dta': ['mh003_']}, ...    False    True   \n",
       "33  [{4: {'sharew4_rel8-0-0_dropoff.dta': ['q5a', ...    False    True   \n",
       "34  [{7: {'sharew7_rel8-0-0_ac.dta': ['ac702_', 'a...    False    True   \n",
       "35  [{7: {'sharew7_rel8-0-0_ac.dta': ['ac706_', 'a...    False    True   \n",
       "36  [{7: {'sharew7_rel8-0-0_ac.dta': ['ac709_', 'a...    False    True   \n",
       "37  [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q3_d',...    False    True   \n",
       "38  [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q3_a',...    False    True   \n",
       "39  [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q4_a',...    False    True   \n",
       "40  [{1: {'sharew1_rel8-0-0_dropoff.dta': ['q4_l',...    False    True   \n",
       "41  [{1: {'sharew1_rel8-0-0_dropoff.dta': ['ilq6',...    False    True   \n",
       "\n",
       "                wave_controller  \n",
       "0                   latest_wave  \n",
       "1                   latest_wave  \n",
       "2                   latest_wave  \n",
       "3                   latest_wave  \n",
       "4                   single_wave  \n",
       "5                   single_wave  \n",
       "6                   single_wave  \n",
       "7                   single_wave  \n",
       "8                   latest_wave  \n",
       "9                   latest_wave  \n",
       "10                  latest_wave  \n",
       "11                  latest_wave  \n",
       "12                  latest_wave  \n",
       "13                  latest_wave  \n",
       "14                  latest_wave  \n",
       "15                   drink_wave  \n",
       "16                  single_wave  \n",
       "17  financial_difficulties_wave  \n",
       "18                  latest_wave  \n",
       "19                  latest_wave  \n",
       "20                  latest_wave  \n",
       "21                  latest_wave  \n",
       "22                  latest_wave  \n",
       "23                  single_wave  \n",
       "24                  single_wave  \n",
       "25                  single_wave  \n",
       "26                  latest_wave  \n",
       "27                  latest_wave  \n",
       "28                  latest_wave  \n",
       "29                       manual  \n",
       "30                  latest_wave  \n",
       "31                       manual  \n",
       "32                       manual  \n",
       "33                       manual  \n",
       "34                       manual  \n",
       "35                       manual  \n",
       "36                       manual  \n",
       "37                       manual  \n",
       "38                       manual  \n",
       "39                       manual  \n",
       "40                       manual  \n",
       "41                       manual  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recode_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "289px",
    "width": "497px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
