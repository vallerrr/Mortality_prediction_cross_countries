{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enviornment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.6 (v3.8.6:db455296be, Sep 23 2020, 13:31:39) \\n[Clang 6.0 (clang-600.0.57)]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os \n",
    "from datetime import datetime\n",
    "os.chdir(Path.cwd().parent)\n",
    "sys.version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 10000 random seed in train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src import DataImport\n",
    "import matplotlib.pyplot as plt\n",
    "from src import Models\n",
    "import shap\n",
    "import pandas as pd \n",
    "import xgboost\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from src import Evaluate\n",
    "\n",
    "df = DataImport.data_reader_by_us(bio=False)\n",
    "\n",
    "df_seed_selection_lst=pd.DataFrame(columns=['seed','model','imv','roc-auc','pr-auc','f1','efron_r2','ffc_r2','IP'])\n",
    "\n",
    "#fit the model again to confirm the model performance \n",
    "import time\n",
    "import random\n",
    "count = 0 \n",
    "while count <=10000:\n",
    "    seed = random.randint(1, 100000)\n",
    "    for model_selection in ['xgb','lgb']:\n",
    "        print(f'\\n{model_selection} and seed is {seed}, count={count}')\n",
    "        model = Models.Model_fixed_test_size(data=df, test_size=0.3,domain_list=domains['all'], model=model_selection,train_subset_size=1, order=0, y_colname='death',random_state=seed)\n",
    "        evas = Evaluate.metric(model)\n",
    "        \n",
    "        temp = pd.DataFrame({'seed':seed,'model':model_selection,\n",
    "                             'imv':evas.imv,'roc-auc':evas.auc_score,\n",
    "                             'pr-auc':evas.pr_auc,'f1':evas.pr_f1,\n",
    "                             'efron_r2':evas.efron_rsquare,'ffc_r2':evas.ffc_r2,'IP':evas.pr_no_skill},index=[0])\n",
    "        df_seed_selection_lst.loc[len(df_seed_selection_lst),] = temp.loc[0,]\n",
    "        if evas.imv>=0.172 and evas.auc_score>=0.817:\n",
    "            print(f'imv={evas.imv},\\nroc-auc={evas.auc_score},\\npr-auc={evas.pr_auc},\\nf1={evas.pr_f1},\\nefron_r2={evas.efron_rsquare},\\nffc_r2={evas.ffc_r2},\\nIP={evas.pr_no_skill}')\n",
    "            print(\"-------------------------------------look at this\")\n",
    "        del model, evas\n",
    "    \n",
    "    if count % 100 ==0:\n",
    "        print(f'now seed is {seed} and we take 100s rest')\n",
    "        time.sleep(100)\n",
    "    count+=1\n",
    "\n",
    "df_seed_selection_lst.to_csv(Path.cwd()/'Data/HRS/seed_selection/10000random_seed_model_performance.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seed_selection_lst=pd.read_csv(Path.cwd()/'Data/HRS/seed_selection/10000random_seed_model_performance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1000 Seed in CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import numpy as np\n",
    "import random\n",
    "import lightgbm as LGB\n",
    "from src import Evaluate\n",
    "from src import DataImport\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def store_coef(count, k, model_name, seed, model, domains, df_coef, cv_name):\n",
    "    NOK = str(count) + '/' + str(k)\n",
    "    coef_dict = {'model': model_name, 'seed': seed, 'fold_method': cv_name, 'k': k, 'NOK': NOK}\n",
    "    for coef, feature in zip(model.coef_.T, domains):\n",
    "        coef_dict[feature] = coef[0]\n",
    "    temp = pd.DataFrame(coef_dict, index=[0])\n",
    "    df_coef.loc[len(df_coef),] = temp.loc[0,]\n",
    "    return df_coef\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('precision', 9)\n",
    "# read data\n",
    "df = DataImport.data_reader_by_us(bio=True)\n",
    "domain_dict = DataImport.domain_dict()\n",
    "domains = list(set(domain_dict['all_bio']))\n",
    "\n",
    "# control zone\n",
    "\n",
    "model_name = 'lgb'\n",
    "test_size = 0.3\n",
    "seed_min_included = 1\n",
    "seed_max_not_included = 3\n",
    "k_list = [1, 10, 50, 100, 200, 500, 1000]\n",
    "\n",
    "# specify dfs\n",
    "df_eval = pd.DataFrame(columns=['model', 'seed', 'fold_method', 'k', 'NOK', 'auc', 'f1', 'efron_r2', 'ffc_r2'])\n",
    "df_coef = pd.DataFrame(columns=['model', 'seed', 'fold_method', 'k', 'NOK'] + domains)\n",
    "\n",
    "for seed in np.arange(seed_min_included, seed_max_not_included, 1):\n",
    "    for k in k_list:\n",
    "        k, seed = int(k), int(seed)\n",
    "        print('seed is {} and k is {}'.format(seed, k))\n",
    "        random.seed(seed)\n",
    "        #  train-test split\n",
    "        X, test_X, y, test_y = train_test_split(df.drop('death', axis=1), df['death'], test_size=test_size, random_state=seed)\n",
    "        # X, test_X, y, test_y = train_test_split(df.drop('death', axis=1), df['death'],test_size=0.3)  # , random_state=2021)\n",
    "        count = 0\n",
    "\n",
    "        # when k = 1\n",
    "        if k == 1:\n",
    "            NOK = str(count) + '/' + str(k)\n",
    "            if model_name == 'lgb':\n",
    "                model = LGB.LGBMClassifier(random_state=seed)\n",
    "                model.fit(X[domains], y)\n",
    "            else:\n",
    "                model = LogisticRegression(random_state=seed)\n",
    "                model.fit(X[domains], y)\n",
    "                df_coef = store_coef(count + 1, k, model_name, seed, model, domains, df_coef, 'NO fold splitting')\n",
    "\n",
    "\n",
    "            pred, pred_prob = model.predict(test_X[domains]), model.predict_proba(test_X[domains])[:, 1]\n",
    "            # TODO: for each split, the predictions should be made on the test set or the cross validation test set?\n",
    "            Eval = Evaluate.evaluate_metric(test_y, pred, pred_prob, y)\n",
    "            df_eval.loc[len(df_eval),] = [model, seed, 'NO fold splitting', k, NOK, Eval['auc'], Eval['f1'],\n",
    "                                          Eval['efron_r2'], Eval['ffc_r2']]\n",
    "        else:\n",
    "            cv_dict = {'KFold': KFold(n_splits=k, shuffle=True, random_state=seed),\n",
    "                       'StratifiedKFold': StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)}\n",
    "            for cv_name in cv_dict.keys():\n",
    "                count = 0\n",
    "                cv = cv_dict[cv_name]\n",
    "\n",
    "                for train_index, test_index in (cv.split(X, y) if cv_name == 'StratifiedKFold' else cv.split(X)):\n",
    "                    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "                    # fit model with this split\n",
    "                    if model_name == 'lgb':\n",
    "                        model = LGB.LGBMClassifier(random_state=seed)\n",
    "                        model.fit(X_train[domains], y_train)\n",
    "                        count += 1\n",
    "                        NOK = str(count) + '/' + str(k)\n",
    "                    else:\n",
    "                        model = LogisticRegression(random_state=seed)\n",
    "                        model.fit(X_train[domains], y_train)\n",
    "                        count += 1\n",
    "                        NOK = str(count) + '/' + str(k)\n",
    "\n",
    "                        df_coef = store_coef(count, k, model_name, seed, model, domains, df_coef, cv_name)\n",
    "\n",
    "                    # store coefficients\n",
    "\n",
    "\n",
    "                    # store result evaluations\n",
    "\n",
    "                    # on the whole validation set\n",
    "                    '''pred, pred_prob = model.predict(test_X[domains]), model.predict_proba(test_X[domains])[:, 1]\n",
    "                    # TODO: for each split, the predictions should be made on the whole test set or the cross validation test set?\n",
    "                    Eval = seed_evaluate_metric(test_y, pred, pred_prob, y_train, test_X['sampWeight'])\n",
    "                    df_eval.loc[len(df_eval), ] = [model, seed, cv_name, k, NOK, Eval['auc'], Eval['f1'], Eval['efron_r2'], Eval['ffc_r2']]'''\n",
    "\n",
    "                    # on the  cross validation test set\n",
    "                    pred, pred_prob = model.predict(test_X[domains]), model.predict_proba(test_X[domains])[:, 1]\n",
    "                    # TODO: for each split, the predictions should be made on the whole test set or the cross validation test set?\n",
    "                    Eval = Evaluate.evaluate_metric(test_y, pred, pred_prob, y_train)\n",
    "                    df_eval.loc[len(df_eval),] = [model, seed, cv_name, k, NOK, Eval['auc'], Eval['f1'],\n",
    "                                                  Eval['efron_r2'], Eval['ffc_r2']]\n",
    "\n",
    "# df_eval.to_csv(Path.cwd()/'Seed/df_eval_lgbm_05052022_seed1-2.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed Result Thesis Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as LGB\n",
    "from src import Evaluate\n",
    "from src import DataImport\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from pathlib import Path\n",
    "\n",
    "df = DataImport.data_reader_by_us(bio=True)\n",
    "test_size=0.3\n",
    "seed = 1\n",
    "domain_dict = DataImport.domain_dict()\n",
    "domains = list(set(domain_dict['all_bio_adjusted']))\n",
    "\n",
    "df_eval=pd.DataFrame(columns=['model','seed','roc_auc','pr_auc','f1','efron_r2','ffc_r2','imv','brier'])\n",
    "\n",
    "for seed in np.arange(0,1000,1):\n",
    "    X, test_X, y, test_y = train_test_split(df.drop('death', axis=1), df['death'], test_size=test_size,\n",
    "                                            random_state=seed)\n",
    "    model=LGB.LGBMClassifier()\n",
    "    model.fit(X=X[domains],y=y)\n",
    "\n",
    "    pred, pred_prob = model.predict(test_X[domains]), model.predict_proba(test_X[domains])[:, 1]\n",
    "\n",
    "    Eval = Evaluate.evaluate_metric(test_y, pred, pred_prob, y)\n",
    "    df_eval.loc[len(df_eval),] = [model, seed, Eval['roc_auc'],Eval['auc'], Eval['f1'],\n",
    "                                  Eval['efron_r2'], Eval['ffc_r2'],Eval['imv'],Eval['brier']]\n",
    "\n",
    "\n",
    "# df_eval.to_csv(Path.cwd()/'Seed/1fold1000seed.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval=pd.read_csv(Path.cwd()/'Seed/1fold1000seed.csv',index_col=0)\n",
    "\n",
    "\n",
    "'''colums=['roc_auc', 'pr_auc', 'f1', 'efron_r2', 'ffc_r2', 'imv']\n",
    "for column in colums:\n",
    "    print(column,'&',round(df_eval[column].min(),3),'&',round(df_eval[column].max(),3),'\\\\\\\\')\n",
    "'''\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig,ax = plt.subplots(3,2)\n",
    "plt.rcParams[\"figure.figsize\"]=[12,10]\n",
    "count=0\n",
    "colums=['roc_auc', 'pr_auc', 'f1', 'efron_r2', 'ffc_r2', 'imv']\n",
    "column_dict={'roc_auc':'ROC-AUC Score', 'pr_auc':'PR-AUC Score', 'f1':'F1', 'efron_r2':'Efron R2', 'ffc_r2':'FFC R2', 'imv':'IMV'}\n",
    "fig.subplots_adjust(left=0.09, top=0.98, bottom=0.06, right=0.95)\n",
    "\n",
    "colors = ['#001c54', '#E89818']\n",
    "letter_fontsize = 24\n",
    "label_fontsize = 16\n",
    "for (m, n), subplot in np.ndenumerate(ax):\n",
    "\n",
    "    sns.distplot(df_eval[colums[count]],\n",
    "                 hist_kws={'facecolor': colors[0],'edgecolor': 'k','alpha': 0.6,},\n",
    "                 kde_kws={'color': colors[1]}, ax=ax[m,n], bins=20)\n",
    "    # ax[m,n].hist(df_eval[colums[count]],color=color_blue,alpha=0.75,bins=30,edgecolor='black')\n",
    "    ax[m, n].set_xlabel(column_dict[colums[count]],fontsize=label_fontsize+1)\n",
    "    ax[m, n].set_ylabel('Density',fontsize=label_fontsize + 1)\n",
    "    ax[m,n].tick_params(axis='both', which='major', labelsize=label_fontsize)\n",
    "    count+=1\n",
    "    ax[m, n].spines['top'].set_visible(False)\n",
    "    ax[m, n].spines['right'].set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.savefig(Path.cwd()/'graphs/seed.pdf')\n",
    "\n",
    "for column in colums:\n",
    "    print(column)\n",
    "    print(df_eval[column].describe())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
