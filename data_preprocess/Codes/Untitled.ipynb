{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b60987bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'var_dict_1' from 'data_preprocess.Codes.Params' (/Users/valler/Python/OX_Thesis/OX_thesis/data_preprocess/Codes/Params.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_3306/3773879521.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_preprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParams\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrecode_var_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_dict_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_dict_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mread_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_dict_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'var_dict_1' from 'data_preprocess.Codes.Params' (/Users/valler/Python/OX_Thesis/OX_thesis/data_preprocess/Codes/Params.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from data_preprocess.Codes.Params import recode_var_dict,var_dict_1,var_dict_2,read_df,var_dict_0\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "df = read_df()\n",
    "df_sent_by_author = pd.read_csv('/Users/valler/Python/OX_Thesis/OX_thesis/data_preprocess/Data/author_data.csv')\n",
    "df_sent_by_author['sampWeight']=df_sent_by_author['sampWeight'].replace(' ',np.nan).replace('0',np.nan)\n",
    "df_sent_by_author = df_sent_by_author.dropna(subset=['sampWeight'])\n",
    "df_rand = pd.read_stata('/Users/valler/Python/OX_Thesis/OX_thesis/data_preprocess/Data/Rand/randhrs1992_2018v1.dta')\n",
    "def save_df(df):\n",
    "    df.to_csv('/Users/valler/Python/OX_Thesis/OX_thesis/data_preprocess/Data/merge_data.csv',index=False)\n",
    "def recode_dict(df,col):\n",
    "    dict={}\n",
    "    for var in df[col].value_counts().index:\n",
    "        replace=input('for value {}, you want it replace with'.format(var))\n",
    "\n",
    "        dict[var]=int(replace)\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d05a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from data_preprocess.Codes.Params import recode_var_dict, var_dict\n",
    "import numpy as np\n",
    "\n",
    "cross_wave = pd.read_stata(\n",
    "    \"/Users/valler/Python/OX_Thesis/OX_thesis/data_preprocess/Data/CrossWaveTracker/trk2018v2a/trk2018tr_r.dta\")\n",
    "weight = cross_wave[['hhid', 'pn', 'kwgtr', 'lwgtr']]\n",
    "cross_wave['hhidpn'] = [str(x) + str(y) for x, y in zip(cross_wave['hhid'], cross_wave['pn'])]\n",
    "\n",
    "data_path = \"/Users/valler/Python/OX_Thesis/OX_thesis/data_preprocess/Data/Variables/multi_original\"\n",
    "\n",
    "# get the list of files in the folder\n",
    "files_lst = [x if 'csv' in x else None for x in os.listdir(data_path)]\n",
    "while None in files_lst: files_lst.remove(None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c35d4b",
   "metadata": {},
   "source": [
    "# Change some 06/08 variables that should not be standardised before merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "425d5163",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_wave_match_col_lst={'21_Neighborhood_Cohesion': True,\n",
    " '21_Neighborhood_Social_Cohesion_and_Neighborhood_Physical_Disorder_A': True,\n",
    " '21_Neighborhood_Social_Cohesion_and_Neighborhood_Physical_Disorder_B': True,\n",
    " '22_Positive_and_Negative_Social_Interactions_Children_A': True,\n",
    " '22_Positive_and_Negative_Social_Interactions_Children_B': True,\n",
    " '22_Positive_and_Negative_Social_Interactions_Family_A': True,\n",
    " '22_Positive_and_Negative_Social_Interactions_Family_B': True,\n",
    " '22_Positive_and_Negative_Social_Interactions_Friends_A': True,\n",
    " '22_Positive_and_Negative_Social_Interactions_Friends_B': True,\n",
    " '23_Personality_traits_agreeableness_A': True,\n",
    " '23_Personality_traits_conscientiousness_D': True,\n",
    " '23_Personality_traits_extroversion_B': True,\n",
    " '23_Personality_traits_neuroticism_C': True,\n",
    " '23_Personality_traits_openness_to_experience_E': True,\n",
    " '24_Anger_Out': True,\n",
    " '25_Anger_In': True,\n",
    " '26_Cynical_Hostility': True,\n",
    " '27_Hopelessness': True,\n",
    " '28_Loneliness': True,\n",
    " '29_Life_Satisfaction': True,\n",
    " '30_Optimism': False,\n",
    " '31_Positive_Affect': True,\n",
    " '32_Negative_Affect': True,\n",
    " '33_Purpose_in_Life': True,\n",
    " '34_Religiosity': True,\n",
    " '35_Perceived_Constraints': True,\n",
    " '36_Perceived_Mastery': True,\n",
    " '37_Trait_Anxiety': True,\n",
    " '38_Adult_Psychosocial_Adversity': True,\n",
    " '39_Daily_Discrimination': True,\n",
    " '40_Major_Discrimination': True,\n",
    " '41_Pessimism': True,\n",
    " '42_Neighborhood_Physical_Disorder': True,\n",
    " '43_Income': False,\n",
    " '44_Wealth': False,\n",
    " '46_Child_Psychosocial_Adversity': True,\n",
    " '47_Lower_Occupational_Status': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51adba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue with ['43_Income_08.csv', '43_Income_06.csv'] y/ny\n",
      "want reverse control? y/ny\n",
      "want to average them? y/nn\n",
      "Index(['hhid', 'pn', 'h9itot'], dtype='object')\n",
      "input the col to saveh9itot\n",
      "Index(['hhid', 'pn', 'h8itot'], dtype='object')\n",
      "input the col to saveh8itot\n",
      "continue with ['44_Wealth_08.csv', '44_Wealth_06.csv'] y/ny\n",
      "want reverse control? y/ny\n",
      "want to average them? y/nn\n",
      "Index(['hhid', 'pn', 'h9atotw'], dtype='object')\n",
      "input the col to saveh9atotw\n",
      "Index(['hhid', 'pn', 'h8atotw'], dtype='object')\n",
      "input the col to saveh8atotw\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for var_name in cross_wave_match_col_lst.keys():\n",
    "    if not cross_wave_match_col_lst[var_name]:\n",
    "        related_files = []\n",
    "        for x in files_lst:\n",
    "            if var_name in x: related_files.append(x)\n",
    "\n",
    "        continue_check = input('continue with {} y/n'.format(related_files))\n",
    "        if continue_check == 'y':\n",
    "            files = related_files\n",
    "        else:\n",
    "            files = input('please input the files to process, with , as splitter')\n",
    "            files = files.replace('\\'', '').replace(' ', '').split(',')\n",
    "        reverse_control = input('want reverse control? y/n')\n",
    "        average_control = input('want to average them? y/n')\n",
    "        for file in files:\n",
    "\n",
    "            if '06' in file:\n",
    "                df_06 = pd.read_csv(data_path + '/' + file, index_col=0)\n",
    "                if 'zero_counts' in df_06.columns:\n",
    "                    columns = [x if 'var' in x else None for x in df_06.columns]\n",
    "                    while None in columns: columns.remove(None)\n",
    "\n",
    "                    # set the max nan number\n",
    "\n",
    "                    choice = input('for var {} in 06, exceed ? nans will be defined as nan'.format(file))\n",
    "                    choice = int(choice)\n",
    "\n",
    "                    # reverse control\n",
    "                    if reverse_control == 'y':\n",
    "                        unique_nums = []\n",
    "                        for column in columns:\n",
    "                            unique_nums = list(set(unique_nums + list(df_06[column].unique())))\n",
    "                        unique_nums.remove(0)\n",
    "                        unique_nums.sort()\n",
    "                        reverse_dict = {x: unique_nums[len(unique_nums) - unique_nums.index(x) - 1] for x in\n",
    "                                        unique_nums}\n",
    "                    \n",
    "                    # deal with the max nan number\n",
    "                    for index, row in df_06.iterrows():\n",
    "                        if row['zero_counts'] >= choice:\n",
    "                            df_06.loc[index, 'value_06'] = None\n",
    "                        else:\n",
    "                            if reverse_control == 'y':\n",
    "                                row[columns] = row[columns].replace(reverse_dict)\n",
    "                            if average_control =='y':\n",
    "                                df_06.loc[index, 'value_06'] = sum(row[columns]) / len(columns)\n",
    "                            else:\n",
    "                                df_06.loc[index, 'value_06'] = sum(row[columns])\n",
    "                else:\n",
    "                    print(df_06.columns)\n",
    "                    col_to_save = input('input the col to save')\n",
    "                    df_06['value_06'] = df_06[col_to_save]\n",
    "            elif '08' in file:\n",
    "                df_08 = pd.read_csv(data_path + '/' + file, index_col=0)\n",
    "                if 'zero_counts' in df_08.columns:\n",
    "                    columns = [x if 'var' in x else None for x in df_08.columns]\n",
    "                    while None in columns: columns.remove(None)\n",
    "\n",
    "                    choice = input('for var {} in 08, exceed ? nans will be defined as nan'.format(file))\n",
    "                    choice = int(choice)\n",
    "\n",
    "                    if reverse_control == 'y':\n",
    "                        unique_nums = []\n",
    "                        for column in columns:\n",
    "                            unique_nums = list(set(unique_nums + list(df_08[column].unique())))\n",
    "\n",
    "                        unique_nums.remove(0)\n",
    "                        unique_nums.sort()\n",
    "                        reverse_dict = {x: unique_nums[len(unique_nums) - unique_nums.index(x) - 1] for x in\n",
    "                                        unique_nums}\n",
    "\n",
    "                    for index, row in df_08.iterrows():\n",
    "                        if row['zero_counts'] >= choice:\n",
    "                            df_08.loc[index, 'value_08'] = None\n",
    "                        else:\n",
    "                            if reverse_control == 'y':\n",
    "                                row[columns] = row[columns].replace(reverse_dict)\n",
    "                            \n",
    "                            if average_control =='y':\n",
    "                                df_08.loc[index, 'value_08'] = sum(row[columns]) / len(columns)\n",
    "                            else:\n",
    "                                df_08.loc[index, 'value_08'] = sum(row[columns])\n",
    "                            \n",
    "                else:\n",
    "                    print(df_08.columns)\n",
    "                    col_to_save = input('input the col to save')\n",
    "                    df_08['value_08'] = df_08[col_to_save]\n",
    "        try:\n",
    "            df_to_save = pd.merge(left=df_06[['HHID', 'PN', 'value_06']], right=df_08[['HHID', 'PN', 'value_08']],\n",
    "                                  left_on=['HHID', 'PN'], right_on=['HHID', 'PN'])\n",
    "        except:\n",
    "            df_to_save = pd.merge(left=df_06[['hhid', 'pn', 'value_06']], right=df_08[['hhid', 'pn', 'value_08']],\n",
    "                                  left_on=['hhid', 'pn'], right_on=['hhid', 'pn'])\n",
    "\n",
    "        df_to_save.to_csv('/Users/valler/Python/OX_Thesis/OX_thesis/data_preprocess/Data/Variables/vars_to_merge/' + var_name + '.csv',\n",
    "            index=False)\n",
    "        cross_wave_match_col_lst[var_name] = True\n",
    "    else:\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f97a761",
   "metadata": {},
   "source": [
    "# UPDATE those rows to the df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c077997",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/valler/Python/OX_Thesis/OX_thesis/data_preprocess/Data/Variables/vars_to_merge\"\n",
    "\n",
    "# get the list of files in the folder\n",
    "files_lst = [x if 'csv' in x else None for x in os.listdir(data_path)]\n",
    "while None in files_lst: files_lst.remove(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5da91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = read_df()\n",
    "\n",
    "var_dict = var_dict\n",
    "\n",
    "for var_name, var_explain in var_dict.items():\n",
    "    \n",
    "    if not var_explain[1]:\n",
    "        print('Start to merge {},{}'.format(var_name, var_explain[0]))\n",
    "        related_files=[]\n",
    "        for x in files_lst:\n",
    "            if var_name in x:\n",
    "                related_files.append(x)\n",
    "\n",
    "        print('files found: {}'.format(related_files))\n",
    "        input_ = input('Continue? y/s(kip)/b(reak)')\n",
    "        if input_ == 'y':\n",
    "            # update files\n",
    "            files_lst = [x if 'csv' in x else None for x in os.listdir(data_path)]\n",
    "            while None in files_lst: files_lst.remove(None)\n",
    "            files = [file_name for file_name in files_lst if var_explain[0].replace(' ', '_') in file_name]\n",
    "            if len(files) == 0:\n",
    "                filenames = input('please input the filenames, with , as the breaker')\n",
    "                files = filenames.split(',')\n",
    "            print('we are going to merge file {}'.format(files))\n",
    "            # read the two files from 08 or 06\n",
    "            for file in files:\n",
    "                print('process file {}'.format(file))\n",
    "                temp, check_mark = read_file(file)\n",
    "                df = mark_the_row(temp, df, check_mark, var_name)\n",
    "            print('finished merging for varirable {},{}'.format(var_name, var_explain[0]))\n",
    "            var_dict[var_name][1] = True\n",
    "            if len(var_explain) == 3:\n",
    "                continue\n",
    "            else:\n",
    "                var_dict[var_name].append(files)\n",
    "            df.to_csv('/Users/valler/Python/OX_Thesis/OX_thesis/data_preprocess/Data/merge_data_no_standardise.csv', index=False)\n",
    "        elif input_ == 's':\n",
    "            continue\n",
    "        else:\n",
    "            temp = input('Please overwrite the params.py with the new var_dict, press random to continue')\n",
    "            print(var_dict)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d0fe69",
   "metadata": {},
   "source": [
    "# Generating Vars that have individual problems\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "016fc589",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4x/vv626j3d62g57l8x8_7ksf0r0000gn/T/ipykernel_3306/1334134702.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/valler/Python/OX_Thesis/OX_thesis/data_preprocess/Data/merge_data_non_standardise_before.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_df' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/valler/Python/OX_Thesis/OX_thesis/data_preprocess/Data/merge_data_non_standardise_before.csv')\n",
    "\n",
    "df['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb4b5657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(df,var):\n",
    "    print('mean={},std={},min={},max={},null_count={},median={}'.format(np.mean(df[var]),np.std(df[var]),df[var].min(),df[var].max(),df[var].isnull().sum(),np.median(df[var])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0924ac",
   "metadata": {},
   "source": [
    "## Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18bffe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ZincomeT'].replace({0:1},inplace=True)\n",
    "df['ZincomeT']=np.log(df['ZincomeT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4bcd9b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0209079996886455e-16 1.0\n"
     ]
    }
   ],
   "source": [
    "df['ZincomeT']-=np.mean(df['ZincomeT'])\n",
    "df['ZincomeT']/=np.std(df['ZincomeT'])\n",
    "\n",
    "print(np.mean(df['ZincomeT']),np.std(df['ZincomeT']))\n",
    "print(np.mean(df['ZincomeT']),np.std(df['ZincomeT']),df['ZincomeT'].min(),df['ZincomeT'].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3241b6e",
   "metadata": {},
   "source": [
    "## Wealth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6c6017b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valler/anaconda3/envs/OX_MPhil_Thesis/lib/python3.7/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df['ZwealthT'].replace({0:1},inplace=True)\n",
    "df['ZwealthT']=np.log(df['ZwealthT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7f9ca77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.069971458236009e-16 1.0\n"
     ]
    }
   ],
   "source": [
    "df['ZwealthT']-=np.mean(df['ZwealthT'])\n",
    "df['ZwealthT']/=np.std(df['ZwealthT'])\n",
    "\n",
    "print(np.mean(df['ZwealthT']),np.std(df['ZwealthT']))\n",
    "print(np.mean(df['ZwealthT']),np.std(df['ZwealthT']),df['ZwealthT'].min(),df['ZwealthT'].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46474d7c",
   "metadata": {},
   "source": [
    "## History of renting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f8a99ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2230500703381441 0.9748069891635723 -1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "df['everrent'].replace({np.nan:-1},inplace=True)\n",
    "print_statistics(df,'everrent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29550cf6",
   "metadata": {},
   "source": [
    "## History of Medicaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df432132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=-0.8614078049288804,std=0.5079139628004019,min=-1.0,max=1.0,null_count=0,median=-1.0\n"
     ]
    }
   ],
   "source": [
    "df['evermedicaid'].replace({np.nan:-1},inplace=True)\n",
    "print_statistics(df,'evermedicaid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b122414",
   "metadata": {},
   "source": [
    "## History of Smoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b423037b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=0.1448087431693989,std=0.9894596646158443,min=-1.0,max=1.0,null_count=161,median=nan\n"
     ]
    }
   ],
   "source": [
    "df['eversmokeYN'].replace({0:-1},inplace=True)\n",
    "print_statistics(df,'eversmokeYN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f200679c",
   "metadata": {},
   "source": [
    "## Current Smoker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c6bda87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=-0.7367314766158697,std=0.6761854267605892,min=-1.0,max=1.0,null_count=163,median=nan\n"
     ]
    }
   ],
   "source": [
    "df['currsmokeYN'].replace({0:-1},inplace=True)\n",
    "print_statistics(df,'currsmokeYN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7076791c",
   "metadata": {},
   "source": [
    "## Lower Education\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46d6925b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    9305\n",
       "0.0    9055\n",
       "1.0     833\n",
       "Name: Zeduccat, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Zeduccat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3badf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=2.295297744861471e-17,std=1.0,min=-1.0183971001905512,max=1.0213373728813755,null_count=0,median=-0.33848560916657566\n"
     ]
    }
   ],
   "source": [
    "df['Zeduccat']-=np.mean(df['Zeduccat'])\n",
    "df['Zeduccat']/=np.std(df['Zeduccat'])\n",
    "print_statistics(df,'Zeduccat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e4a4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/valler/Python/OX_Thesis/OX_thesis/data_preprocess/Data/merge_data_step_3.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed66c760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "453.852px",
    "left": "1322px",
    "right": "20px",
    "top": "121px",
    "width": "312px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
